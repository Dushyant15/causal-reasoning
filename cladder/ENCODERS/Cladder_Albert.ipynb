{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNdKwVe9pLShAeoevOjH5m2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8b54d09169864e8ab8cdce016f5f3c5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6aa226c3238c4d5dad864ddb12a4b870","IPY_MODEL_4bbb9185a80e4776b6b9996b2785dad8","IPY_MODEL_3ae944a854d04bc1b3dc2653a8099f6f"],"layout":"IPY_MODEL_344bf70976b040f9a7f8c7d77698d311"}},"6aa226c3238c4d5dad864ddb12a4b870":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46973420c81340188e20e5f69d1f7bfd","placeholder":"​","style":"IPY_MODEL_81cb6d45fb98400ba449543b5d447eee","value":"spiece.model: 100%"}},"4bbb9185a80e4776b6b9996b2785dad8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55694f39b615448282618bb0286d77f9","max":760289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70f248b6502845a687a1acfe9842cc87","value":760289}},"3ae944a854d04bc1b3dc2653a8099f6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d574ca9adfd341b2b3d02f4d0efd1602","placeholder":"​","style":"IPY_MODEL_5ccf3b605cc948b59c54d07717ce675b","value":" 760k/760k [00:00&lt;00:00, 7.97MB/s]"}},"344bf70976b040f9a7f8c7d77698d311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46973420c81340188e20e5f69d1f7bfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81cb6d45fb98400ba449543b5d447eee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55694f39b615448282618bb0286d77f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70f248b6502845a687a1acfe9842cc87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d574ca9adfd341b2b3d02f4d0efd1602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ccf3b605cc948b59c54d07717ce675b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4243a22290844a7bfa23e48e8ac30e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d54880527294411e84b6122547433dd6","IPY_MODEL_83ef1b301c984168850ce9cb979b102c","IPY_MODEL_7387db9fc55b4216b34daea0e79898d7"],"layout":"IPY_MODEL_276a011d5cec4e7192e888774081ce25"}},"d54880527294411e84b6122547433dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5892b7728914c01b3fc2677aac933fc","placeholder":"​","style":"IPY_MODEL_a10847bda1f14f87b585da92a1976d3e","value":"tokenizer.json: 100%"}},"83ef1b301c984168850ce9cb979b102c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a57f8365ac4b0b9154d232b9108d7c","max":1312669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6de815ea4a4f46ed88cf7c92d2e60871","value":1312669}},"7387db9fc55b4216b34daea0e79898d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70a30cea1ba34fea92f1839260251eb8","placeholder":"​","style":"IPY_MODEL_095ad971d0bd4197ba18027a9b6203e9","value":" 1.31M/1.31M [00:00&lt;00:00, 16.5MB/s]"}},"276a011d5cec4e7192e888774081ce25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5892b7728914c01b3fc2677aac933fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a10847bda1f14f87b585da92a1976d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3a57f8365ac4b0b9154d232b9108d7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6de815ea4a4f46ed88cf7c92d2e60871":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70a30cea1ba34fea92f1839260251eb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"095ad971d0bd4197ba18027a9b6203e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdb9f49b282345148cf7f025efdec322":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b556062ba894d6dbe17640dffb84e0f","IPY_MODEL_64551eb545b54421b8852870b6329454","IPY_MODEL_68babb8198ce46d9862603cca902df64"],"layout":"IPY_MODEL_bc251a1ecbf14173a5857619d8030fc5"}},"6b556062ba894d6dbe17640dffb84e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e81f9891124342f782b2234d70020648","placeholder":"​","style":"IPY_MODEL_62a9ec0ecb924a0e85e6af894a6d972d","value":"config.json: 100%"}},"64551eb545b54421b8852870b6329454":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cefd1c683944bf2a53b256b34db5fd3","max":684,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3da5bfd021844a41b51372752dc04e79","value":684}},"68babb8198ce46d9862603cca902df64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94c6999709f34d729a0d73d81ef546d1","placeholder":"​","style":"IPY_MODEL_8e2cf7e9fbcc4e4094cae642ed7c1fe0","value":" 684/684 [00:00&lt;00:00, 58.2kB/s]"}},"bc251a1ecbf14173a5857619d8030fc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e81f9891124342f782b2234d70020648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62a9ec0ecb924a0e85e6af894a6d972d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cefd1c683944bf2a53b256b34db5fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da5bfd021844a41b51372752dc04e79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94c6999709f34d729a0d73d81ef546d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e2cf7e9fbcc4e4094cae642ed7c1fe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"826727b5d4ff4053be75789974520070":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1458e92a08a14522b2a83f9716069dbd","IPY_MODEL_884ad55840744450928866cbe279da6b","IPY_MODEL_9776bd37bb1d4629a2a29f7d8aca2919"],"layout":"IPY_MODEL_42dea3a1b58f49699942699eafe0f16d"}},"1458e92a08a14522b2a83f9716069dbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22fd286cb1948ca96fcf676ef09c8ea","placeholder":"​","style":"IPY_MODEL_6faed65c95664ac5aac1ae79df3e23c5","value":"model.safetensors: 100%"}},"884ad55840744450928866cbe279da6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90173033e35b4e819e4ac3fd0bef86df","max":47372894,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcc36b651cfe49809744db8f7e564319","value":47372894}},"9776bd37bb1d4629a2a29f7d8aca2919":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8352b763654345348705487820f2e9e1","placeholder":"​","style":"IPY_MODEL_bcd89ba239974e5aa67b5595fcf9a31e","value":" 47.4M/47.4M [00:00&lt;00:00, 109MB/s]"}},"42dea3a1b58f49699942699eafe0f16d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a22fd286cb1948ca96fcf676ef09c8ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6faed65c95664ac5aac1ae79df3e23c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90173033e35b4e819e4ac3fd0bef86df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcc36b651cfe49809744db8f7e564319":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8352b763654345348705487820f2e9e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcd89ba239974e5aa67b5595fcf9a31e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"HcupLzV-TcEO","executionInfo":{"status":"ok","timestamp":1707459773415,"user_tz":480,"elapsed":4159,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"outputs":[],"source":["import json\n","import random\n","import torch"]},{"cell_type":"code","source":["import pandas as pd\n","\n","dataset = pd.read_csv(\"data_full_v1.csv\")"],"metadata":{"id":"UfVjEWGqVaFV","executionInfo":{"status":"ok","timestamp":1707459773811,"user_tz":480,"elapsed":398,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["dataset['ground_truth'] = dataset.apply(lambda row: 1 if row['label']=='yes' else 0, axis=1)\n","\n","dataset['prompt'] = dataset.apply(lambda row: (row['prompt']).removeprefix('Imagine a self-contained, hypothetical world with only the following conditions, and without any unmentioned factors or causal relationships: '), axis=1)\n"],"metadata":{"id":"veZaizBjVbN_","executionInfo":{"status":"ok","timestamp":1707459774011,"user_tz":480,"elapsed":202,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["dataset['prompt'] = dataset['prompt'].str.lower()"],"metadata":{"id":"mkcrERfYVcPS","executionInfo":{"status":"ok","timestamp":1707459774011,"user_tz":480,"elapsed":8,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"8UMC2QuQVdWW","executionInfo":{"status":"ok","timestamp":1707459774011,"user_tz":480,"elapsed":7,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}},"outputId":"57567e7b-2f81-4060-b4b2-7a4122fe8e24"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id                                             prompt label  \\\n","0          4  husband has a direct effect on wife and alarm ...   yes   \n","1          7  husband has a direct effect on wife and alarm ...    no   \n","2          8  husband has a direct effect on wife and alarm ...   yes   \n","3         15  husband has a direct effect on wife and alarm ...    no   \n","4         21  husband has a direct effect on wife and alarm ...    no   \n","...      ...                                                ...   ...   \n","10107  31012  zuph has a direct effect on glimx. jyka has a ...   yes   \n","10108  31014  zuph has a direct effect on glimx. jyka has a ...   yes   \n","10109  31015  zuph has a direct effect on glimx. jyka has a ...    no   \n","10110  31016  zuph has a direct effect on glimx. jyka has a ...    no   \n","10111  31019  zuph has a direct effect on glimx. jyka has a ...   yes   \n","\n","       ground_truth  \n","0                 1  \n","1                 0  \n","2                 1  \n","3                 0  \n","4                 0  \n","...             ...  \n","10107             1  \n","10108             1  \n","10109             0  \n","10110             0  \n","10111             1  \n","\n","[10112 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-d60bea51-5dfb-4a96-a71e-8cd846533141\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>label</th>\n","      <th>ground_truth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>husband has a direct effect on wife and alarm ...</td>\n","      <td>yes</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7</td>\n","      <td>husband has a direct effect on wife and alarm ...</td>\n","      <td>no</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>husband has a direct effect on wife and alarm ...</td>\n","      <td>yes</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15</td>\n","      <td>husband has a direct effect on wife and alarm ...</td>\n","      <td>no</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>21</td>\n","      <td>husband has a direct effect on wife and alarm ...</td>\n","      <td>no</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10107</th>\n","      <td>31012</td>\n","      <td>zuph has a direct effect on glimx. jyka has a ...</td>\n","      <td>yes</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10108</th>\n","      <td>31014</td>\n","      <td>zuph has a direct effect on glimx. jyka has a ...</td>\n","      <td>yes</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10109</th>\n","      <td>31015</td>\n","      <td>zuph has a direct effect on glimx. jyka has a ...</td>\n","      <td>no</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10110</th>\n","      <td>31016</td>\n","      <td>zuph has a direct effect on glimx. jyka has a ...</td>\n","      <td>no</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10111</th>\n","      <td>31019</td>\n","      <td>zuph has a direct effect on glimx. jyka has a ...</td>\n","      <td>yes</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10112 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d60bea51-5dfb-4a96-a71e-8cd846533141')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d60bea51-5dfb-4a96-a71e-8cd846533141 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d60bea51-5dfb-4a96-a71e-8cd846533141');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4318f424-d2af-457d-b486-eb870b6849b4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4318f424-d2af-457d-b486-eb870b6849b4')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4318f424-d2af-457d-b486-eb870b6849b4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_92440e48-a690-4edb-8758-c0d91d14cc1b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_92440e48-a690-4edb-8758-c0d91d14cc1b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('dataset');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["dataset = json.loads(dataset.to_json(orient ='records'))\n","\n","# Shuffle the dataset\n","random.shuffle(dataset)\n","\n","# Define split sizes for a 75-25 split\n","train_size = int(0.75 * len(dataset))\n","valid_size = len(dataset) - train_size\n","\n","# Split the dataset\n","train_data = dataset[:train_size]\n","validation_data = dataset[train_size:]"],"metadata":{"id":"p7NEYKASVeaI","executionInfo":{"status":"ok","timestamp":1707459774011,"user_tz":480,"elapsed":5,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class CladderDataset(Dataset):\n","    def __init__(self, cladder_data, tokenizer):\n","        self.cladder_data = cladder_data\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.cladder_data)\n","\n","    def __getitem__(self, idx):\n","        data = self.cladder_data[idx]\n","        # print(data)\n","        prompt = data['prompt']\n","        label = data['ground_truth']\n","\n","        # print(prompt)\n","        # print(label)\n","\n","        # Tokenize\n","        encoded_input = self.tokenizer(prompt, padding='max_length', truncation=True, return_tensors='pt').to(\"cuda\")\n","        # print(encoded_input)\n","        encoded_input['labels'] = torch.tensor(label).to(\"cuda\")\n","\n","        return encoded_input\n"],"metadata":{"id":"nC-HmeecVgRq","executionInfo":{"status":"ok","timestamp":1707459774011,"user_tz":480,"elapsed":5,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# from transformers import AlbertTokenizer, AlbertForSequenceClassification\n","# import torch\n","# from torch.utils.data import DataLoader\n","# import torch.optim as optim\n","\n","# # Load tokenizer and model\n","# tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n","# model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels = 2)"],"metadata":{"id":"w6gZGxrZVhlW","executionInfo":{"status":"ok","timestamp":1707459780016,"user_tz":480,"elapsed":3,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","# model.to(device)"],"metadata":{"id":"SIKn-enWWA8f","executionInfo":{"status":"ok","timestamp":1707459783588,"user_tz":480,"elapsed":185,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","from transformers import AlbertTokenizer as tkz\n","from transformers import AlbertForSequenceClassification as mpc\n","\n","# Load tokenizer and model\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2)\n","\n","# run = 0\n","# for run in range(1):\n","\n","for run in range(3):\n","  model_base = 'albert-base-v2'\n","  tokenizer = tkz.from_pretrained(model_base)\n","  model = mpc.from_pretrained(model_base, num_labels = 2)\n","\n","  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","  model.to(device)\n","\n","  # Prepare the DataLoader\n","  cladder_dataset = CladderDataset(train_data, tokenizer)\n","  dataloader = DataLoader(cladder_dataset, batch_size=8, shuffle=True)\n","\n","  # Optimizer and Loss Function\n","  optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","  loss_fn = torch.nn.CrossEntropyLoss()\n","\n","\n","\n","  # Training Loop\n","  model.train()\n","\n","  #change to 3\n","\n","  for epoch in range(3):  # Number of epochs\n","    for batch in dataloader:\n","        optimizer.zero_grad()\n","\n","        input_ids = batch['input_ids'].squeeze(1)\n","        attention_mask = batch['attention_mask'].squeeze(1)\n","        labels = batch['labels']\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n","\n","\n","  model_path = 'cladder_' + model_base + '_' + str(run) + '.pt'\n","  torch.save(model.state_dict(), model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8b54d09169864e8ab8cdce016f5f3c5c","6aa226c3238c4d5dad864ddb12a4b870","4bbb9185a80e4776b6b9996b2785dad8","3ae944a854d04bc1b3dc2653a8099f6f","344bf70976b040f9a7f8c7d77698d311","46973420c81340188e20e5f69d1f7bfd","81cb6d45fb98400ba449543b5d447eee","55694f39b615448282618bb0286d77f9","70f248b6502845a687a1acfe9842cc87","d574ca9adfd341b2b3d02f4d0efd1602","5ccf3b605cc948b59c54d07717ce675b","c4243a22290844a7bfa23e48e8ac30e0","d54880527294411e84b6122547433dd6","83ef1b301c984168850ce9cb979b102c","7387db9fc55b4216b34daea0e79898d7","276a011d5cec4e7192e888774081ce25","d5892b7728914c01b3fc2677aac933fc","a10847bda1f14f87b585da92a1976d3e","e3a57f8365ac4b0b9154d232b9108d7c","6de815ea4a4f46ed88cf7c92d2e60871","70a30cea1ba34fea92f1839260251eb8","095ad971d0bd4197ba18027a9b6203e9","bdb9f49b282345148cf7f025efdec322","6b556062ba894d6dbe17640dffb84e0f","64551eb545b54421b8852870b6329454","68babb8198ce46d9862603cca902df64","bc251a1ecbf14173a5857619d8030fc5","e81f9891124342f782b2234d70020648","62a9ec0ecb924a0e85e6af894a6d972d","9cefd1c683944bf2a53b256b34db5fd3","3da5bfd021844a41b51372752dc04e79","94c6999709f34d729a0d73d81ef546d1","8e2cf7e9fbcc4e4094cae642ed7c1fe0","826727b5d4ff4053be75789974520070","1458e92a08a14522b2a83f9716069dbd","884ad55840744450928866cbe279da6b","9776bd37bb1d4629a2a29f7d8aca2919","42dea3a1b58f49699942699eafe0f16d","a22fd286cb1948ca96fcf676ef09c8ea","6faed65c95664ac5aac1ae79df3e23c5","90173033e35b4e819e4ac3fd0bef86df","dcc36b651cfe49809744db8f7e564319","8352b763654345348705487820f2e9e1","bcd89ba239974e5aa67b5595fcf9a31e"]},"id":"WWE20-oUiN1N","executionInfo":{"status":"ok","timestamp":1707466363042,"user_tz":480,"elapsed":6545307,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}},"outputId":"5c5f7d66-a080-4f94-c1e3-120af5589bd8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b54d09169864e8ab8cdce016f5f3c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4243a22290844a7bfa23e48e8ac30e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb9f49b282345148cf7f025efdec322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826727b5d4ff4053be75789974520070"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss: 0.7095731496810913\n","Epoch: 0, Loss: 0.7612349987030029\n","Epoch: 0, Loss: 0.7637986540794373\n","Epoch: 0, Loss: 0.8401581048965454\n","Epoch: 0, Loss: 0.6446523070335388\n","Epoch: 0, Loss: 0.765009880065918\n","Epoch: 0, Loss: 0.7326542735099792\n","Epoch: 0, Loss: 0.649212121963501\n","Epoch: 0, Loss: 0.6538665890693665\n","Epoch: 0, Loss: 0.7557125091552734\n","Epoch: 0, Loss: 0.6962482333183289\n","Epoch: 0, Loss: 0.6790494322776794\n","Epoch: 0, Loss: 0.7162517309188843\n","Epoch: 0, Loss: 0.769901692867279\n","Epoch: 0, Loss: 0.7448083758354187\n","Epoch: 0, Loss: 0.8619913458824158\n","Epoch: 0, Loss: 0.7573511600494385\n","Epoch: 0, Loss: 0.6929714679718018\n","Epoch: 0, Loss: 0.6456261277198792\n","Epoch: 0, Loss: 0.7049251794815063\n","Epoch: 0, Loss: 0.6318690776824951\n","Epoch: 0, Loss: 0.820895254611969\n","Epoch: 0, Loss: 0.7399256229400635\n","Epoch: 0, Loss: 0.6800333857536316\n","Epoch: 0, Loss: 0.6628275513648987\n","Epoch: 0, Loss: 0.7710145711898804\n","Epoch: 0, Loss: 0.7096896767616272\n","Epoch: 0, Loss: 0.7462410926818848\n","Epoch: 0, Loss: 0.6948224902153015\n","Epoch: 0, Loss: 0.6421837210655212\n","Epoch: 0, Loss: 0.7363063097000122\n","Epoch: 0, Loss: 0.6412270665168762\n","Epoch: 0, Loss: 0.6707046031951904\n","Epoch: 0, Loss: 0.6871017217636108\n","Epoch: 0, Loss: 0.7667875289916992\n","Epoch: 0, Loss: 0.7329897284507751\n","Epoch: 0, Loss: 0.6708832383155823\n","Epoch: 0, Loss: 0.7566928267478943\n","Epoch: 0, Loss: 0.7057762145996094\n","Epoch: 0, Loss: 0.7331057190895081\n","Epoch: 0, Loss: 0.7078391909599304\n","Epoch: 0, Loss: 0.7463531494140625\n","Epoch: 0, Loss: 0.7358575463294983\n","Epoch: 0, Loss: 0.745037317276001\n","Epoch: 0, Loss: 0.6804404258728027\n","Epoch: 0, Loss: 0.7404419779777527\n","Epoch: 0, Loss: 0.6847022175788879\n","Epoch: 0, Loss: 0.685444176197052\n","Epoch: 0, Loss: 0.7116737365722656\n","Epoch: 0, Loss: 0.6824136972427368\n","Epoch: 0, Loss: 0.7143069505691528\n","Epoch: 0, Loss: 0.6414772868156433\n","Epoch: 0, Loss: 0.7219782471656799\n","Epoch: 0, Loss: 0.6620010137557983\n","Epoch: 0, Loss: 0.6998932957649231\n","Epoch: 0, Loss: 0.6669392585754395\n","Epoch: 0, Loss: 0.6998045444488525\n","Epoch: 0, Loss: 0.7455366849899292\n","Epoch: 0, Loss: 0.6409845352172852\n","Epoch: 0, Loss: 0.7258089184761047\n","Epoch: 0, Loss: 0.6771482229232788\n","Epoch: 0, Loss: 0.677547812461853\n","Epoch: 0, Loss: 0.696495532989502\n","Epoch: 0, Loss: 0.7400866150856018\n","Epoch: 0, Loss: 0.7415645122528076\n","Epoch: 0, Loss: 0.6967172026634216\n","Epoch: 0, Loss: 0.6168003082275391\n","Epoch: 0, Loss: 0.6165006160736084\n","Epoch: 0, Loss: 0.7435762286186218\n","Epoch: 0, Loss: 0.6981328129768372\n","Epoch: 0, Loss: 0.7240161299705505\n","Epoch: 0, Loss: 0.7166544198989868\n","Epoch: 0, Loss: 0.6797757744789124\n","Epoch: 0, Loss: 0.7438346147537231\n","Epoch: 0, Loss: 0.6979243159294128\n","Epoch: 0, Loss: 0.6926223039627075\n","Epoch: 0, Loss: 0.7411543726921082\n","Epoch: 0, Loss: 0.7222931385040283\n","Epoch: 0, Loss: 0.6393440961837769\n","Epoch: 0, Loss: 0.6880121231079102\n","Epoch: 0, Loss: 0.7164070010185242\n","Epoch: 0, Loss: 0.6949270963668823\n","Epoch: 0, Loss: 0.7535655498504639\n","Epoch: 0, Loss: 0.7225583791732788\n","Epoch: 0, Loss: 0.5916659832000732\n","Epoch: 0, Loss: 0.6797943115234375\n","Epoch: 0, Loss: 0.6397958993911743\n","Epoch: 0, Loss: 0.6166161298751831\n","Epoch: 0, Loss: 0.8254258036613464\n","Epoch: 0, Loss: 0.7375254034996033\n","Epoch: 0, Loss: 0.748572051525116\n","Epoch: 0, Loss: 0.7330033183097839\n","Epoch: 0, Loss: 0.8177909851074219\n","Epoch: 0, Loss: 0.7005301713943481\n","Epoch: 0, Loss: 0.6941900849342346\n","Epoch: 0, Loss: 0.7135523557662964\n","Epoch: 0, Loss: 0.7323875427246094\n","Epoch: 0, Loss: 0.7205264568328857\n","Epoch: 0, Loss: 0.6878445744514465\n","Epoch: 0, Loss: 0.6818608641624451\n","Epoch: 0, Loss: 0.6998117566108704\n","Epoch: 0, Loss: 0.7143906950950623\n","Epoch: 0, Loss: 0.7331425547599792\n","Epoch: 0, Loss: 0.7017190456390381\n","Epoch: 0, Loss: 0.7023153901100159\n","Epoch: 0, Loss: 0.7325336933135986\n","Epoch: 0, Loss: 0.6412518620491028\n","Epoch: 0, Loss: 0.7056798338890076\n","Epoch: 0, Loss: 0.6745849251747131\n","Epoch: 0, Loss: 0.6666014790534973\n","Epoch: 0, Loss: 0.6967818140983582\n","Epoch: 0, Loss: 0.683880090713501\n","Epoch: 0, Loss: 0.7271981835365295\n","Epoch: 0, Loss: 0.6724734902381897\n","Epoch: 0, Loss: 0.690031111240387\n","Epoch: 0, Loss: 0.6972082853317261\n","Epoch: 0, Loss: 0.6590629816055298\n","Epoch: 0, Loss: 0.6842376589775085\n","Epoch: 0, Loss: 0.6886885166168213\n","Epoch: 0, Loss: 0.7353001832962036\n","Epoch: 0, Loss: 0.6747109293937683\n","Epoch: 0, Loss: 0.6568583250045776\n","Epoch: 0, Loss: 0.6956641674041748\n","Epoch: 0, Loss: 0.7529672384262085\n","Epoch: 0, Loss: 0.7276151180267334\n","Epoch: 0, Loss: 0.6553546190261841\n","Epoch: 0, Loss: 0.7628650665283203\n","Epoch: 0, Loss: 0.6728518605232239\n","Epoch: 0, Loss: 0.7966681718826294\n","Epoch: 0, Loss: 0.685346782207489\n","Epoch: 0, Loss: 0.7621799111366272\n","Epoch: 0, Loss: 0.8172596096992493\n","Epoch: 0, Loss: 0.7385623455047607\n","Epoch: 0, Loss: 0.7233183979988098\n","Epoch: 0, Loss: 0.7023289203643799\n","Epoch: 0, Loss: 0.6766218543052673\n","Epoch: 0, Loss: 0.6787488460540771\n","Epoch: 0, Loss: 0.6964097619056702\n","Epoch: 0, Loss: 0.6907976865768433\n","Epoch: 0, Loss: 0.6935158967971802\n","Epoch: 0, Loss: 0.6576439142227173\n","Epoch: 0, Loss: 0.7102299332618713\n","Epoch: 0, Loss: 0.6466925740242004\n","Epoch: 0, Loss: 0.7053700685501099\n","Epoch: 0, Loss: 0.7474803924560547\n","Epoch: 0, Loss: 0.7080363035202026\n","Epoch: 0, Loss: 0.6852352023124695\n","Epoch: 0, Loss: 0.7064594030380249\n","Epoch: 0, Loss: 0.7305423021316528\n","Epoch: 0, Loss: 0.6796252727508545\n","Epoch: 0, Loss: 0.6925004124641418\n","Epoch: 0, Loss: 0.752443790435791\n","Epoch: 0, Loss: 0.6834919452667236\n","Epoch: 0, Loss: 0.8333386182785034\n","Epoch: 0, Loss: 0.6931110620498657\n","Epoch: 0, Loss: 0.6662082076072693\n","Epoch: 0, Loss: 0.6784570217132568\n","Epoch: 0, Loss: 0.7032949924468994\n","Epoch: 0, Loss: 0.6945300698280334\n","Epoch: 0, Loss: 0.7008692026138306\n","Epoch: 0, Loss: 0.7376101016998291\n","Epoch: 0, Loss: 0.7384326457977295\n","Epoch: 0, Loss: 0.7022254467010498\n","Epoch: 0, Loss: 0.6992682814598083\n","Epoch: 0, Loss: 0.6850410103797913\n","Epoch: 0, Loss: 0.6802497506141663\n","Epoch: 0, Loss: 0.6658045649528503\n","Epoch: 0, Loss: 0.6872992515563965\n","Epoch: 0, Loss: 0.7063236832618713\n","Epoch: 0, Loss: 0.7249821424484253\n","Epoch: 0, Loss: 0.6763452291488647\n","Epoch: 0, Loss: 0.7032157182693481\n","Epoch: 0, Loss: 0.68817538022995\n","Epoch: 0, Loss: 0.7299638390541077\n","Epoch: 0, Loss: 0.6926381587982178\n","Epoch: 0, Loss: 0.6821930408477783\n","Epoch: 0, Loss: 0.7294589281082153\n","Epoch: 0, Loss: 0.7048725485801697\n","Epoch: 0, Loss: 0.6786862015724182\n","Epoch: 0, Loss: 0.6116562485694885\n","Epoch: 0, Loss: 0.6280404329299927\n","Epoch: 0, Loss: 0.6876706480979919\n","Epoch: 0, Loss: 0.7392093539237976\n","Epoch: 0, Loss: 0.8310025334358215\n","Epoch: 0, Loss: 0.6952176690101624\n","Epoch: 0, Loss: 0.6723055243492126\n","Epoch: 0, Loss: 0.6686046719551086\n","Epoch: 0, Loss: 0.7712706327438354\n","Epoch: 0, Loss: 0.6596508026123047\n","Epoch: 0, Loss: 0.6966826915740967\n","Epoch: 0, Loss: 0.6818233728408813\n","Epoch: 0, Loss: 0.7297526597976685\n","Epoch: 0, Loss: 0.663048267364502\n","Epoch: 0, Loss: 0.6774386167526245\n","Epoch: 0, Loss: 0.7059530019760132\n","Epoch: 0, Loss: 0.6730049848556519\n","Epoch: 0, Loss: 0.6926028728485107\n","Epoch: 0, Loss: 0.7013887763023376\n","Epoch: 0, Loss: 0.7246642112731934\n","Epoch: 0, Loss: 0.7069032788276672\n","Epoch: 0, Loss: 0.7588119506835938\n","Epoch: 0, Loss: 0.7000330686569214\n","Epoch: 0, Loss: 0.6571228504180908\n","Epoch: 0, Loss: 0.6446602940559387\n","Epoch: 0, Loss: 0.6812280416488647\n","Epoch: 0, Loss: 0.6674661040306091\n","Epoch: 0, Loss: 0.6897063255310059\n","Epoch: 0, Loss: 0.7019721865653992\n","Epoch: 0, Loss: 0.7149308323860168\n","Epoch: 0, Loss: 0.6792227029800415\n","Epoch: 0, Loss: 0.7290686368942261\n","Epoch: 0, Loss: 0.6690992116928101\n","Epoch: 0, Loss: 0.61398845911026\n","Epoch: 0, Loss: 0.6161842346191406\n","Epoch: 0, Loss: 0.6680305600166321\n","Epoch: 0, Loss: 0.8874731063842773\n","Epoch: 0, Loss: 0.7113929390907288\n","Epoch: 0, Loss: 0.6974565982818604\n","Epoch: 0, Loss: 0.7170359492301941\n","Epoch: 0, Loss: 0.7661851644515991\n","Epoch: 0, Loss: 0.7053104639053345\n","Epoch: 0, Loss: 0.8633171319961548\n","Epoch: 0, Loss: 0.7496268153190613\n","Epoch: 0, Loss: 0.8006308078765869\n","Epoch: 0, Loss: 0.7133312225341797\n","Epoch: 0, Loss: 0.675662636756897\n","Epoch: 0, Loss: 0.6676134467124939\n","Epoch: 0, Loss: 0.659535825252533\n","Epoch: 0, Loss: 0.7629879713058472\n","Epoch: 0, Loss: 0.6228557825088501\n","Epoch: 0, Loss: 0.7808653116226196\n","Epoch: 0, Loss: 0.7723138332366943\n","Epoch: 0, Loss: 0.7545931339263916\n","Epoch: 0, Loss: 0.725989580154419\n","Epoch: 0, Loss: 0.6404469609260559\n","Epoch: 0, Loss: 0.6882818937301636\n","Epoch: 0, Loss: 0.7239823341369629\n","Epoch: 0, Loss: 0.7085961699485779\n","Epoch: 0, Loss: 0.7422136068344116\n","Epoch: 0, Loss: 0.7108310461044312\n","Epoch: 0, Loss: 0.6303173303604126\n","Epoch: 0, Loss: 0.7345372438430786\n","Epoch: 0, Loss: 0.7164999842643738\n","Epoch: 0, Loss: 0.661919355392456\n","Epoch: 0, Loss: 0.6324629187583923\n","Epoch: 0, Loss: 0.6295075416564941\n","Epoch: 0, Loss: 0.6509653925895691\n","Epoch: 0, Loss: 0.7077483534812927\n","Epoch: 0, Loss: 0.7374534010887146\n","Epoch: 0, Loss: 0.6744731664657593\n","Epoch: 0, Loss: 0.7028658390045166\n","Epoch: 0, Loss: 0.8122400045394897\n","Epoch: 0, Loss: 0.8118228912353516\n","Epoch: 0, Loss: 0.7422348856925964\n","Epoch: 0, Loss: 0.7651251554489136\n","Epoch: 0, Loss: 0.6511882543563843\n","Epoch: 0, Loss: 0.7305876612663269\n","Epoch: 0, Loss: 0.726343035697937\n","Epoch: 0, Loss: 0.7226828336715698\n","Epoch: 0, Loss: 0.653738260269165\n","Epoch: 0, Loss: 0.7036253213882446\n","Epoch: 0, Loss: 0.7085270285606384\n","Epoch: 0, Loss: 0.730463981628418\n","Epoch: 0, Loss: 0.7324648499488831\n","Epoch: 0, Loss: 0.7082251906394958\n","Epoch: 0, Loss: 0.7252633571624756\n","Epoch: 0, Loss: 0.7344766855239868\n","Epoch: 0, Loss: 0.6736629009246826\n","Epoch: 0, Loss: 0.706358790397644\n","Epoch: 0, Loss: 0.6896921396255493\n","Epoch: 0, Loss: 0.705856204032898\n","Epoch: 0, Loss: 0.6346420049667358\n","Epoch: 0, Loss: 0.6874675750732422\n","Epoch: 0, Loss: 0.617008626461029\n","Epoch: 0, Loss: 0.636307954788208\n","Epoch: 0, Loss: 0.7871332168579102\n","Epoch: 0, Loss: 0.6602301597595215\n","Epoch: 0, Loss: 0.7109571695327759\n","Epoch: 0, Loss: 0.7808518409729004\n","Epoch: 0, Loss: 0.6674137711524963\n","Epoch: 0, Loss: 0.675224244594574\n","Epoch: 0, Loss: 0.6569679975509644\n","Epoch: 0, Loss: 0.7263297438621521\n","Epoch: 0, Loss: 0.7799716591835022\n","Epoch: 0, Loss: 0.6308042407035828\n","Epoch: 0, Loss: 0.687874436378479\n","Epoch: 0, Loss: 0.7357580065727234\n","Epoch: 0, Loss: 0.7420227527618408\n","Epoch: 0, Loss: 0.70157790184021\n","Epoch: 0, Loss: 0.7374818325042725\n","Epoch: 0, Loss: 0.6969464421272278\n","Epoch: 0, Loss: 0.6785441637039185\n","Epoch: 0, Loss: 0.7514078617095947\n","Epoch: 0, Loss: 0.6956303119659424\n","Epoch: 0, Loss: 0.6948611736297607\n","Epoch: 0, Loss: 0.6841051578521729\n","Epoch: 0, Loss: 0.6934740543365479\n","Epoch: 0, Loss: 0.7015565037727356\n","Epoch: 0, Loss: 0.7538098692893982\n","Epoch: 0, Loss: 0.6363093852996826\n","Epoch: 0, Loss: 0.670450747013092\n","Epoch: 0, Loss: 0.6416894197463989\n","Epoch: 0, Loss: 0.6876997351646423\n","Epoch: 0, Loss: 0.7117807269096375\n","Epoch: 0, Loss: 0.6849529147148132\n","Epoch: 0, Loss: 0.6952863335609436\n","Epoch: 0, Loss: 0.6291184425354004\n","Epoch: 0, Loss: 0.6921238303184509\n","Epoch: 0, Loss: 0.705740749835968\n","Epoch: 0, Loss: 0.6913180947303772\n","Epoch: 0, Loss: 0.6875402331352234\n","Epoch: 0, Loss: 0.7378295660018921\n","Epoch: 0, Loss: 0.7902699112892151\n","Epoch: 0, Loss: 0.7140330076217651\n","Epoch: 0, Loss: 0.6874321699142456\n","Epoch: 0, Loss: 0.5966710448265076\n","Epoch: 0, Loss: 0.6890080571174622\n","Epoch: 0, Loss: 0.6996896266937256\n","Epoch: 0, Loss: 0.7102171182632446\n","Epoch: 0, Loss: 0.658247709274292\n","Epoch: 0, Loss: 0.6632924675941467\n","Epoch: 0, Loss: 0.68109530210495\n","Epoch: 0, Loss: 0.6731617450714111\n","Epoch: 0, Loss: 0.7087768316268921\n","Epoch: 0, Loss: 0.6955642700195312\n","Epoch: 0, Loss: 0.6897820234298706\n","Epoch: 0, Loss: 0.6941370368003845\n","Epoch: 0, Loss: 0.7002443075180054\n","Epoch: 0, Loss: 0.7190213799476624\n","Epoch: 0, Loss: 0.6796596050262451\n","Epoch: 0, Loss: 0.7235182523727417\n","Epoch: 0, Loss: 0.673531174659729\n","Epoch: 0, Loss: 0.6894445419311523\n","Epoch: 0, Loss: 0.6411905884742737\n","Epoch: 0, Loss: 0.7149642109870911\n","Epoch: 0, Loss: 0.6995363235473633\n","Epoch: 0, Loss: 0.6963909864425659\n","Epoch: 0, Loss: 0.7700144648551941\n","Epoch: 0, Loss: 0.6912654638290405\n","Epoch: 0, Loss: 0.7191314101219177\n","Epoch: 0, Loss: 0.6616940498352051\n","Epoch: 0, Loss: 0.7021512985229492\n","Epoch: 0, Loss: 0.7457877397537231\n","Epoch: 0, Loss: 0.7270943522453308\n","Epoch: 0, Loss: 0.7156338691711426\n","Epoch: 0, Loss: 0.6975864768028259\n","Epoch: 0, Loss: 0.7207785248756409\n","Epoch: 0, Loss: 0.7475132942199707\n","Epoch: 0, Loss: 0.7134202122688293\n","Epoch: 0, Loss: 0.6995322704315186\n","Epoch: 0, Loss: 0.642370343208313\n","Epoch: 0, Loss: 0.7089952826499939\n","Epoch: 0, Loss: 0.6496996283531189\n","Epoch: 0, Loss: 0.728905439376831\n","Epoch: 0, Loss: 0.638604462146759\n","Epoch: 0, Loss: 0.6729967594146729\n","Epoch: 0, Loss: 0.7180103659629822\n","Epoch: 0, Loss: 0.7778648138046265\n","Epoch: 0, Loss: 0.7726414799690247\n","Epoch: 0, Loss: 0.6550837159156799\n","Epoch: 0, Loss: 0.5976753830909729\n","Epoch: 0, Loss: 0.773032546043396\n","Epoch: 0, Loss: 0.5966935753822327\n","Epoch: 0, Loss: 0.6463978290557861\n","Epoch: 0, Loss: 0.6797140836715698\n","Epoch: 0, Loss: 0.7366483807563782\n","Epoch: 0, Loss: 0.7587513327598572\n","Epoch: 0, Loss: 0.8117190599441528\n","Epoch: 0, Loss: 0.6226713061332703\n","Epoch: 0, Loss: 0.8017747402191162\n","Epoch: 0, Loss: 0.7452161908149719\n","Epoch: 0, Loss: 0.6425960659980774\n","Epoch: 0, Loss: 0.7237483263015747\n","Epoch: 0, Loss: 0.7338187098503113\n","Epoch: 0, Loss: 0.6263865232467651\n","Epoch: 0, Loss: 0.6134985089302063\n","Epoch: 0, Loss: 0.6519474387168884\n","Epoch: 0, Loss: 0.7664006352424622\n","Epoch: 0, Loss: 0.6810706853866577\n","Epoch: 0, Loss: 0.6663086414337158\n","Epoch: 0, Loss: 0.7007068991661072\n","Epoch: 0, Loss: 0.7422509789466858\n","Epoch: 0, Loss: 0.6626881957054138\n","Epoch: 0, Loss: 0.6979467272758484\n","Epoch: 0, Loss: 0.6984378099441528\n","Epoch: 0, Loss: 0.707781195640564\n","Epoch: 0, Loss: 0.7043833136558533\n","Epoch: 0, Loss: 0.6550514101982117\n","Epoch: 0, Loss: 0.6354201436042786\n","Epoch: 0, Loss: 0.670120358467102\n","Epoch: 0, Loss: 0.6425432562828064\n","Epoch: 0, Loss: 0.7131255865097046\n","Epoch: 0, Loss: 0.6794142127037048\n","Epoch: 0, Loss: 0.7418750524520874\n","Epoch: 0, Loss: 0.6473729610443115\n","Epoch: 0, Loss: 0.7285562753677368\n","Epoch: 0, Loss: 0.7450100183486938\n","Epoch: 0, Loss: 0.7886748313903809\n","Epoch: 0, Loss: 0.7026616930961609\n","Epoch: 0, Loss: 0.7574071288108826\n","Epoch: 0, Loss: 0.6751551628112793\n","Epoch: 0, Loss: 0.698171854019165\n","Epoch: 0, Loss: 0.7266277074813843\n","Epoch: 0, Loss: 0.6847051978111267\n","Epoch: 0, Loss: 0.716858983039856\n","Epoch: 0, Loss: 0.6775811910629272\n","Epoch: 0, Loss: 0.6739209890365601\n","Epoch: 0, Loss: 0.6859270930290222\n","Epoch: 0, Loss: 0.7226818799972534\n","Epoch: 0, Loss: 0.6805979609489441\n","Epoch: 0, Loss: 0.6943917274475098\n","Epoch: 0, Loss: 0.6837798357009888\n","Epoch: 0, Loss: 0.6902890205383301\n","Epoch: 0, Loss: 0.7591413259506226\n","Epoch: 0, Loss: 0.6690467596054077\n","Epoch: 0, Loss: 0.724670946598053\n","Epoch: 0, Loss: 0.7350361943244934\n","Epoch: 0, Loss: 0.7221252918243408\n","Epoch: 0, Loss: 0.7339974641799927\n","Epoch: 0, Loss: 0.6333151459693909\n","Epoch: 0, Loss: 0.6740093231201172\n","Epoch: 0, Loss: 0.6514366865158081\n","Epoch: 0, Loss: 0.6689145565032959\n","Epoch: 0, Loss: 0.7072681188583374\n","Epoch: 0, Loss: 0.7188835144042969\n","Epoch: 0, Loss: 0.673808753490448\n","Epoch: 0, Loss: 0.6718241572380066\n","Epoch: 0, Loss: 0.673801839351654\n","Epoch: 0, Loss: 0.73273766040802\n","Epoch: 0, Loss: 0.6280233860015869\n","Epoch: 0, Loss: 0.6579204797744751\n","Epoch: 0, Loss: 0.7178806662559509\n","Epoch: 0, Loss: 0.6956851482391357\n","Epoch: 0, Loss: 0.6159651279449463\n","Epoch: 0, Loss: 0.7343077063560486\n","Epoch: 0, Loss: 0.5554080009460449\n","Epoch: 0, Loss: 0.6318842768669128\n","Epoch: 0, Loss: 0.8291926383972168\n","Epoch: 0, Loss: 0.6970994472503662\n","Epoch: 0, Loss: 0.9061405658721924\n","Epoch: 0, Loss: 0.6668519377708435\n","Epoch: 0, Loss: 0.748720109462738\n","Epoch: 0, Loss: 0.8477758169174194\n","Epoch: 0, Loss: 0.74456387758255\n","Epoch: 0, Loss: 0.7478665709495544\n","Epoch: 0, Loss: 0.6405497193336487\n","Epoch: 0, Loss: 0.6778114438056946\n","Epoch: 0, Loss: 0.7072415947914124\n","Epoch: 0, Loss: 0.657421886920929\n","Epoch: 0, Loss: 0.6603877544403076\n","Epoch: 0, Loss: 0.7355119585990906\n","Epoch: 0, Loss: 0.7295913696289062\n","Epoch: 0, Loss: 0.742545485496521\n","Epoch: 0, Loss: 0.721117377281189\n","Epoch: 0, Loss: 0.7172043323516846\n","Epoch: 0, Loss: 0.7233525514602661\n","Epoch: 0, Loss: 0.6495271921157837\n","Epoch: 0, Loss: 0.6660792827606201\n","Epoch: 0, Loss: 0.6990177035331726\n","Epoch: 0, Loss: 0.7051454782485962\n","Epoch: 0, Loss: 0.7037196755409241\n","Epoch: 0, Loss: 0.64158034324646\n","Epoch: 0, Loss: 0.7233296632766724\n","Epoch: 0, Loss: 0.7065873742103577\n","Epoch: 0, Loss: 0.7451844811439514\n","Epoch: 0, Loss: 0.691956102848053\n","Epoch: 0, Loss: 0.7711853981018066\n","Epoch: 0, Loss: 0.6892324090003967\n","Epoch: 0, Loss: 0.7325814962387085\n","Epoch: 0, Loss: 0.6735256910324097\n","Epoch: 0, Loss: 0.6880103349685669\n","Epoch: 0, Loss: 0.6427415013313293\n","Epoch: 0, Loss: 0.6842400431632996\n","Epoch: 0, Loss: 0.7310639023780823\n","Epoch: 0, Loss: 0.7119889855384827\n","Epoch: 0, Loss: 0.7341662645339966\n","Epoch: 0, Loss: 0.7128539085388184\n","Epoch: 0, Loss: 0.7217318415641785\n","Epoch: 0, Loss: 0.7042209506034851\n","Epoch: 0, Loss: 0.6880596876144409\n","Epoch: 0, Loss: 0.6604336500167847\n","Epoch: 0, Loss: 0.6680992245674133\n","Epoch: 0, Loss: 0.6829729080200195\n","Epoch: 0, Loss: 0.7161917090415955\n","Epoch: 0, Loss: 0.6880335807800293\n","Epoch: 0, Loss: 0.6512213945388794\n","Epoch: 0, Loss: 0.7140946388244629\n","Epoch: 0, Loss: 0.6662746667861938\n","Epoch: 0, Loss: 0.6610315442085266\n","Epoch: 0, Loss: 0.6528325080871582\n","Epoch: 0, Loss: 0.7128132581710815\n","Epoch: 0, Loss: 0.7242415547370911\n","Epoch: 0, Loss: 0.6846714019775391\n","Epoch: 0, Loss: 0.6636401414871216\n","Epoch: 0, Loss: 0.7108516693115234\n","Epoch: 0, Loss: 0.7203643321990967\n","Epoch: 0, Loss: 0.7160587310791016\n","Epoch: 0, Loss: 0.707787275314331\n","Epoch: 0, Loss: 0.6874352693557739\n","Epoch: 0, Loss: 0.6902443766593933\n","Epoch: 0, Loss: 0.6628270149230957\n","Epoch: 0, Loss: 0.7265822887420654\n","Epoch: 0, Loss: 0.6522067189216614\n","Epoch: 0, Loss: 0.6686027646064758\n","Epoch: 0, Loss: 0.6309143304824829\n","Epoch: 0, Loss: 0.7043976187705994\n","Epoch: 0, Loss: 0.6414455771446228\n","Epoch: 0, Loss: 0.6524584889411926\n","Epoch: 0, Loss: 0.6467471122741699\n","Epoch: 0, Loss: 0.7233167290687561\n","Epoch: 0, Loss: 0.7112631797790527\n","Epoch: 0, Loss: 0.6880906820297241\n","Epoch: 0, Loss: 0.6985100507736206\n","Epoch: 0, Loss: 0.7040112018585205\n","Epoch: 0, Loss: 0.6917296648025513\n","Epoch: 0, Loss: 0.7379934191703796\n","Epoch: 0, Loss: 0.7744793891906738\n","Epoch: 0, Loss: 0.7055866718292236\n","Epoch: 0, Loss: 0.732786238193512\n","Epoch: 0, Loss: 0.6491477489471436\n","Epoch: 0, Loss: 0.7229601144790649\n","Epoch: 0, Loss: 0.6888924241065979\n","Epoch: 0, Loss: 0.6141575574874878\n","Epoch: 0, Loss: 0.7213596701622009\n","Epoch: 0, Loss: 0.6923563480377197\n","Epoch: 0, Loss: 0.7612543106079102\n","Epoch: 0, Loss: 0.7150627374649048\n","Epoch: 0, Loss: 0.7272442579269409\n","Epoch: 0, Loss: 0.6804383397102356\n","Epoch: 0, Loss: 0.6795157790184021\n","Epoch: 0, Loss: 0.6952687501907349\n","Epoch: 0, Loss: 0.6659829020500183\n","Epoch: 0, Loss: 0.7007514238357544\n","Epoch: 0, Loss: 0.6894712448120117\n","Epoch: 0, Loss: 0.6918033361434937\n","Epoch: 0, Loss: 0.7516434192657471\n","Epoch: 0, Loss: 0.7325199842453003\n","Epoch: 0, Loss: 0.6718312501907349\n","Epoch: 0, Loss: 0.7148457765579224\n","Epoch: 0, Loss: 0.6981021165847778\n","Epoch: 0, Loss: 0.6680840253829956\n","Epoch: 0, Loss: 0.6727513074874878\n","Epoch: 0, Loss: 0.7117429971694946\n","Epoch: 0, Loss: 0.7018066644668579\n","Epoch: 0, Loss: 0.7525456547737122\n","Epoch: 0, Loss: 0.6885353922843933\n","Epoch: 0, Loss: 0.7227067351341248\n","Epoch: 0, Loss: 0.6892762184143066\n","Epoch: 0, Loss: 0.6370556950569153\n","Epoch: 0, Loss: 0.7159631252288818\n","Epoch: 0, Loss: 0.738673746585846\n","Epoch: 0, Loss: 0.7225127220153809\n","Epoch: 0, Loss: 0.672186553478241\n","Epoch: 0, Loss: 0.684185266494751\n","Epoch: 0, Loss: 0.6897655725479126\n","Epoch: 0, Loss: 0.6947579383850098\n","Epoch: 0, Loss: 0.7112958431243896\n","Epoch: 0, Loss: 0.6966209411621094\n","Epoch: 0, Loss: 0.6878122091293335\n","Epoch: 0, Loss: 0.708099365234375\n","Epoch: 0, Loss: 0.7183496952056885\n","Epoch: 0, Loss: 0.740414023399353\n","Epoch: 0, Loss: 0.6841089725494385\n","Epoch: 0, Loss: 0.6239835023880005\n","Epoch: 0, Loss: 0.6983463168144226\n","Epoch: 0, Loss: 0.7121526598930359\n","Epoch: 0, Loss: 0.6872946619987488\n","Epoch: 0, Loss: 0.702932596206665\n","Epoch: 0, Loss: 0.7044183611869812\n","Epoch: 0, Loss: 0.7554030418395996\n","Epoch: 0, Loss: 0.7667542099952698\n","Epoch: 0, Loss: 0.679279625415802\n","Epoch: 0, Loss: 0.6879961490631104\n","Epoch: 0, Loss: 0.7285887598991394\n","Epoch: 0, Loss: 0.693417489528656\n","Epoch: 0, Loss: 0.6937897205352783\n","Epoch: 0, Loss: 0.7609190344810486\n","Epoch: 0, Loss: 0.6021002531051636\n","Epoch: 0, Loss: 0.6539878845214844\n","Epoch: 0, Loss: 0.8163291811943054\n","Epoch: 0, Loss: 0.762586236000061\n","Epoch: 0, Loss: 0.694580614566803\n","Epoch: 0, Loss: 0.703532338142395\n","Epoch: 0, Loss: 0.7183641791343689\n","Epoch: 0, Loss: 0.7200557589530945\n","Epoch: 0, Loss: 0.6697737574577332\n","Epoch: 0, Loss: 0.6855335235595703\n","Epoch: 0, Loss: 0.6959590315818787\n","Epoch: 0, Loss: 0.6861549019813538\n","Epoch: 0, Loss: 0.7014524340629578\n","Epoch: 0, Loss: 0.7190527319908142\n","Epoch: 0, Loss: 0.7338999509811401\n","Epoch: 0, Loss: 0.7002091407775879\n","Epoch: 0, Loss: 0.7069867849349976\n","Epoch: 0, Loss: 0.7338616251945496\n","Epoch: 0, Loss: 0.6946275234222412\n","Epoch: 0, Loss: 0.7135606408119202\n","Epoch: 0, Loss: 0.6824541091918945\n","Epoch: 0, Loss: 0.6613468527793884\n","Epoch: 0, Loss: 0.6329455375671387\n","Epoch: 0, Loss: 0.6842788457870483\n","Epoch: 0, Loss: 0.6749648451805115\n","Epoch: 0, Loss: 0.6906023621559143\n","Epoch: 0, Loss: 0.7043498754501343\n","Epoch: 0, Loss: 0.6794872283935547\n","Epoch: 0, Loss: 0.6807795166969299\n","Epoch: 0, Loss: 0.7195183634757996\n","Epoch: 0, Loss: 0.6950166821479797\n","Epoch: 0, Loss: 0.6620923280715942\n","Epoch: 0, Loss: 0.7245356440544128\n","Epoch: 0, Loss: 0.7354221343994141\n","Epoch: 0, Loss: 0.7068272829055786\n","Epoch: 0, Loss: 0.7095041275024414\n","Epoch: 0, Loss: 0.7102368474006653\n","Epoch: 0, Loss: 0.7512303590774536\n","Epoch: 0, Loss: 0.70566725730896\n","Epoch: 0, Loss: 0.6450897455215454\n","Epoch: 0, Loss: 0.6761841177940369\n","Epoch: 0, Loss: 0.6846214532852173\n","Epoch: 0, Loss: 0.6981887817382812\n","Epoch: 0, Loss: 0.7063921689987183\n","Epoch: 0, Loss: 0.7138881683349609\n","Epoch: 0, Loss: 0.7294917106628418\n","Epoch: 0, Loss: 0.7318404912948608\n","Epoch: 0, Loss: 0.6995177268981934\n","Epoch: 0, Loss: 0.655386745929718\n","Epoch: 0, Loss: 0.6714330315589905\n","Epoch: 0, Loss: 0.7149216532707214\n","Epoch: 0, Loss: 0.7318118214607239\n","Epoch: 0, Loss: 0.7641504406929016\n","Epoch: 0, Loss: 0.7047395706176758\n","Epoch: 0, Loss: 0.7246203422546387\n","Epoch: 0, Loss: 0.6698851585388184\n","Epoch: 0, Loss: 0.7230280637741089\n","Epoch: 0, Loss: 0.6857805848121643\n","Epoch: 0, Loss: 0.7080302834510803\n","Epoch: 0, Loss: 0.6603018045425415\n","Epoch: 0, Loss: 0.7256484031677246\n","Epoch: 0, Loss: 0.677736759185791\n","Epoch: 0, Loss: 0.7300041913986206\n","Epoch: 0, Loss: 0.6973424553871155\n","Epoch: 0, Loss: 0.7314215302467346\n","Epoch: 0, Loss: 0.6789774894714355\n","Epoch: 0, Loss: 0.68937748670578\n","Epoch: 0, Loss: 0.6755333542823792\n","Epoch: 0, Loss: 0.7480143904685974\n","Epoch: 0, Loss: 0.6637256741523743\n","Epoch: 0, Loss: 0.6617131233215332\n","Epoch: 0, Loss: 0.7242748141288757\n","Epoch: 0, Loss: 0.6907857656478882\n","Epoch: 0, Loss: 0.676856279373169\n","Epoch: 0, Loss: 0.6979151368141174\n","Epoch: 0, Loss: 0.6982567310333252\n","Epoch: 0, Loss: 0.6763473749160767\n","Epoch: 0, Loss: 0.7149885892868042\n","Epoch: 0, Loss: 0.6891250610351562\n","Epoch: 0, Loss: 0.6856375336647034\n","Epoch: 0, Loss: 0.6826908588409424\n","Epoch: 0, Loss: 0.7063374519348145\n","Epoch: 0, Loss: 0.7336608171463013\n","Epoch: 0, Loss: 0.7016266584396362\n","Epoch: 0, Loss: 0.678730845451355\n","Epoch: 0, Loss: 0.7357107996940613\n","Epoch: 0, Loss: 0.6105363368988037\n","Epoch: 0, Loss: 0.676332950592041\n","Epoch: 0, Loss: 0.6944410800933838\n","Epoch: 0, Loss: 0.6256769895553589\n","Epoch: 0, Loss: 0.6988131999969482\n","Epoch: 0, Loss: 0.6796348690986633\n","Epoch: 0, Loss: 0.687956690788269\n","Epoch: 0, Loss: 0.6905127763748169\n","Epoch: 0, Loss: 0.5881004333496094\n","Epoch: 0, Loss: 0.6492700576782227\n","Epoch: 0, Loss: 0.7038082480430603\n","Epoch: 0, Loss: 0.8190822005271912\n","Epoch: 0, Loss: 0.7379740476608276\n","Epoch: 0, Loss: 0.6068834066390991\n","Epoch: 0, Loss: 0.6040312051773071\n","Epoch: 0, Loss: 0.5915095210075378\n","Epoch: 0, Loss: 0.5991678237915039\n","Epoch: 0, Loss: 0.751329779624939\n","Epoch: 0, Loss: 0.5776925086975098\n","Epoch: 0, Loss: 0.6316500902175903\n","Epoch: 0, Loss: 0.6219657063484192\n","Epoch: 0, Loss: 0.7936135530471802\n","Epoch: 0, Loss: 0.6283977031707764\n","Epoch: 0, Loss: 0.7565091848373413\n","Epoch: 0, Loss: 0.7278763651847839\n","Epoch: 0, Loss: 0.6635857820510864\n","Epoch: 0, Loss: 0.7435178160667419\n","Epoch: 0, Loss: 0.722042441368103\n","Epoch: 0, Loss: 0.743419349193573\n","Epoch: 0, Loss: 0.6805856227874756\n","Epoch: 0, Loss: 0.6954391598701477\n","Epoch: 0, Loss: 0.6551289558410645\n","Epoch: 0, Loss: 0.7973369359970093\n","Epoch: 0, Loss: 0.8519127368927002\n","Epoch: 0, Loss: 0.8071804046630859\n","Epoch: 0, Loss: 0.655079185962677\n","Epoch: 0, Loss: 0.7571731805801392\n","Epoch: 0, Loss: 0.7751922011375427\n","Epoch: 0, Loss: 0.6434789299964905\n","Epoch: 0, Loss: 0.6976760625839233\n","Epoch: 0, Loss: 0.7425302863121033\n","Epoch: 0, Loss: 0.6944888830184937\n","Epoch: 0, Loss: 0.7453256845474243\n","Epoch: 0, Loss: 0.6505998373031616\n","Epoch: 0, Loss: 0.6738388538360596\n","Epoch: 0, Loss: 0.7384519577026367\n","Epoch: 0, Loss: 0.6812748312950134\n","Epoch: 0, Loss: 0.6848641633987427\n","Epoch: 0, Loss: 0.6756196022033691\n","Epoch: 0, Loss: 0.5746363401412964\n","Epoch: 0, Loss: 0.6190618872642517\n","Epoch: 0, Loss: 0.8072510361671448\n","Epoch: 0, Loss: 0.7267666459083557\n","Epoch: 0, Loss: 0.726890504360199\n","Epoch: 0, Loss: 0.6709172129631042\n","Epoch: 0, Loss: 0.7857283353805542\n","Epoch: 0, Loss: 0.7158217430114746\n","Epoch: 0, Loss: 0.7466822862625122\n","Epoch: 0, Loss: 0.6797829866409302\n","Epoch: 0, Loss: 0.6923590898513794\n","Epoch: 0, Loss: 0.7558922171592712\n","Epoch: 0, Loss: 0.6082712411880493\n","Epoch: 0, Loss: 0.654563307762146\n","Epoch: 0, Loss: 0.7619149684906006\n","Epoch: 0, Loss: 0.6566760540008545\n","Epoch: 0, Loss: 0.6175808906555176\n","Epoch: 0, Loss: 0.7346057295799255\n","Epoch: 0, Loss: 0.7424176931381226\n","Epoch: 0, Loss: 0.7185298800468445\n","Epoch: 0, Loss: 0.6734161376953125\n","Epoch: 0, Loss: 0.6541496515274048\n","Epoch: 0, Loss: 0.7108749151229858\n","Epoch: 0, Loss: 0.7006882429122925\n","Epoch: 0, Loss: 0.6672195196151733\n","Epoch: 0, Loss: 0.7245820760726929\n","Epoch: 0, Loss: 0.7032344937324524\n","Epoch: 0, Loss: 0.7210161685943604\n","Epoch: 0, Loss: 0.715861439704895\n","Epoch: 0, Loss: 0.6960285902023315\n","Epoch: 0, Loss: 0.7256994843482971\n","Epoch: 0, Loss: 0.6665031909942627\n","Epoch: 0, Loss: 0.6498291492462158\n","Epoch: 0, Loss: 0.653804361820221\n","Epoch: 0, Loss: 0.6292067170143127\n","Epoch: 0, Loss: 0.7135705351829529\n","Epoch: 0, Loss: 0.7203052043914795\n","Epoch: 0, Loss: 0.7754786610603333\n","Epoch: 0, Loss: 0.7115382552146912\n","Epoch: 0, Loss: 0.724159300327301\n","Epoch: 0, Loss: 0.6847783923149109\n","Epoch: 0, Loss: 0.6833935976028442\n","Epoch: 0, Loss: 0.7001336812973022\n","Epoch: 0, Loss: 0.7188175916671753\n","Epoch: 0, Loss: 0.7677701711654663\n","Epoch: 0, Loss: 0.7135013937950134\n","Epoch: 0, Loss: 0.6847982406616211\n","Epoch: 0, Loss: 0.7680144309997559\n","Epoch: 0, Loss: 0.7105405926704407\n","Epoch: 0, Loss: 0.713010847568512\n","Epoch: 0, Loss: 0.7197727560997009\n","Epoch: 0, Loss: 0.6925636529922485\n","Epoch: 0, Loss: 0.6624512672424316\n","Epoch: 0, Loss: 0.6447630524635315\n","Epoch: 0, Loss: 0.6940414905548096\n","Epoch: 0, Loss: 0.716218888759613\n","Epoch: 0, Loss: 0.6610445380210876\n","Epoch: 0, Loss: 0.7540810108184814\n","Epoch: 0, Loss: 0.6787562370300293\n","Epoch: 0, Loss: 0.6647581458091736\n","Epoch: 0, Loss: 0.698567807674408\n","Epoch: 0, Loss: 0.6805778741836548\n","Epoch: 0, Loss: 0.6879475712776184\n","Epoch: 0, Loss: 0.6941589713096619\n","Epoch: 0, Loss: 0.6714071035385132\n","Epoch: 0, Loss: 0.6828779578208923\n","Epoch: 0, Loss: 0.7451498508453369\n","Epoch: 0, Loss: 0.6933443546295166\n","Epoch: 0, Loss: 0.6698830127716064\n","Epoch: 0, Loss: 0.6604148149490356\n","Epoch: 0, Loss: 0.6502698659896851\n","Epoch: 0, Loss: 0.6938282251358032\n","Epoch: 0, Loss: 0.7307559251785278\n","Epoch: 0, Loss: 0.6779516935348511\n","Epoch: 0, Loss: 0.673549473285675\n","Epoch: 0, Loss: 0.7271443605422974\n","Epoch: 0, Loss: 0.6675444841384888\n","Epoch: 0, Loss: 0.6633931398391724\n","Epoch: 0, Loss: 0.6677380204200745\n","Epoch: 0, Loss: 0.6202089786529541\n","Epoch: 0, Loss: 0.7577444911003113\n","Epoch: 0, Loss: 0.7629722356796265\n","Epoch: 0, Loss: 0.6868463158607483\n","Epoch: 0, Loss: 0.6741390824317932\n","Epoch: 0, Loss: 0.6983404159545898\n","Epoch: 0, Loss: 0.7163926362991333\n","Epoch: 0, Loss: 0.6990610361099243\n","Epoch: 0, Loss: 0.654242992401123\n","Epoch: 0, Loss: 0.6843618750572205\n","Epoch: 0, Loss: 0.7563778758049011\n","Epoch: 0, Loss: 0.7134161591529846\n","Epoch: 0, Loss: 0.7757984399795532\n","Epoch: 0, Loss: 0.6802713871002197\n","Epoch: 0, Loss: 0.6888163685798645\n","Epoch: 0, Loss: 0.6438006162643433\n","Epoch: 0, Loss: 0.6792199611663818\n","Epoch: 0, Loss: 0.6327729225158691\n","Epoch: 0, Loss: 0.6779955625534058\n","Epoch: 0, Loss: 0.7371838092803955\n","Epoch: 0, Loss: 0.6186463832855225\n","Epoch: 0, Loss: 0.6765010356903076\n","Epoch: 0, Loss: 0.7305726408958435\n","Epoch: 0, Loss: 0.6976656317710876\n","Epoch: 0, Loss: 0.7090121507644653\n","Epoch: 0, Loss: 0.7100600004196167\n","Epoch: 0, Loss: 0.7081772089004517\n","Epoch: 0, Loss: 0.6784738302230835\n","Epoch: 0, Loss: 0.6303579211235046\n","Epoch: 0, Loss: 0.7232522964477539\n","Epoch: 0, Loss: 0.6571199893951416\n","Epoch: 0, Loss: 0.653169572353363\n","Epoch: 0, Loss: 0.6837303042411804\n","Epoch: 0, Loss: 0.6496862769126892\n","Epoch: 0, Loss: 0.6760239005088806\n","Epoch: 0, Loss: 0.6987788081169128\n","Epoch: 0, Loss: 0.727834165096283\n","Epoch: 0, Loss: 0.6282901167869568\n","Epoch: 0, Loss: 0.7401599287986755\n","Epoch: 0, Loss: 0.7328754663467407\n","Epoch: 0, Loss: 0.6403101086616516\n","Epoch: 0, Loss: 0.807350754737854\n","Epoch: 0, Loss: 0.7333383560180664\n","Epoch: 0, Loss: 0.7855502367019653\n","Epoch: 0, Loss: 0.6929585933685303\n","Epoch: 0, Loss: 0.6858866810798645\n","Epoch: 0, Loss: 0.6662245988845825\n","Epoch: 0, Loss: 0.6306449174880981\n","Epoch: 0, Loss: 0.6926470994949341\n","Epoch: 0, Loss: 0.7303792238235474\n","Epoch: 0, Loss: 0.6715072989463806\n","Epoch: 0, Loss: 0.7379850149154663\n","Epoch: 0, Loss: 0.676150381565094\n","Epoch: 0, Loss: 0.67347252368927\n","Epoch: 0, Loss: 0.6658847332000732\n","Epoch: 0, Loss: 0.6915572285652161\n","Epoch: 0, Loss: 0.6867395043373108\n","Epoch: 0, Loss: 0.7249099612236023\n","Epoch: 0, Loss: 0.7194958925247192\n","Epoch: 0, Loss: 0.7204472422599792\n","Epoch: 0, Loss: 0.6408476233482361\n","Epoch: 0, Loss: 0.7196376919746399\n","Epoch: 0, Loss: 0.6581503748893738\n","Epoch: 0, Loss: 0.721067488193512\n","Epoch: 0, Loss: 0.7011392712593079\n","Epoch: 0, Loss: 0.6921218633651733\n","Epoch: 0, Loss: 0.6630544662475586\n","Epoch: 0, Loss: 0.7339427471160889\n","Epoch: 0, Loss: 0.6661170125007629\n","Epoch: 0, Loss: 0.6594550609588623\n","Epoch: 0, Loss: 0.6998946666717529\n","Epoch: 0, Loss: 0.7255301475524902\n","Epoch: 0, Loss: 0.7023770213127136\n","Epoch: 0, Loss: 0.6449663043022156\n","Epoch: 0, Loss: 0.6553003787994385\n","Epoch: 0, Loss: 0.6727802753448486\n","Epoch: 0, Loss: 0.680497407913208\n","Epoch: 0, Loss: 0.631323516368866\n","Epoch: 0, Loss: 0.6919576525688171\n","Epoch: 0, Loss: 0.8051869869232178\n","Epoch: 0, Loss: 0.7648829817771912\n","Epoch: 0, Loss: 0.64530348777771\n","Epoch: 0, Loss: 0.6603939533233643\n","Epoch: 0, Loss: 0.7772446274757385\n","Epoch: 0, Loss: 0.6755039691925049\n","Epoch: 0, Loss: 0.698029100894928\n","Epoch: 0, Loss: 0.6328350901603699\n","Epoch: 0, Loss: 0.7220554351806641\n","Epoch: 0, Loss: 0.7988607883453369\n","Epoch: 0, Loss: 0.6506555676460266\n","Epoch: 0, Loss: 0.725798487663269\n","Epoch: 0, Loss: 0.6936632990837097\n","Epoch: 0, Loss: 0.6262142658233643\n","Epoch: 0, Loss: 0.6792160272598267\n","Epoch: 0, Loss: 0.6746924519538879\n","Epoch: 0, Loss: 0.6729928255081177\n","Epoch: 0, Loss: 0.6633004546165466\n","Epoch: 0, Loss: 0.6843729615211487\n","Epoch: 0, Loss: 0.7428792119026184\n","Epoch: 0, Loss: 0.6458397507667542\n","Epoch: 0, Loss: 0.7258366942405701\n","Epoch: 0, Loss: 0.7038277387619019\n","Epoch: 0, Loss: 0.7141753435134888\n","Epoch: 0, Loss: 0.6877462863922119\n","Epoch: 0, Loss: 0.6778503060340881\n","Epoch: 0, Loss: 0.6698464155197144\n","Epoch: 0, Loss: 0.6922754049301147\n","Epoch: 0, Loss: 0.739338755607605\n","Epoch: 0, Loss: 0.7583023905754089\n","Epoch: 0, Loss: 0.6772522926330566\n","Epoch: 0, Loss: 0.6801505088806152\n","Epoch: 0, Loss: 0.740345299243927\n","Epoch: 0, Loss: 0.6990085244178772\n","Epoch: 0, Loss: 0.6718979477882385\n","Epoch: 0, Loss: 0.7667629718780518\n","Epoch: 0, Loss: 0.6503065228462219\n","Epoch: 0, Loss: 0.7541327476501465\n","Epoch: 0, Loss: 0.690071702003479\n","Epoch: 0, Loss: 0.684365451335907\n","Epoch: 0, Loss: 0.7546136975288391\n","Epoch: 0, Loss: 0.7545942068099976\n","Epoch: 0, Loss: 0.8081494569778442\n","Epoch: 0, Loss: 0.7452635765075684\n","Epoch: 0, Loss: 0.6662566661834717\n","Epoch: 0, Loss: 0.6943113803863525\n","Epoch: 0, Loss: 0.6675006151199341\n","Epoch: 0, Loss: 0.7036198377609253\n","Epoch: 0, Loss: 0.7541170716285706\n","Epoch: 0, Loss: 0.7202155590057373\n","Epoch: 0, Loss: 0.6827961802482605\n","Epoch: 0, Loss: 0.6701080203056335\n","Epoch: 0, Loss: 0.6445483565330505\n","Epoch: 0, Loss: 0.6852773427963257\n","Epoch: 0, Loss: 0.6715692281723022\n","Epoch: 0, Loss: 0.6416001319885254\n","Epoch: 0, Loss: 0.6835615634918213\n","Epoch: 0, Loss: 0.7930521965026855\n","Epoch: 0, Loss: 0.64412522315979\n","Epoch: 0, Loss: 0.6979071497917175\n","Epoch: 0, Loss: 0.7107438445091248\n","Epoch: 0, Loss: 0.7493793368339539\n","Epoch: 0, Loss: 0.6454407572746277\n","Epoch: 0, Loss: 0.7191078066825867\n","Epoch: 0, Loss: 0.7061208486557007\n","Epoch: 0, Loss: 0.6737549304962158\n","Epoch: 0, Loss: 0.7191610336303711\n","Epoch: 0, Loss: 0.7686972618103027\n","Epoch: 0, Loss: 0.7265321016311646\n","Epoch: 0, Loss: 0.7145759463310242\n","Epoch: 0, Loss: 0.6543304920196533\n","Epoch: 0, Loss: 0.683928906917572\n","Epoch: 0, Loss: 0.676260232925415\n","Epoch: 0, Loss: 0.7630047798156738\n","Epoch: 0, Loss: 0.6787624359130859\n","Epoch: 0, Loss: 0.7355991005897522\n","Epoch: 0, Loss: 0.680223822593689\n","Epoch: 0, Loss: 0.7361331582069397\n","Epoch: 1, Loss: 0.6575770378112793\n","Epoch: 1, Loss: 0.6589071750640869\n","Epoch: 1, Loss: 0.6760993599891663\n","Epoch: 1, Loss: 0.6821007132530212\n","Epoch: 1, Loss: 0.7193446755409241\n","Epoch: 1, Loss: 0.6203646659851074\n","Epoch: 1, Loss: 0.6889654397964478\n","Epoch: 1, Loss: 0.7534286379814148\n","Epoch: 1, Loss: 0.6700162887573242\n","Epoch: 1, Loss: 0.7013357877731323\n","Epoch: 1, Loss: 0.6527919173240662\n","Epoch: 1, Loss: 0.7392476797103882\n","Epoch: 1, Loss: 0.6954394578933716\n","Epoch: 1, Loss: 0.7043876051902771\n","Epoch: 1, Loss: 0.6853296160697937\n","Epoch: 1, Loss: 0.7259858250617981\n","Epoch: 1, Loss: 0.7033557891845703\n","Epoch: 1, Loss: 0.705902099609375\n","Epoch: 1, Loss: 0.7168123126029968\n","Epoch: 1, Loss: 0.6703447103500366\n","Epoch: 1, Loss: 0.6918554306030273\n","Epoch: 1, Loss: 0.6857196092605591\n","Epoch: 1, Loss: 0.6949995160102844\n","Epoch: 1, Loss: 0.671206533908844\n","Epoch: 1, Loss: 0.7469956278800964\n","Epoch: 1, Loss: 0.6943807005882263\n","Epoch: 1, Loss: 0.694894015789032\n","Epoch: 1, Loss: 0.690822958946228\n","Epoch: 1, Loss: 0.6883672475814819\n","Epoch: 1, Loss: 0.6577824950218201\n","Epoch: 1, Loss: 0.6660792231559753\n","Epoch: 1, Loss: 0.6989172697067261\n","Epoch: 1, Loss: 0.6758068799972534\n","Epoch: 1, Loss: 0.683847963809967\n","Epoch: 1, Loss: 0.7161037921905518\n","Epoch: 1, Loss: 0.7124665975570679\n","Epoch: 1, Loss: 0.7165502905845642\n","Epoch: 1, Loss: 0.6806266903877258\n","Epoch: 1, Loss: 0.6376069784164429\n","Epoch: 1, Loss: 0.7317250967025757\n","Epoch: 1, Loss: 0.6598461270332336\n","Epoch: 1, Loss: 0.6725612878799438\n","Epoch: 1, Loss: 0.7116953134536743\n","Epoch: 1, Loss: 0.709948718547821\n","Epoch: 1, Loss: 0.6416031718254089\n","Epoch: 1, Loss: 0.6973880529403687\n","Epoch: 1, Loss: 0.6798650622367859\n","Epoch: 1, Loss: 0.6091245412826538\n","Epoch: 1, Loss: 0.764143705368042\n","Epoch: 1, Loss: 0.6355419158935547\n","Epoch: 1, Loss: 0.6730566024780273\n","Epoch: 1, Loss: 0.6383004188537598\n","Epoch: 1, Loss: 0.7576894164085388\n","Epoch: 1, Loss: 0.7444068789482117\n","Epoch: 1, Loss: 0.6916549205780029\n","Epoch: 1, Loss: 0.718472957611084\n","Epoch: 1, Loss: 0.6719849705696106\n","Epoch: 1, Loss: 0.6949016451835632\n","Epoch: 1, Loss: 0.65253746509552\n","Epoch: 1, Loss: 0.6514701247215271\n","Epoch: 1, Loss: 0.7094694375991821\n","Epoch: 1, Loss: 0.7321305274963379\n","Epoch: 1, Loss: 0.7746807932853699\n","Epoch: 1, Loss: 0.6870758533477783\n","Epoch: 1, Loss: 0.6659555435180664\n","Epoch: 1, Loss: 0.6513631343841553\n","Epoch: 1, Loss: 0.6189146637916565\n","Epoch: 1, Loss: 0.8312972784042358\n","Epoch: 1, Loss: 0.6454554796218872\n","Epoch: 1, Loss: 0.6560673117637634\n","Epoch: 1, Loss: 0.6701632738113403\n","Epoch: 1, Loss: 0.8480180501937866\n","Epoch: 1, Loss: 0.7830562591552734\n","Epoch: 1, Loss: 0.6603305339813232\n","Epoch: 1, Loss: 0.6440135836601257\n","Epoch: 1, Loss: 0.7309502363204956\n","Epoch: 1, Loss: 0.689760148525238\n","Epoch: 1, Loss: 0.70415198802948\n","Epoch: 1, Loss: 0.6211478114128113\n","Epoch: 1, Loss: 0.7310770153999329\n","Epoch: 1, Loss: 0.6938016414642334\n","Epoch: 1, Loss: 0.6487550735473633\n","Epoch: 1, Loss: 0.801155149936676\n","Epoch: 1, Loss: 0.7304164171218872\n","Epoch: 1, Loss: 0.7281261682510376\n","Epoch: 1, Loss: 0.734959602355957\n","Epoch: 1, Loss: 0.7278156280517578\n","Epoch: 1, Loss: 0.66623455286026\n","Epoch: 1, Loss: 0.6777665615081787\n","Epoch: 1, Loss: 0.7131106853485107\n","Epoch: 1, Loss: 0.6946424245834351\n","Epoch: 1, Loss: 0.6590042114257812\n","Epoch: 1, Loss: 0.6165342926979065\n","Epoch: 1, Loss: 0.72745281457901\n","Epoch: 1, Loss: 0.7616625428199768\n","Epoch: 1, Loss: 0.7102380394935608\n","Epoch: 1, Loss: 0.6845196485519409\n","Epoch: 1, Loss: 0.6167154312133789\n","Epoch: 1, Loss: 0.6668774485588074\n","Epoch: 1, Loss: 0.6815476417541504\n","Epoch: 1, Loss: 0.6816253066062927\n","Epoch: 1, Loss: 0.7271859645843506\n","Epoch: 1, Loss: 0.7432345151901245\n","Epoch: 1, Loss: 0.556615948677063\n","Epoch: 1, Loss: 0.6278836131095886\n","Epoch: 1, Loss: 0.7021487951278687\n","Epoch: 1, Loss: 0.7682662010192871\n","Epoch: 1, Loss: 0.6298427581787109\n","Epoch: 1, Loss: 0.6621913909912109\n","Epoch: 1, Loss: 0.5765912532806396\n","Epoch: 1, Loss: 0.7046624422073364\n","Epoch: 1, Loss: 0.7054652571678162\n","Epoch: 1, Loss: 0.8248612284660339\n","Epoch: 1, Loss: 0.6678904891014099\n","Epoch: 1, Loss: 0.6634561419487\n","Epoch: 1, Loss: 0.6139087677001953\n","Epoch: 1, Loss: 0.763140857219696\n","Epoch: 1, Loss: 0.7205350399017334\n","Epoch: 1, Loss: 0.62891685962677\n","Epoch: 1, Loss: 0.6107581257820129\n","Epoch: 1, Loss: 0.7502604722976685\n","Epoch: 1, Loss: 0.5911300182342529\n","Epoch: 1, Loss: 0.7529699206352234\n","Epoch: 1, Loss: 0.6377131938934326\n","Epoch: 1, Loss: 0.6652928590774536\n","Epoch: 1, Loss: 0.7209150195121765\n","Epoch: 1, Loss: 0.7814890146255493\n","Epoch: 1, Loss: 0.740372359752655\n","Epoch: 1, Loss: 0.6386159062385559\n","Epoch: 1, Loss: 0.7583221197128296\n","Epoch: 1, Loss: 0.7121465802192688\n","Epoch: 1, Loss: 0.7020113468170166\n","Epoch: 1, Loss: 0.7410352826118469\n","Epoch: 1, Loss: 0.7133041024208069\n","Epoch: 1, Loss: 0.6646188497543335\n","Epoch: 1, Loss: 0.7212649583816528\n","Epoch: 1, Loss: 0.6761799454689026\n","Epoch: 1, Loss: 0.7059604525566101\n","Epoch: 1, Loss: 0.7152489423751831\n","Epoch: 1, Loss: 0.6801128387451172\n","Epoch: 1, Loss: 0.7456639409065247\n","Epoch: 1, Loss: 0.7660347819328308\n","Epoch: 1, Loss: 0.7288879752159119\n","Epoch: 1, Loss: 0.7368337512016296\n","Epoch: 1, Loss: 0.6838884353637695\n","Epoch: 1, Loss: 0.7005940079689026\n","Epoch: 1, Loss: 0.7027785181999207\n","Epoch: 1, Loss: 0.617993950843811\n","Epoch: 1, Loss: 0.6490797996520996\n","Epoch: 1, Loss: 0.6687664985656738\n","Epoch: 1, Loss: 0.7051973938941956\n","Epoch: 1, Loss: 0.7701354026794434\n","Epoch: 1, Loss: 0.6856313347816467\n","Epoch: 1, Loss: 0.7065936923027039\n","Epoch: 1, Loss: 0.6504726409912109\n","Epoch: 1, Loss: 0.7191299200057983\n","Epoch: 1, Loss: 0.7281234264373779\n","Epoch: 1, Loss: 0.7027781009674072\n","Epoch: 1, Loss: 0.7672579884529114\n","Epoch: 1, Loss: 0.6563034057617188\n","Epoch: 1, Loss: 0.7720875144004822\n","Epoch: 1, Loss: 0.6481618285179138\n","Epoch: 1, Loss: 0.7166913151741028\n","Epoch: 1, Loss: 0.6538362503051758\n","Epoch: 1, Loss: 0.752474844455719\n","Epoch: 1, Loss: 0.708423376083374\n","Epoch: 1, Loss: 0.6840602159500122\n","Epoch: 1, Loss: 0.7271449565887451\n","Epoch: 1, Loss: 0.7360677719116211\n","Epoch: 1, Loss: 0.6924523115158081\n","Epoch: 1, Loss: 0.715848445892334\n","Epoch: 1, Loss: 0.6885011792182922\n","Epoch: 1, Loss: 0.6650780439376831\n","Epoch: 1, Loss: 0.7337064743041992\n","Epoch: 1, Loss: 0.6794323325157166\n","Epoch: 1, Loss: 0.7551508545875549\n","Epoch: 1, Loss: 0.6534044146537781\n","Epoch: 1, Loss: 0.7036029696464539\n","Epoch: 1, Loss: 0.7311381101608276\n","Epoch: 1, Loss: 0.6472095847129822\n","Epoch: 1, Loss: 0.6925317645072937\n","Epoch: 1, Loss: 0.6887151598930359\n","Epoch: 1, Loss: 0.7418681383132935\n","Epoch: 1, Loss: 0.7912397384643555\n","Epoch: 1, Loss: 0.7020665407180786\n","Epoch: 1, Loss: 0.6720755100250244\n","Epoch: 1, Loss: 0.6776213645935059\n","Epoch: 1, Loss: 0.660993754863739\n","Epoch: 1, Loss: 0.6807835698127747\n","Epoch: 1, Loss: 0.6885417699813843\n","Epoch: 1, Loss: 0.6617429852485657\n","Epoch: 1, Loss: 0.7156479358673096\n","Epoch: 1, Loss: 0.6845964193344116\n","Epoch: 1, Loss: 0.7396060228347778\n","Epoch: 1, Loss: 0.7007752060890198\n","Epoch: 1, Loss: 0.7153949737548828\n","Epoch: 1, Loss: 0.7164620757102966\n","Epoch: 1, Loss: 0.7062962055206299\n","Epoch: 1, Loss: 0.6699810028076172\n","Epoch: 1, Loss: 0.6766007542610168\n","Epoch: 1, Loss: 0.7432794570922852\n","Epoch: 1, Loss: 0.7229395508766174\n","Epoch: 1, Loss: 0.6899610161781311\n","Epoch: 1, Loss: 0.659694492816925\n","Epoch: 1, Loss: 0.7177783250808716\n","Epoch: 1, Loss: 0.7151094079017639\n","Epoch: 1, Loss: 0.7096725702285767\n","Epoch: 1, Loss: 0.6781567335128784\n","Epoch: 1, Loss: 0.6877591013908386\n","Epoch: 1, Loss: 0.7099349498748779\n","Epoch: 1, Loss: 0.7577419877052307\n","Epoch: 1, Loss: 0.6646566987037659\n","Epoch: 1, Loss: 0.7077316045761108\n","Epoch: 1, Loss: 0.6851573586463928\n","Epoch: 1, Loss: 0.6773999929428101\n","Epoch: 1, Loss: 0.7164257764816284\n","Epoch: 1, Loss: 0.6891096830368042\n","Epoch: 1, Loss: 0.6930187940597534\n","Epoch: 1, Loss: 0.6793085932731628\n","Epoch: 1, Loss: 0.6514010429382324\n","Epoch: 1, Loss: 0.7516489028930664\n","Epoch: 1, Loss: 0.7216466665267944\n","Epoch: 1, Loss: 0.7086132168769836\n","Epoch: 1, Loss: 0.6180745363235474\n","Epoch: 1, Loss: 0.6827242970466614\n","Epoch: 1, Loss: 0.6884248852729797\n","Epoch: 1, Loss: 0.6922765374183655\n","Epoch: 1, Loss: 0.713952898979187\n","Epoch: 1, Loss: 0.7269019484519958\n","Epoch: 1, Loss: 0.7348904609680176\n","Epoch: 1, Loss: 0.662887692451477\n","Epoch: 1, Loss: 0.7073482275009155\n","Epoch: 1, Loss: 0.7379027009010315\n","Epoch: 1, Loss: 0.6623640656471252\n","Epoch: 1, Loss: 0.6567695140838623\n","Epoch: 1, Loss: 0.7094765901565552\n","Epoch: 1, Loss: 0.6898083686828613\n","Epoch: 1, Loss: 0.7780690789222717\n","Epoch: 1, Loss: 0.6927005052566528\n","Epoch: 1, Loss: 0.700380265712738\n","Epoch: 1, Loss: 0.6658152341842651\n","Epoch: 1, Loss: 0.6803305745124817\n","Epoch: 1, Loss: 0.6800788640975952\n","Epoch: 1, Loss: 0.6872167587280273\n","Epoch: 1, Loss: 0.7121577262878418\n","Epoch: 1, Loss: 0.7143574953079224\n","Epoch: 1, Loss: 0.6570606827735901\n","Epoch: 1, Loss: 0.6985467076301575\n","Epoch: 1, Loss: 0.6957212090492249\n","Epoch: 1, Loss: 0.6952013969421387\n","Epoch: 1, Loss: 0.7182719707489014\n","Epoch: 1, Loss: 0.7306293249130249\n","Epoch: 1, Loss: 0.6773090362548828\n","Epoch: 1, Loss: 0.7346986532211304\n","Epoch: 1, Loss: 0.7311930656433105\n","Epoch: 1, Loss: 0.7277287244796753\n","Epoch: 1, Loss: 0.6848702430725098\n","Epoch: 1, Loss: 0.7148274779319763\n","Epoch: 1, Loss: 0.6889867782592773\n","Epoch: 1, Loss: 0.6994264125823975\n","Epoch: 1, Loss: 0.7149339318275452\n","Epoch: 1, Loss: 0.6919317841529846\n","Epoch: 1, Loss: 0.7397416830062866\n","Epoch: 1, Loss: 0.6926302909851074\n","Epoch: 1, Loss: 0.6592013239860535\n","Epoch: 1, Loss: 0.6732456088066101\n","Epoch: 1, Loss: 0.6354616284370422\n","Epoch: 1, Loss: 0.6934431791305542\n","Epoch: 1, Loss: 0.6510988473892212\n","Epoch: 1, Loss: 0.7838753461837769\n","Epoch: 1, Loss: 0.7242683172225952\n","Epoch: 1, Loss: 0.6341655254364014\n","Epoch: 1, Loss: 0.6202971935272217\n","Epoch: 1, Loss: 0.6363381743431091\n","Epoch: 1, Loss: 0.7186641693115234\n","Epoch: 1, Loss: 0.725446343421936\n","Epoch: 1, Loss: 0.7566104531288147\n","Epoch: 1, Loss: 0.7276555299758911\n","Epoch: 1, Loss: 0.6186696887016296\n","Epoch: 1, Loss: 0.6776745915412903\n","Epoch: 1, Loss: 0.6209564208984375\n","Epoch: 1, Loss: 0.7476947903633118\n","Epoch: 1, Loss: 0.6316007375717163\n","Epoch: 1, Loss: 0.7330173850059509\n","Epoch: 1, Loss: 0.6499108672142029\n","Epoch: 1, Loss: 0.5841425657272339\n","Epoch: 1, Loss: 0.8308777213096619\n","Epoch: 1, Loss: 0.7124071717262268\n","Epoch: 1, Loss: 0.7411361336708069\n","Epoch: 1, Loss: 0.739714503288269\n","Epoch: 1, Loss: 0.6165330410003662\n","Epoch: 1, Loss: 0.7625596523284912\n","Epoch: 1, Loss: 0.7272765040397644\n","Epoch: 1, Loss: 0.6979609131813049\n","Epoch: 1, Loss: 0.6875709295272827\n","Epoch: 1, Loss: 0.8280685544013977\n","Epoch: 1, Loss: 0.7183802723884583\n","Epoch: 1, Loss: 0.7233693599700928\n","Epoch: 1, Loss: 0.692970871925354\n","Epoch: 1, Loss: 0.6868676543235779\n","Epoch: 1, Loss: 0.7147099375724792\n","Epoch: 1, Loss: 0.7006460428237915\n","Epoch: 1, Loss: 0.7475152611732483\n","Epoch: 1, Loss: 0.6721799373626709\n","Epoch: 1, Loss: 0.6806201338768005\n","Epoch: 1, Loss: 0.6552566289901733\n","Epoch: 1, Loss: 0.7004514336585999\n","Epoch: 1, Loss: 0.7542814016342163\n","Epoch: 1, Loss: 0.68023282289505\n","Epoch: 1, Loss: 0.7031205892562866\n","Epoch: 1, Loss: 0.7241753339767456\n","Epoch: 1, Loss: 0.637048602104187\n","Epoch: 1, Loss: 0.6853035688400269\n","Epoch: 1, Loss: 0.6814387440681458\n","Epoch: 1, Loss: 0.6776623129844666\n","Epoch: 1, Loss: 0.7355590462684631\n","Epoch: 1, Loss: 0.6794376373291016\n","Epoch: 1, Loss: 0.713276207447052\n","Epoch: 1, Loss: 0.6940339207649231\n","Epoch: 1, Loss: 0.7147505283355713\n","Epoch: 1, Loss: 0.681381344795227\n","Epoch: 1, Loss: 0.6651822924613953\n","Epoch: 1, Loss: 0.6324145793914795\n","Epoch: 1, Loss: 0.672168493270874\n","Epoch: 1, Loss: 0.6747604608535767\n","Epoch: 1, Loss: 0.6580889225006104\n","Epoch: 1, Loss: 0.6957496404647827\n","Epoch: 1, Loss: 0.6896824836730957\n","Epoch: 1, Loss: 0.6406755447387695\n","Epoch: 1, Loss: 0.6880058646202087\n","Epoch: 1, Loss: 0.6727603673934937\n","Epoch: 1, Loss: 0.6015616655349731\n","Epoch: 1, Loss: 0.6696079969406128\n","Epoch: 1, Loss: 0.6562093496322632\n","Epoch: 1, Loss: 0.6837319135665894\n","Epoch: 1, Loss: 0.601945161819458\n","Epoch: 1, Loss: 0.6884970664978027\n","Epoch: 1, Loss: 0.6215518116950989\n","Epoch: 1, Loss: 0.6701965928077698\n","Epoch: 1, Loss: 0.7775979042053223\n","Epoch: 1, Loss: 0.7869381904602051\n","Epoch: 1, Loss: 0.6553200483322144\n","Epoch: 1, Loss: 0.7406101822853088\n","Epoch: 1, Loss: 0.5463318824768066\n","Epoch: 1, Loss: 0.6634072065353394\n","Epoch: 1, Loss: 0.7344396114349365\n","Epoch: 1, Loss: 0.6934151649475098\n","Epoch: 1, Loss: 0.6937050819396973\n","Epoch: 1, Loss: 0.7271933555603027\n","Epoch: 1, Loss: 0.7319073677062988\n","Epoch: 1, Loss: 0.6592047214508057\n","Epoch: 1, Loss: 0.624638020992279\n","Epoch: 1, Loss: 0.7591047883033752\n","Epoch: 1, Loss: 0.6900729537010193\n","Epoch: 1, Loss: 0.7119081020355225\n","Epoch: 1, Loss: 0.6946594715118408\n","Epoch: 1, Loss: 0.7269036769866943\n","Epoch: 1, Loss: 0.6929162740707397\n","Epoch: 1, Loss: 0.7185363173484802\n","Epoch: 1, Loss: 0.7024251818656921\n","Epoch: 1, Loss: 0.7552475929260254\n","Epoch: 1, Loss: 0.6806405782699585\n","Epoch: 1, Loss: 0.6911970376968384\n","Epoch: 1, Loss: 0.6979935765266418\n","Epoch: 1, Loss: 0.6942183971405029\n","Epoch: 1, Loss: 0.6383219957351685\n","Epoch: 1, Loss: 0.7551900148391724\n","Epoch: 1, Loss: 0.7344442009925842\n","Epoch: 1, Loss: 0.6933232545852661\n","Epoch: 1, Loss: 0.690829336643219\n","Epoch: 1, Loss: 0.66693514585495\n","Epoch: 1, Loss: 0.7195798754692078\n","Epoch: 1, Loss: 0.7135968208312988\n","Epoch: 1, Loss: 0.6873635649681091\n","Epoch: 1, Loss: 0.6362242698669434\n","Epoch: 1, Loss: 0.700369119644165\n","Epoch: 1, Loss: 0.7174593806266785\n","Epoch: 1, Loss: 0.6890029907226562\n","Epoch: 1, Loss: 0.6825575828552246\n","Epoch: 1, Loss: 0.7089537978172302\n","Epoch: 1, Loss: 0.6649454236030579\n","Epoch: 1, Loss: 0.707208514213562\n","Epoch: 1, Loss: 0.751843273639679\n","Epoch: 1, Loss: 0.6716852188110352\n","Epoch: 1, Loss: 0.6966192722320557\n","Epoch: 1, Loss: 0.7227704524993896\n","Epoch: 1, Loss: 0.6847317814826965\n","Epoch: 1, Loss: 0.6584577560424805\n","Epoch: 1, Loss: 0.6860028505325317\n","Epoch: 1, Loss: 0.7079245448112488\n","Epoch: 1, Loss: 0.7273935675621033\n","Epoch: 1, Loss: 0.752967357635498\n","Epoch: 1, Loss: 0.7203946113586426\n","Epoch: 1, Loss: 0.6782317757606506\n","Epoch: 1, Loss: 0.6401206851005554\n","Epoch: 1, Loss: 0.7341313362121582\n","Epoch: 1, Loss: 0.6361594796180725\n","Epoch: 1, Loss: 0.7010225653648376\n","Epoch: 1, Loss: 0.6610615253448486\n","Epoch: 1, Loss: 0.7666597962379456\n","Epoch: 1, Loss: 0.739496648311615\n","Epoch: 1, Loss: 0.7556700706481934\n","Epoch: 1, Loss: 0.6715050935745239\n","Epoch: 1, Loss: 0.7012039422988892\n","Epoch: 1, Loss: 0.6765498518943787\n","Epoch: 1, Loss: 0.6737892627716064\n","Epoch: 1, Loss: 0.669841468334198\n","Epoch: 1, Loss: 0.6326732635498047\n","Epoch: 1, Loss: 0.7632879614830017\n","Epoch: 1, Loss: 0.6443912982940674\n","Epoch: 1, Loss: 0.7036473751068115\n","Epoch: 1, Loss: 0.6646891236305237\n","Epoch: 1, Loss: 0.6624029278755188\n","Epoch: 1, Loss: 0.6514399647712708\n","Epoch: 1, Loss: 0.7036986351013184\n","Epoch: 1, Loss: 0.6631951928138733\n","Epoch: 1, Loss: 0.7267356514930725\n","Epoch: 1, Loss: 0.7238724231719971\n","Epoch: 1, Loss: 0.7262532114982605\n","Epoch: 1, Loss: 0.7440090179443359\n","Epoch: 1, Loss: 0.6317978501319885\n","Epoch: 1, Loss: 0.7454716563224792\n","Epoch: 1, Loss: 0.7031282782554626\n","Epoch: 1, Loss: 0.6954461336135864\n","Epoch: 1, Loss: 0.651077151298523\n","Epoch: 1, Loss: 0.7161226272583008\n","Epoch: 1, Loss: 0.7136415243148804\n","Epoch: 1, Loss: 0.697619616985321\n","Epoch: 1, Loss: 0.7043917179107666\n","Epoch: 1, Loss: 0.6825158596038818\n","Epoch: 1, Loss: 0.6609093546867371\n","Epoch: 1, Loss: 0.758612334728241\n","Epoch: 1, Loss: 0.6614615321159363\n","Epoch: 1, Loss: 0.6623327136039734\n","Epoch: 1, Loss: 0.7614186406135559\n","Epoch: 1, Loss: 0.6966855525970459\n","Epoch: 1, Loss: 0.6921263933181763\n","Epoch: 1, Loss: 0.699699878692627\n","Epoch: 1, Loss: 0.6837478280067444\n","Epoch: 1, Loss: 0.6740140914916992\n","Epoch: 1, Loss: 0.6493417620658875\n","Epoch: 1, Loss: 0.6666727066040039\n","Epoch: 1, Loss: 0.7175546884536743\n","Epoch: 1, Loss: 0.7301846742630005\n","Epoch: 1, Loss: 0.7237920165061951\n","Epoch: 1, Loss: 0.6504772901535034\n","Epoch: 1, Loss: 0.6582214832305908\n","Epoch: 1, Loss: 0.670076310634613\n","Epoch: 1, Loss: 0.7167037129402161\n","Epoch: 1, Loss: 0.6996606588363647\n","Epoch: 1, Loss: 0.7481018900871277\n","Epoch: 1, Loss: 0.6915234327316284\n","Epoch: 1, Loss: 0.6983019709587097\n","Epoch: 1, Loss: 0.6695467233657837\n","Epoch: 1, Loss: 0.752116322517395\n","Epoch: 1, Loss: 0.6793362498283386\n","Epoch: 1, Loss: 0.6674492359161377\n","Epoch: 1, Loss: 0.7003377676010132\n","Epoch: 1, Loss: 0.6978910565376282\n","Epoch: 1, Loss: 0.7281132340431213\n","Epoch: 1, Loss: 0.7195749282836914\n","Epoch: 1, Loss: 0.6768730282783508\n","Epoch: 1, Loss: 0.6739198565483093\n","Epoch: 1, Loss: 0.7568826675415039\n","Epoch: 1, Loss: 0.672838568687439\n","Epoch: 1, Loss: 0.7139105796813965\n","Epoch: 1, Loss: 0.7158663272857666\n","Epoch: 1, Loss: 0.683915913105011\n","Epoch: 1, Loss: 0.740334153175354\n","Epoch: 1, Loss: 0.7061290144920349\n","Epoch: 1, Loss: 0.6936843991279602\n","Epoch: 1, Loss: 0.7007778882980347\n","Epoch: 1, Loss: 0.7117026448249817\n","Epoch: 1, Loss: 0.7021663784980774\n","Epoch: 1, Loss: 0.7274991273880005\n","Epoch: 1, Loss: 0.7435405850410461\n","Epoch: 1, Loss: 0.6238901615142822\n","Epoch: 1, Loss: 0.7273202538490295\n","Epoch: 1, Loss: 0.7141607999801636\n","Epoch: 1, Loss: 0.7209945321083069\n","Epoch: 1, Loss: 0.6516051888465881\n","Epoch: 1, Loss: 0.7305613160133362\n","Epoch: 1, Loss: 0.7110289931297302\n","Epoch: 1, Loss: 0.7089566588401794\n","Epoch: 1, Loss: 0.6894344091415405\n","Epoch: 1, Loss: 0.6448355913162231\n","Epoch: 1, Loss: 0.7012279033660889\n","Epoch: 1, Loss: 0.6791280508041382\n","Epoch: 1, Loss: 0.7269237637519836\n","Epoch: 1, Loss: 0.7023015022277832\n","Epoch: 1, Loss: 0.7042698860168457\n","Epoch: 1, Loss: 0.7113779783248901\n","Epoch: 1, Loss: 0.7104783654212952\n","Epoch: 1, Loss: 0.7163792252540588\n","Epoch: 1, Loss: 0.6899203658103943\n","Epoch: 1, Loss: 0.7260116934776306\n","Epoch: 1, Loss: 0.7477599382400513\n","Epoch: 1, Loss: 0.7444567680358887\n","Epoch: 1, Loss: 0.6873285174369812\n","Epoch: 1, Loss: 0.7192050218582153\n","Epoch: 1, Loss: 0.7166553139686584\n","Epoch: 1, Loss: 0.7266076803207397\n","Epoch: 1, Loss: 0.7170594930648804\n","Epoch: 1, Loss: 0.651167094707489\n","Epoch: 1, Loss: 0.7292565107345581\n","Epoch: 1, Loss: 0.6586818695068359\n","Epoch: 1, Loss: 0.7312016487121582\n","Epoch: 1, Loss: 0.7024539709091187\n","Epoch: 1, Loss: 0.6914687752723694\n","Epoch: 1, Loss: 0.6989713311195374\n","Epoch: 1, Loss: 0.7098332643508911\n","Epoch: 1, Loss: 0.6647196412086487\n","Epoch: 1, Loss: 0.6740934252738953\n","Epoch: 1, Loss: 0.6895630359649658\n","Epoch: 1, Loss: 0.72145015001297\n","Epoch: 1, Loss: 0.6834037899971008\n","Epoch: 1, Loss: 0.6817493438720703\n","Epoch: 1, Loss: 0.6345941424369812\n","Epoch: 1, Loss: 0.6762752532958984\n","Epoch: 1, Loss: 0.7135009169578552\n","Epoch: 1, Loss: 0.6792961359024048\n","Epoch: 1, Loss: 0.682971715927124\n","Epoch: 1, Loss: 0.7432460188865662\n","Epoch: 1, Loss: 0.6910309195518494\n","Epoch: 1, Loss: 0.6822265386581421\n","Epoch: 1, Loss: 0.670771598815918\n","Epoch: 1, Loss: 0.6951532959938049\n","Epoch: 1, Loss: 0.6792235970497131\n","Epoch: 1, Loss: 0.6816099882125854\n","Epoch: 1, Loss: 0.6716439723968506\n","Epoch: 1, Loss: 0.6894688606262207\n","Epoch: 1, Loss: 0.6794050931930542\n","Epoch: 1, Loss: 0.6738331317901611\n","Epoch: 1, Loss: 0.7202532887458801\n","Epoch: 1, Loss: 0.7406823635101318\n","Epoch: 1, Loss: 0.6847067475318909\n","Epoch: 1, Loss: 0.6518710255622864\n","Epoch: 1, Loss: 0.6531189680099487\n","Epoch: 1, Loss: 0.6940954327583313\n","Epoch: 1, Loss: 0.7261648178100586\n","Epoch: 1, Loss: 0.6891435384750366\n","Epoch: 1, Loss: 0.6916239261627197\n","Epoch: 1, Loss: 0.7341957092285156\n","Epoch: 1, Loss: 0.6892491579055786\n","Epoch: 1, Loss: 0.6682465672492981\n","Epoch: 1, Loss: 0.6395042538642883\n","Epoch: 1, Loss: 0.7214239239692688\n","Epoch: 1, Loss: 0.6824972033500671\n","Epoch: 1, Loss: 0.6090703010559082\n","Epoch: 1, Loss: 0.6477415561676025\n","Epoch: 1, Loss: 0.652676522731781\n","Epoch: 1, Loss: 0.6724676489830017\n","Epoch: 1, Loss: 0.6678285598754883\n","Epoch: 1, Loss: 0.6955358386039734\n","Epoch: 1, Loss: 0.7531195282936096\n","Epoch: 1, Loss: 0.768910825252533\n","Epoch: 1, Loss: 0.6629627346992493\n","Epoch: 1, Loss: 0.7469173073768616\n","Epoch: 1, Loss: 0.6229885816574097\n","Epoch: 1, Loss: 0.6467581391334534\n","Epoch: 1, Loss: 0.7362706661224365\n","Epoch: 1, Loss: 0.6799641847610474\n","Epoch: 1, Loss: 0.6889325380325317\n","Epoch: 1, Loss: 0.6775675415992737\n","Epoch: 1, Loss: 0.6911714673042297\n","Epoch: 1, Loss: 0.5769867897033691\n","Epoch: 1, Loss: 0.7918683290481567\n","Epoch: 1, Loss: 0.7543062567710876\n","Epoch: 1, Loss: 0.6730315685272217\n","Epoch: 1, Loss: 0.7496756315231323\n","Epoch: 1, Loss: 0.6623926162719727\n","Epoch: 1, Loss: 0.7435435652732849\n","Epoch: 1, Loss: 0.7071661353111267\n","Epoch: 1, Loss: 0.713322103023529\n","Epoch: 1, Loss: 0.7048255205154419\n","Epoch: 1, Loss: 0.6648053526878357\n","Epoch: 1, Loss: 0.7081751227378845\n","Epoch: 1, Loss: 0.7034254670143127\n","Epoch: 1, Loss: 0.7098065614700317\n","Epoch: 1, Loss: 0.650212824344635\n","Epoch: 1, Loss: 0.6857792139053345\n","Epoch: 1, Loss: 0.6126689910888672\n","Epoch: 1, Loss: 0.6890326738357544\n","Epoch: 1, Loss: 0.7184499502182007\n","Epoch: 1, Loss: 0.7097459435462952\n","Epoch: 1, Loss: 0.6520260572433472\n","Epoch: 1, Loss: 0.7135702967643738\n","Epoch: 1, Loss: 0.6486073136329651\n","Epoch: 1, Loss: 0.6771758198738098\n","Epoch: 1, Loss: 0.7271820902824402\n","Epoch: 1, Loss: 0.7081257700920105\n","Epoch: 1, Loss: 0.6993741393089294\n","Epoch: 1, Loss: 0.6746982932090759\n","Epoch: 1, Loss: 0.7062706351280212\n","Epoch: 1, Loss: 0.690060555934906\n","Epoch: 1, Loss: 0.6556285619735718\n","Epoch: 1, Loss: 0.6849808692932129\n","Epoch: 1, Loss: 0.7778051495552063\n","Epoch: 1, Loss: 0.6252803206443787\n","Epoch: 1, Loss: 0.6599410772323608\n","Epoch: 1, Loss: 0.6754834055900574\n","Epoch: 1, Loss: 0.6730640530586243\n","Epoch: 1, Loss: 0.7048567533493042\n","Epoch: 1, Loss: 0.7147471904754639\n","Epoch: 1, Loss: 0.6875078678131104\n","Epoch: 1, Loss: 0.6738742589950562\n","Epoch: 1, Loss: 0.6648914217948914\n","Epoch: 1, Loss: 0.7395851612091064\n","Epoch: 1, Loss: 0.704944372177124\n","Epoch: 1, Loss: 0.7383995652198792\n","Epoch: 1, Loss: 0.647407054901123\n","Epoch: 1, Loss: 0.7047321796417236\n","Epoch: 1, Loss: 0.7473905682563782\n","Epoch: 1, Loss: 0.6549926400184631\n","Epoch: 1, Loss: 0.5717635750770569\n","Epoch: 1, Loss: 0.7398295402526855\n","Epoch: 1, Loss: 0.6960745453834534\n","Epoch: 1, Loss: 0.7262624502182007\n","Epoch: 1, Loss: 0.6463626027107239\n","Epoch: 1, Loss: 0.7248942852020264\n","Epoch: 1, Loss: 0.7207510471343994\n","Epoch: 1, Loss: 0.7332894206047058\n","Epoch: 1, Loss: 0.6034773588180542\n","Epoch: 1, Loss: 0.6721625328063965\n","Epoch: 1, Loss: 0.6474330425262451\n","Epoch: 1, Loss: 0.656170666217804\n","Epoch: 1, Loss: 0.6076698303222656\n","Epoch: 1, Loss: 0.6491254568099976\n","Epoch: 1, Loss: 0.7423300743103027\n","Epoch: 1, Loss: 0.7391587495803833\n","Epoch: 1, Loss: 0.6690951585769653\n","Epoch: 1, Loss: 0.6463564038276672\n","Epoch: 1, Loss: 0.6637076139450073\n","Epoch: 1, Loss: 0.6930256485939026\n","Epoch: 1, Loss: 0.7710800766944885\n","Epoch: 1, Loss: 0.7088169455528259\n","Epoch: 1, Loss: 0.579615592956543\n","Epoch: 1, Loss: 0.7937487363815308\n","Epoch: 1, Loss: 0.5589730143547058\n","Epoch: 1, Loss: 0.7730080485343933\n","Epoch: 1, Loss: 0.7018471360206604\n","Epoch: 1, Loss: 0.7203373312950134\n","Epoch: 1, Loss: 0.7130234241485596\n","Epoch: 1, Loss: 0.9267993569374084\n","Epoch: 1, Loss: 0.5636027455329895\n","Epoch: 1, Loss: 0.6955898404121399\n","Epoch: 1, Loss: 0.6916264891624451\n","Epoch: 1, Loss: 0.770199179649353\n","Epoch: 1, Loss: 0.6598631143569946\n","Epoch: 1, Loss: 0.661280632019043\n","Epoch: 1, Loss: 0.6291449069976807\n","Epoch: 1, Loss: 0.7739299535751343\n","Epoch: 1, Loss: 0.7850836515426636\n","Epoch: 1, Loss: 0.7242332100868225\n","Epoch: 1, Loss: 0.7236567139625549\n","Epoch: 1, Loss: 0.6241563558578491\n","Epoch: 1, Loss: 0.6564122438430786\n","Epoch: 1, Loss: 0.7258970141410828\n","Epoch: 1, Loss: 0.7425481677055359\n","Epoch: 1, Loss: 0.6681225299835205\n","Epoch: 1, Loss: 0.7172423005104065\n","Epoch: 1, Loss: 0.7163450717926025\n","Epoch: 1, Loss: 0.7304545044898987\n","Epoch: 1, Loss: 0.6781119704246521\n","Epoch: 1, Loss: 0.690869927406311\n","Epoch: 1, Loss: 0.7097481489181519\n","Epoch: 1, Loss: 0.6688135862350464\n","Epoch: 1, Loss: 0.7013221383094788\n","Epoch: 1, Loss: 0.7220472097396851\n","Epoch: 1, Loss: 0.6968618035316467\n","Epoch: 1, Loss: 0.6623789072036743\n","Epoch: 1, Loss: 0.7155722975730896\n","Epoch: 1, Loss: 0.7081474661827087\n","Epoch: 1, Loss: 0.6545729637145996\n","Epoch: 1, Loss: 0.648405134677887\n","Epoch: 1, Loss: 0.7151816487312317\n","Epoch: 1, Loss: 0.7505438327789307\n","Epoch: 1, Loss: 0.7145587801933289\n","Epoch: 1, Loss: 0.7399197220802307\n","Epoch: 1, Loss: 0.6847386360168457\n","Epoch: 1, Loss: 0.6873381733894348\n","Epoch: 1, Loss: 0.6753212809562683\n","Epoch: 1, Loss: 0.6577363014221191\n","Epoch: 1, Loss: 0.6948579549789429\n","Epoch: 1, Loss: 0.7343319058418274\n","Epoch: 1, Loss: 0.65578693151474\n","Epoch: 1, Loss: 0.6529786586761475\n","Epoch: 1, Loss: 0.6942631006240845\n","Epoch: 1, Loss: 0.7118614912033081\n","Epoch: 1, Loss: 0.6860443949699402\n","Epoch: 1, Loss: 0.6364037990570068\n","Epoch: 1, Loss: 0.6598443984985352\n","Epoch: 1, Loss: 0.6915397047996521\n","Epoch: 1, Loss: 0.6829633116722107\n","Epoch: 1, Loss: 0.6707158088684082\n","Epoch: 1, Loss: 0.6604020595550537\n","Epoch: 1, Loss: 0.7353837490081787\n","Epoch: 1, Loss: 0.721560537815094\n","Epoch: 1, Loss: 0.7164040803909302\n","Epoch: 1, Loss: 0.7212916612625122\n","Epoch: 1, Loss: 0.7187252640724182\n","Epoch: 1, Loss: 0.6700554490089417\n","Epoch: 1, Loss: 0.7262410521507263\n","Epoch: 1, Loss: 0.6492825746536255\n","Epoch: 1, Loss: 0.6895098090171814\n","Epoch: 1, Loss: 0.7045594453811646\n","Epoch: 1, Loss: 0.677440881729126\n","Epoch: 1, Loss: 0.666218638420105\n","Epoch: 1, Loss: 0.6932337880134583\n","Epoch: 1, Loss: 0.7100507616996765\n","Epoch: 1, Loss: 0.6311143040657043\n","Epoch: 1, Loss: 0.7770026326179504\n","Epoch: 1, Loss: 0.6263248324394226\n","Epoch: 1, Loss: 0.7097786664962769\n","Epoch: 1, Loss: 0.6622633337974548\n","Epoch: 1, Loss: 0.730838418006897\n","Epoch: 1, Loss: 0.6688835024833679\n","Epoch: 1, Loss: 0.7043742537498474\n","Epoch: 1, Loss: 0.6437060236930847\n","Epoch: 1, Loss: 0.7318146824836731\n","Epoch: 1, Loss: 0.6576288938522339\n","Epoch: 1, Loss: 0.7829686999320984\n","Epoch: 1, Loss: 0.7313899993896484\n","Epoch: 1, Loss: 0.6232965588569641\n","Epoch: 1, Loss: 0.7789863348007202\n","Epoch: 1, Loss: 0.7510222792625427\n","Epoch: 1, Loss: 0.6904675960540771\n","Epoch: 1, Loss: 0.6814571022987366\n","Epoch: 1, Loss: 0.6870297193527222\n","Epoch: 1, Loss: 0.7336934208869934\n","Epoch: 1, Loss: 0.7157357335090637\n","Epoch: 1, Loss: 0.6537688970565796\n","Epoch: 1, Loss: 0.6915525197982788\n","Epoch: 1, Loss: 0.7687109708786011\n","Epoch: 1, Loss: 0.7003626227378845\n","Epoch: 1, Loss: 0.6938769817352295\n","Epoch: 1, Loss: 0.6462201476097107\n","Epoch: 1, Loss: 0.7074791789054871\n","Epoch: 1, Loss: 0.7763659358024597\n","Epoch: 1, Loss: 0.654117226600647\n","Epoch: 1, Loss: 0.6484041810035706\n","Epoch: 1, Loss: 0.6607341766357422\n","Epoch: 1, Loss: 0.7024299502372742\n","Epoch: 1, Loss: 0.7229149341583252\n","Epoch: 1, Loss: 0.6443655490875244\n","Epoch: 1, Loss: 0.685574471950531\n","Epoch: 1, Loss: 0.6763260364532471\n","Epoch: 1, Loss: 0.7055197954177856\n","Epoch: 1, Loss: 0.6969422101974487\n","Epoch: 1, Loss: 0.6746793389320374\n","Epoch: 1, Loss: 0.6896467804908752\n","Epoch: 1, Loss: 0.7004919052124023\n","Epoch: 1, Loss: 0.6615463495254517\n","Epoch: 1, Loss: 0.7083402276039124\n","Epoch: 1, Loss: 0.7125412225723267\n","Epoch: 1, Loss: 0.7087751626968384\n","Epoch: 1, Loss: 0.7436621785163879\n","Epoch: 1, Loss: 0.74785315990448\n","Epoch: 1, Loss: 0.6665090918540955\n","Epoch: 1, Loss: 0.6561909317970276\n","Epoch: 1, Loss: 0.703286349773407\n","Epoch: 1, Loss: 0.6672495603561401\n","Epoch: 1, Loss: 0.693226158618927\n","Epoch: 1, Loss: 0.7205031514167786\n","Epoch: 1, Loss: 0.7079637050628662\n","Epoch: 1, Loss: 0.7055391073226929\n","Epoch: 1, Loss: 0.6858403086662292\n","Epoch: 1, Loss: 0.6920748353004456\n","Epoch: 1, Loss: 0.6915997862815857\n","Epoch: 1, Loss: 0.7186267971992493\n","Epoch: 1, Loss: 0.6932815313339233\n","Epoch: 1, Loss: 0.7303667068481445\n","Epoch: 1, Loss: 0.7276571393013\n","Epoch: 1, Loss: 0.7068018913269043\n","Epoch: 1, Loss: 0.6802382469177246\n","Epoch: 1, Loss: 0.7112303972244263\n","Epoch: 1, Loss: 0.6900020837783813\n","Epoch: 1, Loss: 0.6937779188156128\n","Epoch: 1, Loss: 0.7148323655128479\n","Epoch: 1, Loss: 0.6791573762893677\n","Epoch: 1, Loss: 0.6985776424407959\n","Epoch: 1, Loss: 0.7215490341186523\n","Epoch: 1, Loss: 0.6990984678268433\n","Epoch: 1, Loss: 0.7051122188568115\n","Epoch: 1, Loss: 0.7206788063049316\n","Epoch: 1, Loss: 0.6577236652374268\n","Epoch: 1, Loss: 0.6286500096321106\n","Epoch: 1, Loss: 0.658293604850769\n","Epoch: 1, Loss: 0.6817381978034973\n","Epoch: 1, Loss: 0.6330505609512329\n","Epoch: 1, Loss: 0.6907289028167725\n","Epoch: 1, Loss: 0.6970720291137695\n","Epoch: 1, Loss: 0.6961419582366943\n","Epoch: 1, Loss: 0.6394306421279907\n","Epoch: 1, Loss: 0.7213857173919678\n","Epoch: 1, Loss: 0.7133269309997559\n","Epoch: 1, Loss: 0.6988613605499268\n","Epoch: 1, Loss: 0.648206353187561\n","Epoch: 1, Loss: 0.6275949478149414\n","Epoch: 1, Loss: 0.766907811164856\n","Epoch: 1, Loss: 0.6222306489944458\n","Epoch: 1, Loss: 0.5544748306274414\n","Epoch: 1, Loss: 0.6744714975357056\n","Epoch: 1, Loss: 0.7983030676841736\n","Epoch: 1, Loss: 0.7142506241798401\n","Epoch: 1, Loss: 0.6925182342529297\n","Epoch: 1, Loss: 0.691052258014679\n","Epoch: 1, Loss: 0.6268050074577332\n","Epoch: 1, Loss: 0.7325088977813721\n","Epoch: 1, Loss: 0.7574995756149292\n","Epoch: 1, Loss: 0.5935963988304138\n","Epoch: 1, Loss: 0.75627201795578\n","Epoch: 1, Loss: 0.6501225829124451\n","Epoch: 1, Loss: 0.8345461487770081\n","Epoch: 1, Loss: 0.7823102474212646\n","Epoch: 1, Loss: 0.7368754744529724\n","Epoch: 1, Loss: 0.7321188449859619\n","Epoch: 1, Loss: 0.5877335071563721\n","Epoch: 1, Loss: 0.6815406084060669\n","Epoch: 1, Loss: 0.7700788974761963\n","Epoch: 1, Loss: 0.6003747582435608\n","Epoch: 1, Loss: 0.7460132241249084\n","Epoch: 1, Loss: 0.7304397225379944\n","Epoch: 1, Loss: 0.7375615239143372\n","Epoch: 1, Loss: 0.670012354850769\n","Epoch: 1, Loss: 0.6602386832237244\n","Epoch: 1, Loss: 0.7402554750442505\n","Epoch: 1, Loss: 0.6796547770500183\n","Epoch: 1, Loss: 0.7032349109649658\n","Epoch: 1, Loss: 0.7075585126876831\n","Epoch: 1, Loss: 0.6676274538040161\n","Epoch: 1, Loss: 0.6907459497451782\n","Epoch: 1, Loss: 0.6397038698196411\n","Epoch: 1, Loss: 0.7496657371520996\n","Epoch: 1, Loss: 0.6689452528953552\n","Epoch: 1, Loss: 0.6823634505271912\n","Epoch: 1, Loss: 0.7127252221107483\n","Epoch: 1, Loss: 0.6569238305091858\n","Epoch: 1, Loss: 0.6577524542808533\n","Epoch: 1, Loss: 0.6959772109985352\n","Epoch: 1, Loss: 0.690487802028656\n","Epoch: 1, Loss: 0.7865447998046875\n","Epoch: 1, Loss: 0.7045906186103821\n","Epoch: 1, Loss: 0.6703563928604126\n","Epoch: 1, Loss: 0.7319080829620361\n","Epoch: 1, Loss: 0.7388839721679688\n","Epoch: 1, Loss: 0.7347182035446167\n","Epoch: 1, Loss: 0.7087686657905579\n","Epoch: 1, Loss: 0.711518406867981\n","Epoch: 1, Loss: 0.7203498482704163\n","Epoch: 1, Loss: 0.7200942635536194\n","Epoch: 1, Loss: 0.70667564868927\n","Epoch: 1, Loss: 0.6395092010498047\n","Epoch: 1, Loss: 0.6685140132904053\n","Epoch: 1, Loss: 0.7177781462669373\n","Epoch: 1, Loss: 0.7022100687026978\n","Epoch: 1, Loss: 0.7352654933929443\n","Epoch: 1, Loss: 0.6609704494476318\n","Epoch: 1, Loss: 0.6287807822227478\n","Epoch: 1, Loss: 0.667783796787262\n","Epoch: 1, Loss: 0.8127722144126892\n","Epoch: 1, Loss: 0.6684837341308594\n","Epoch: 1, Loss: 0.7762479186058044\n","Epoch: 1, Loss: 0.5891473889350891\n","Epoch: 1, Loss: 0.6764652729034424\n","Epoch: 1, Loss: 0.6564359068870544\n","Epoch: 1, Loss: 0.7061183452606201\n","Epoch: 1, Loss: 0.6795355081558228\n","Epoch: 1, Loss: 0.6003122329711914\n","Epoch: 1, Loss: 0.6280177235603333\n","Epoch: 1, Loss: 0.6829004287719727\n","Epoch: 1, Loss: 0.7249336242675781\n","Epoch: 1, Loss: 0.8142499327659607\n","Epoch: 1, Loss: 0.7566791772842407\n","Epoch: 1, Loss: 0.7835332155227661\n","Epoch: 1, Loss: 0.6587513089179993\n","Epoch: 1, Loss: 0.9351298809051514\n","Epoch: 1, Loss: 0.6562454104423523\n","Epoch: 1, Loss: 0.6988901495933533\n","Epoch: 1, Loss: 0.708724856376648\n","Epoch: 1, Loss: 0.6899699568748474\n","Epoch: 1, Loss: 0.6398065686225891\n","Epoch: 1, Loss: 0.6940826773643494\n","Epoch: 1, Loss: 0.6689185500144958\n","Epoch: 1, Loss: 0.7084057927131653\n","Epoch: 1, Loss: 0.7248114943504333\n","Epoch: 1, Loss: 0.6711134910583496\n","Epoch: 1, Loss: 0.702980637550354\n","Epoch: 1, Loss: 0.7092393636703491\n","Epoch: 1, Loss: 0.6756486892700195\n","Epoch: 1, Loss: 0.6917275786399841\n","Epoch: 1, Loss: 0.7400816679000854\n","Epoch: 1, Loss: 0.7207978963851929\n","Epoch: 1, Loss: 0.7278177738189697\n","Epoch: 1, Loss: 0.67762291431427\n","Epoch: 1, Loss: 0.724107563495636\n","Epoch: 1, Loss: 0.7439647316932678\n","Epoch: 1, Loss: 0.6961117386817932\n","Epoch: 1, Loss: 0.6599606275558472\n","Epoch: 1, Loss: 0.6985543966293335\n","Epoch: 1, Loss: 0.668457567691803\n","Epoch: 1, Loss: 0.7062813639640808\n","Epoch: 1, Loss: 0.7019172310829163\n","Epoch: 1, Loss: 0.6654380559921265\n","Epoch: 1, Loss: 0.7143761515617371\n","Epoch: 1, Loss: 0.6407163143157959\n","Epoch: 1, Loss: 0.7099655866622925\n","Epoch: 1, Loss: 0.6900328993797302\n","Epoch: 1, Loss: 0.6914865970611572\n","Epoch: 1, Loss: 0.8112531304359436\n","Epoch: 1, Loss: 0.7166197896003723\n","Epoch: 1, Loss: 0.7340906858444214\n","Epoch: 1, Loss: 0.7069762349128723\n","Epoch: 1, Loss: 0.7356835007667542\n","Epoch: 1, Loss: 0.7028945088386536\n","Epoch: 1, Loss: 0.7001197934150696\n","Epoch: 1, Loss: 0.6670616269111633\n","Epoch: 1, Loss: 0.6528963446617126\n","Epoch: 1, Loss: 0.6945368647575378\n","Epoch: 1, Loss: 0.6878859996795654\n","Epoch: 1, Loss: 0.7221081256866455\n","Epoch: 1, Loss: 0.7193528413772583\n","Epoch: 1, Loss: 0.6961910724639893\n","Epoch: 1, Loss: 0.707524299621582\n","Epoch: 1, Loss: 0.6809708476066589\n","Epoch: 1, Loss: 0.6414101123809814\n","Epoch: 1, Loss: 0.679665744304657\n","Epoch: 1, Loss: 0.6644809246063232\n","Epoch: 1, Loss: 0.7069247364997864\n","Epoch: 1, Loss: 0.666484534740448\n","Epoch: 1, Loss: 0.673964262008667\n","Epoch: 1, Loss: 0.7384456396102905\n","Epoch: 1, Loss: 0.5882095098495483\n","Epoch: 1, Loss: 0.6945415735244751\n","Epoch: 1, Loss: 0.6416020393371582\n","Epoch: 1, Loss: 0.7879106998443604\n","Epoch: 1, Loss: 0.7094083428382874\n","Epoch: 1, Loss: 0.7739587426185608\n","Epoch: 1, Loss: 0.6516308784484863\n","Epoch: 1, Loss: 0.7774714827537537\n","Epoch: 1, Loss: 0.7686700820922852\n","Epoch: 1, Loss: 0.5734286308288574\n","Epoch: 1, Loss: 0.6373298168182373\n","Epoch: 1, Loss: 0.7275046110153198\n","Epoch: 1, Loss: 0.6564307808876038\n","Epoch: 1, Loss: 0.7290833592414856\n","Epoch: 1, Loss: 0.7052326202392578\n","Epoch: 1, Loss: 0.6890174746513367\n","Epoch: 2, Loss: 0.6628816723823547\n","Epoch: 2, Loss: 0.7908002138137817\n","Epoch: 2, Loss: 0.7187974452972412\n","Epoch: 2, Loss: 0.7012417316436768\n","Epoch: 2, Loss: 0.6480007767677307\n","Epoch: 2, Loss: 0.723193883895874\n","Epoch: 2, Loss: 0.7599009275436401\n","Epoch: 2, Loss: 0.741197407245636\n","Epoch: 2, Loss: 0.7107521295547485\n","Epoch: 2, Loss: 0.6827354431152344\n","Epoch: 2, Loss: 0.6780572533607483\n","Epoch: 2, Loss: 0.6594143509864807\n","Epoch: 2, Loss: 0.7007378339767456\n","Epoch: 2, Loss: 0.6560529470443726\n","Epoch: 2, Loss: 0.663165271282196\n","Epoch: 2, Loss: 0.6937219500541687\n","Epoch: 2, Loss: 0.7312484979629517\n","Epoch: 2, Loss: 0.7049845457077026\n","Epoch: 2, Loss: 0.7487942576408386\n","Epoch: 2, Loss: 0.5714983344078064\n","Epoch: 2, Loss: 0.634996771812439\n","Epoch: 2, Loss: 0.6143838167190552\n","Epoch: 2, Loss: 0.7564971446990967\n","Epoch: 2, Loss: 0.546521008014679\n","Epoch: 2, Loss: 0.6682234406471252\n","Epoch: 2, Loss: 0.9302001595497131\n","Epoch: 2, Loss: 0.6816290616989136\n","Epoch: 2, Loss: 0.6968985795974731\n","Epoch: 2, Loss: 0.7167236804962158\n","Epoch: 2, Loss: 0.6896944642066956\n","Epoch: 2, Loss: 0.5904856324195862\n","Epoch: 2, Loss: 0.5702311992645264\n","Epoch: 2, Loss: 0.7119063138961792\n","Epoch: 2, Loss: 0.6906595826148987\n","Epoch: 2, Loss: 0.6818965077400208\n","Epoch: 2, Loss: 0.6314767599105835\n","Epoch: 2, Loss: 0.7683188915252686\n","Epoch: 2, Loss: 0.6123204231262207\n","Epoch: 2, Loss: 0.792618453502655\n","Epoch: 2, Loss: 0.6731550097465515\n","Epoch: 2, Loss: 0.6103304624557495\n","Epoch: 2, Loss: 0.6713268160820007\n","Epoch: 2, Loss: 0.7411128878593445\n","Epoch: 2, Loss: 0.6926994323730469\n","Epoch: 2, Loss: 0.7151994705200195\n","Epoch: 2, Loss: 0.6795452237129211\n","Epoch: 2, Loss: 0.8034800291061401\n","Epoch: 2, Loss: 0.7015863656997681\n","Epoch: 2, Loss: 0.6533039808273315\n","Epoch: 2, Loss: 0.7430739402770996\n","Epoch: 2, Loss: 0.7218533754348755\n","Epoch: 2, Loss: 0.7017744779586792\n","Epoch: 2, Loss: 0.7206907272338867\n","Epoch: 2, Loss: 0.7233402729034424\n","Epoch: 2, Loss: 0.6040785908699036\n","Epoch: 2, Loss: 0.7138240337371826\n","Epoch: 2, Loss: 0.7094173431396484\n","Epoch: 2, Loss: 0.740617036819458\n","Epoch: 2, Loss: 0.7482742071151733\n","Epoch: 2, Loss: 0.7278472781181335\n","Epoch: 2, Loss: 0.679851233959198\n","Epoch: 2, Loss: 0.7287595272064209\n","Epoch: 2, Loss: 0.6451281309127808\n","Epoch: 2, Loss: 0.6796286106109619\n","Epoch: 2, Loss: 0.6610533595085144\n","Epoch: 2, Loss: 0.6641823053359985\n","Epoch: 2, Loss: 0.7026013135910034\n","Epoch: 2, Loss: 0.6498633027076721\n","Epoch: 2, Loss: 0.6290028691291809\n","Epoch: 2, Loss: 0.6360383033752441\n","Epoch: 2, Loss: 0.6605181694030762\n","Epoch: 2, Loss: 0.6683683395385742\n","Epoch: 2, Loss: 0.7043315768241882\n","Epoch: 2, Loss: 0.6741379499435425\n","Epoch: 2, Loss: 0.6292855739593506\n","Epoch: 2, Loss: 0.789313793182373\n","Epoch: 2, Loss: 0.7536853551864624\n","Epoch: 2, Loss: 0.7400956153869629\n","Epoch: 2, Loss: 0.684224009513855\n","Epoch: 2, Loss: 0.6880664229393005\n","Epoch: 2, Loss: 0.6982619762420654\n","Epoch: 2, Loss: 0.648341715335846\n","Epoch: 2, Loss: 0.6982532143592834\n","Epoch: 2, Loss: 0.683906614780426\n","Epoch: 2, Loss: 0.7038465738296509\n","Epoch: 2, Loss: 0.7328766584396362\n","Epoch: 2, Loss: 0.644827127456665\n","Epoch: 2, Loss: 0.6625033617019653\n","Epoch: 2, Loss: 0.6432792544364929\n","Epoch: 2, Loss: 0.6884453296661377\n","Epoch: 2, Loss: 0.776612401008606\n","Epoch: 2, Loss: 0.698017418384552\n","Epoch: 2, Loss: 0.6863048076629639\n","Epoch: 2, Loss: 0.7182909250259399\n","Epoch: 2, Loss: 0.6503909826278687\n","Epoch: 2, Loss: 0.6526327133178711\n","Epoch: 2, Loss: 0.6657267212867737\n","Epoch: 2, Loss: 0.728294849395752\n","Epoch: 2, Loss: 0.7008860111236572\n","Epoch: 2, Loss: 0.7117061614990234\n","Epoch: 2, Loss: 0.8470270037651062\n","Epoch: 2, Loss: 0.7838757038116455\n","Epoch: 2, Loss: 0.6720993518829346\n","Epoch: 2, Loss: 0.6819280385971069\n","Epoch: 2, Loss: 0.6983637809753418\n","Epoch: 2, Loss: 0.8217108845710754\n","Epoch: 2, Loss: 0.6963443756103516\n","Epoch: 2, Loss: 0.7366517186164856\n","Epoch: 2, Loss: 0.6599897146224976\n","Epoch: 2, Loss: 0.7332354187965393\n","Epoch: 2, Loss: 0.7631472945213318\n","Epoch: 2, Loss: 0.6882469654083252\n","Epoch: 2, Loss: 0.7135727405548096\n","Epoch: 2, Loss: 0.663979709148407\n","Epoch: 2, Loss: 0.6863003969192505\n","Epoch: 2, Loss: 0.6816919445991516\n","Epoch: 2, Loss: 0.7326844334602356\n","Epoch: 2, Loss: 0.688162088394165\n","Epoch: 2, Loss: 0.6956462860107422\n","Epoch: 2, Loss: 0.6526331901550293\n","Epoch: 2, Loss: 0.702946662902832\n","Epoch: 2, Loss: 0.6673633456230164\n","Epoch: 2, Loss: 0.6759915351867676\n","Epoch: 2, Loss: 0.7606426477432251\n","Epoch: 2, Loss: 0.681141197681427\n","Epoch: 2, Loss: 0.7064706683158875\n","Epoch: 2, Loss: 0.8381598591804504\n","Epoch: 2, Loss: 0.6747394800186157\n","Epoch: 2, Loss: 0.7352645993232727\n","Epoch: 2, Loss: 0.6303951740264893\n","Epoch: 2, Loss: 0.7550203800201416\n","Epoch: 2, Loss: 0.7470558881759644\n","Epoch: 2, Loss: 0.6969900131225586\n","Epoch: 2, Loss: 0.6234802007675171\n","Epoch: 2, Loss: 0.6917237639427185\n","Epoch: 2, Loss: 0.7020384669303894\n","Epoch: 2, Loss: 0.6897752285003662\n","Epoch: 2, Loss: 0.7120336890220642\n","Epoch: 2, Loss: 0.723549485206604\n","Epoch: 2, Loss: 0.706485390663147\n","Epoch: 2, Loss: 0.6882375478744507\n","Epoch: 2, Loss: 0.6724211573600769\n","Epoch: 2, Loss: 0.716461181640625\n","Epoch: 2, Loss: 0.7120006084442139\n","Epoch: 2, Loss: 0.738863468170166\n","Epoch: 2, Loss: 0.6901423931121826\n","Epoch: 2, Loss: 0.66502845287323\n","Epoch: 2, Loss: 0.6859979629516602\n","Epoch: 2, Loss: 0.7262434363365173\n","Epoch: 2, Loss: 0.6753589510917664\n","Epoch: 2, Loss: 0.7337968945503235\n","Epoch: 2, Loss: 0.6532917022705078\n","Epoch: 2, Loss: 0.6603359580039978\n","Epoch: 2, Loss: 0.6571521162986755\n","Epoch: 2, Loss: 0.6706706285476685\n","Epoch: 2, Loss: 0.6880962252616882\n","Epoch: 2, Loss: 0.7027976512908936\n","Epoch: 2, Loss: 0.6797741651535034\n","Epoch: 2, Loss: 0.6432478427886963\n","Epoch: 2, Loss: 0.7230889797210693\n","Epoch: 2, Loss: 0.6878477931022644\n","Epoch: 2, Loss: 0.704293966293335\n","Epoch: 2, Loss: 0.7295242547988892\n","Epoch: 2, Loss: 0.7027671337127686\n","Epoch: 2, Loss: 0.6787082552909851\n","Epoch: 2, Loss: 0.6489865183830261\n","Epoch: 2, Loss: 0.6654412150382996\n","Epoch: 2, Loss: 0.6613419055938721\n","Epoch: 2, Loss: 0.7243481874465942\n","Epoch: 2, Loss: 0.7280928492546082\n","Epoch: 2, Loss: 0.6880640983581543\n","Epoch: 2, Loss: 0.6736317276954651\n","Epoch: 2, Loss: 0.6752328872680664\n","Epoch: 2, Loss: 0.6357946991920471\n","Epoch: 2, Loss: 0.714357852935791\n","Epoch: 2, Loss: 0.7240960001945496\n","Epoch: 2, Loss: 0.7224223613739014\n","Epoch: 2, Loss: 0.7534934878349304\n","Epoch: 2, Loss: 0.6580927968025208\n","Epoch: 2, Loss: 0.6944066882133484\n","Epoch: 2, Loss: 0.7114386558532715\n","Epoch: 2, Loss: 0.6044713258743286\n","Epoch: 2, Loss: 0.6510092616081238\n","Epoch: 2, Loss: 0.6681910753250122\n","Epoch: 2, Loss: 0.7417004108428955\n","Epoch: 2, Loss: 0.6575989723205566\n","Epoch: 2, Loss: 0.7092839479446411\n","Epoch: 2, Loss: 0.6832149028778076\n","Epoch: 2, Loss: 0.6986991763114929\n","Epoch: 2, Loss: 0.6809398531913757\n","Epoch: 2, Loss: 0.7053326368331909\n","Epoch: 2, Loss: 0.6481229662895203\n","Epoch: 2, Loss: 0.6816431879997253\n","Epoch: 2, Loss: 0.697812557220459\n","Epoch: 2, Loss: 0.6815027594566345\n","Epoch: 2, Loss: 0.6994731426239014\n","Epoch: 2, Loss: 0.7238616347312927\n","Epoch: 2, Loss: 0.7068665623664856\n","Epoch: 2, Loss: 0.7041198015213013\n","Epoch: 2, Loss: 0.77006596326828\n","Epoch: 2, Loss: 0.715105414390564\n","Epoch: 2, Loss: 0.7042369842529297\n","Epoch: 2, Loss: 0.7545821070671082\n","Epoch: 2, Loss: 0.7262108325958252\n","Epoch: 2, Loss: 0.6473294496536255\n","Epoch: 2, Loss: 0.6654652953147888\n","Epoch: 2, Loss: 0.7139844298362732\n","Epoch: 2, Loss: 0.7077059745788574\n","Epoch: 2, Loss: 0.7238349914550781\n","Epoch: 2, Loss: 0.7061364054679871\n","Epoch: 2, Loss: 0.7321025729179382\n","Epoch: 2, Loss: 0.7292370200157166\n","Epoch: 2, Loss: 0.731487512588501\n","Epoch: 2, Loss: 0.7791542410850525\n","Epoch: 2, Loss: 0.635378360748291\n","Epoch: 2, Loss: 0.7349517345428467\n","Epoch: 2, Loss: 0.7359802722930908\n","Epoch: 2, Loss: 0.6510784029960632\n","Epoch: 2, Loss: 0.7654547691345215\n","Epoch: 2, Loss: 0.7340254783630371\n","Epoch: 2, Loss: 0.715467095375061\n","Epoch: 2, Loss: 0.6394892930984497\n","Epoch: 2, Loss: 0.6512782573699951\n","Epoch: 2, Loss: 0.6943135857582092\n","Epoch: 2, Loss: 0.6686036586761475\n","Epoch: 2, Loss: 0.7377206683158875\n","Epoch: 2, Loss: 0.6173489689826965\n","Epoch: 2, Loss: 0.5956720113754272\n","Epoch: 2, Loss: 0.6888608932495117\n","Epoch: 2, Loss: 0.6817194819450378\n","Epoch: 2, Loss: 0.6582328677177429\n","Epoch: 2, Loss: 0.7459399104118347\n","Epoch: 2, Loss: 0.671977698802948\n","Epoch: 2, Loss: 0.7004978060722351\n","Epoch: 2, Loss: 0.7328906059265137\n","Epoch: 2, Loss: 0.7497916221618652\n","Epoch: 2, Loss: 0.7526698112487793\n","Epoch: 2, Loss: 0.7442978024482727\n","Epoch: 2, Loss: 0.6580075621604919\n","Epoch: 2, Loss: 0.6418133974075317\n","Epoch: 2, Loss: 0.6619284749031067\n","Epoch: 2, Loss: 0.7622141242027283\n","Epoch: 2, Loss: 0.7066408395767212\n","Epoch: 2, Loss: 0.6553357243537903\n","Epoch: 2, Loss: 0.6617429852485657\n","Epoch: 2, Loss: 0.7068057060241699\n","Epoch: 2, Loss: 0.6991901397705078\n","Epoch: 2, Loss: 0.7078239917755127\n","Epoch: 2, Loss: 0.7189255356788635\n","Epoch: 2, Loss: 0.670803964138031\n","Epoch: 2, Loss: 0.6770857572555542\n","Epoch: 2, Loss: 0.7100697159767151\n","Epoch: 2, Loss: 0.6738690137863159\n","Epoch: 2, Loss: 0.6396011114120483\n","Epoch: 2, Loss: 0.7054905891418457\n","Epoch: 2, Loss: 0.7592129707336426\n","Epoch: 2, Loss: 0.6921769380569458\n","Epoch: 2, Loss: 0.7189123034477234\n","Epoch: 2, Loss: 0.7077001333236694\n","Epoch: 2, Loss: 0.6683923602104187\n","Epoch: 2, Loss: 0.6880544424057007\n","Epoch: 2, Loss: 0.7240644097328186\n","Epoch: 2, Loss: 0.7202215194702148\n","Epoch: 2, Loss: 0.7273129820823669\n","Epoch: 2, Loss: 0.6847572326660156\n","Epoch: 2, Loss: 0.7089782953262329\n","Epoch: 2, Loss: 0.6330076456069946\n","Epoch: 2, Loss: 0.648522675037384\n","Epoch: 2, Loss: 0.6445971131324768\n","Epoch: 2, Loss: 0.7227787971496582\n","Epoch: 2, Loss: 0.71660315990448\n","Epoch: 2, Loss: 0.6445399522781372\n","Epoch: 2, Loss: 0.709037184715271\n","Epoch: 2, Loss: 0.7587379217147827\n","Epoch: 2, Loss: 0.8054536581039429\n","Epoch: 2, Loss: 0.792418360710144\n","Epoch: 2, Loss: 0.6702796816825867\n","Epoch: 2, Loss: 0.7452884316444397\n","Epoch: 2, Loss: 0.6913378238677979\n","Epoch: 2, Loss: 0.6514750719070435\n","Epoch: 2, Loss: 0.6702764630317688\n","Epoch: 2, Loss: 0.7142300605773926\n","Epoch: 2, Loss: 0.7356516718864441\n","Epoch: 2, Loss: 0.6842182278633118\n","Epoch: 2, Loss: 0.6601488590240479\n","Epoch: 2, Loss: 0.7245931625366211\n","Epoch: 2, Loss: 0.7194448113441467\n","Epoch: 2, Loss: 0.7068250775337219\n","Epoch: 2, Loss: 0.7039698958396912\n","Epoch: 2, Loss: 0.7156290411949158\n","Epoch: 2, Loss: 0.731609582901001\n","Epoch: 2, Loss: 0.6378644108772278\n","Epoch: 2, Loss: 0.6683470010757446\n","Epoch: 2, Loss: 0.7021040320396423\n","Epoch: 2, Loss: 0.7736808657646179\n","Epoch: 2, Loss: 0.7074869871139526\n","Epoch: 2, Loss: 0.6846569776535034\n","Epoch: 2, Loss: 0.6429461240768433\n","Epoch: 2, Loss: 0.7220578789710999\n","Epoch: 2, Loss: 0.6621888279914856\n","Epoch: 2, Loss: 0.690893828868866\n","Epoch: 2, Loss: 0.682822048664093\n","Epoch: 2, Loss: 0.6909791827201843\n","Epoch: 2, Loss: 0.6849050521850586\n","Epoch: 2, Loss: 0.6824166178703308\n","Epoch: 2, Loss: 0.6748940944671631\n","Epoch: 2, Loss: 0.6974472999572754\n","Epoch: 2, Loss: 0.7237823605537415\n","Epoch: 2, Loss: 0.6918210983276367\n","Epoch: 2, Loss: 0.6792848110198975\n","Epoch: 2, Loss: 0.6987044811248779\n","Epoch: 2, Loss: 0.6817389726638794\n","Epoch: 2, Loss: 0.6811697483062744\n","Epoch: 2, Loss: 0.6800051331520081\n","Epoch: 2, Loss: 0.6553624868392944\n","Epoch: 2, Loss: 0.759446918964386\n","Epoch: 2, Loss: 0.7459899187088013\n","Epoch: 2, Loss: 0.6501191258430481\n","Epoch: 2, Loss: 0.6764109134674072\n","Epoch: 2, Loss: 0.7281436324119568\n","Epoch: 2, Loss: 0.6385979652404785\n","Epoch: 2, Loss: 0.7846680879592896\n","Epoch: 2, Loss: 0.724804699420929\n","Epoch: 2, Loss: 0.6904317140579224\n","Epoch: 2, Loss: 0.7192866206169128\n","Epoch: 2, Loss: 0.6939575672149658\n","Epoch: 2, Loss: 0.6788762807846069\n","Epoch: 2, Loss: 0.6578567624092102\n","Epoch: 2, Loss: 0.7327700257301331\n","Epoch: 2, Loss: 0.682043194770813\n","Epoch: 2, Loss: 0.7314682602882385\n","Epoch: 2, Loss: 0.7362095713615417\n","Epoch: 2, Loss: 0.6974635720252991\n","Epoch: 2, Loss: 0.6238897442817688\n","Epoch: 2, Loss: 0.7107745409011841\n","Epoch: 2, Loss: 0.706488311290741\n","Epoch: 2, Loss: 0.7216407060623169\n","Epoch: 2, Loss: 0.7238943576812744\n","Epoch: 2, Loss: 0.6654386520385742\n","Epoch: 2, Loss: 0.7011762261390686\n","Epoch: 2, Loss: 0.7221273183822632\n","Epoch: 2, Loss: 0.6713378429412842\n","Epoch: 2, Loss: 0.7124367952346802\n","Epoch: 2, Loss: 0.6774205565452576\n","Epoch: 2, Loss: 0.6528483629226685\n","Epoch: 2, Loss: 0.6848862767219543\n","Epoch: 2, Loss: 0.7454980611801147\n","Epoch: 2, Loss: 0.7092502117156982\n","Epoch: 2, Loss: 0.6899898052215576\n","Epoch: 2, Loss: 0.6836003065109253\n","Epoch: 2, Loss: 0.6606371998786926\n","Epoch: 2, Loss: 0.6640233993530273\n","Epoch: 2, Loss: 0.6889772415161133\n","Epoch: 2, Loss: 0.6340897083282471\n","Epoch: 2, Loss: 0.6796303391456604\n","Epoch: 2, Loss: 0.6768165826797485\n","Epoch: 2, Loss: 0.6634471416473389\n","Epoch: 2, Loss: 0.6706266403198242\n","Epoch: 2, Loss: 0.7072892785072327\n","Epoch: 2, Loss: 0.6818442344665527\n","Epoch: 2, Loss: 0.6972547173500061\n","Epoch: 2, Loss: 0.6555062532424927\n","Epoch: 2, Loss: 0.6670185327529907\n","Epoch: 2, Loss: 0.7037825584411621\n","Epoch: 2, Loss: 0.6327720880508423\n","Epoch: 2, Loss: 0.6404855251312256\n","Epoch: 2, Loss: 0.7102694511413574\n","Epoch: 2, Loss: 0.7153024673461914\n","Epoch: 2, Loss: 0.6337467432022095\n","Epoch: 2, Loss: 0.7161427736282349\n","Epoch: 2, Loss: 0.6908339858055115\n","Epoch: 2, Loss: 0.7328046560287476\n","Epoch: 2, Loss: 0.6565990447998047\n","Epoch: 2, Loss: 0.6854140162467957\n","Epoch: 2, Loss: 0.7109875082969666\n","Epoch: 2, Loss: 0.7086029052734375\n","Epoch: 2, Loss: 0.794154167175293\n","Epoch: 2, Loss: 0.6067478060722351\n","Epoch: 2, Loss: 0.6545596122741699\n","Epoch: 2, Loss: 0.7431462407112122\n","Epoch: 2, Loss: 0.7692768573760986\n","Epoch: 2, Loss: 0.8210874795913696\n","Epoch: 2, Loss: 0.7115302085876465\n","Epoch: 2, Loss: 0.6646721363067627\n","Epoch: 2, Loss: 0.6679875254631042\n","Epoch: 2, Loss: 0.6990014314651489\n","Epoch: 2, Loss: 0.7274249792098999\n","Epoch: 2, Loss: 0.6576630473136902\n","Epoch: 2, Loss: 0.7158193588256836\n","Epoch: 2, Loss: 0.7048505544662476\n","Epoch: 2, Loss: 0.6987709999084473\n","Epoch: 2, Loss: 0.7020301818847656\n","Epoch: 2, Loss: 0.723788857460022\n","Epoch: 2, Loss: 0.6786038875579834\n","Epoch: 2, Loss: 0.7636586427688599\n","Epoch: 2, Loss: 0.6698031425476074\n","Epoch: 2, Loss: 0.7347633838653564\n","Epoch: 2, Loss: 0.6859370470046997\n","Epoch: 2, Loss: 0.6590281128883362\n","Epoch: 2, Loss: 0.6755746603012085\n","Epoch: 2, Loss: 0.7539535760879517\n","Epoch: 2, Loss: 0.72862309217453\n","Epoch: 2, Loss: 0.692996621131897\n","Epoch: 2, Loss: 0.7011910676956177\n","Epoch: 2, Loss: 0.671287477016449\n","Epoch: 2, Loss: 0.7265753149986267\n","Epoch: 2, Loss: 0.7406562566757202\n","Epoch: 2, Loss: 0.6522914171218872\n","Epoch: 2, Loss: 0.7276623249053955\n","Epoch: 2, Loss: 0.6723530292510986\n","Epoch: 2, Loss: 0.7069329619407654\n","Epoch: 2, Loss: 0.6765605211257935\n","Epoch: 2, Loss: 0.6740857362747192\n","Epoch: 2, Loss: 0.6647578477859497\n","Epoch: 2, Loss: 0.6940356492996216\n","Epoch: 2, Loss: 0.7306398153305054\n","Epoch: 2, Loss: 0.7124662399291992\n","Epoch: 2, Loss: 0.6883194446563721\n","Epoch: 2, Loss: 0.6575202345848083\n","Epoch: 2, Loss: 0.6685715913772583\n","Epoch: 2, Loss: 0.6560598015785217\n","Epoch: 2, Loss: 0.7091827392578125\n","Epoch: 2, Loss: 0.631274402141571\n","Epoch: 2, Loss: 0.6553078293800354\n","Epoch: 2, Loss: 0.7167112827301025\n","Epoch: 2, Loss: 0.6784912347793579\n","Epoch: 2, Loss: 0.6817003488540649\n","Epoch: 2, Loss: 0.7460514307022095\n","Epoch: 2, Loss: 0.7147532105445862\n","Epoch: 2, Loss: 0.5835939645767212\n","Epoch: 2, Loss: 0.7129594683647156\n","Epoch: 2, Loss: 0.6912081837654114\n","Epoch: 2, Loss: 0.6867167353630066\n","Epoch: 2, Loss: 0.6916850805282593\n","Epoch: 2, Loss: 0.6394217610359192\n","Epoch: 2, Loss: 0.8367269039154053\n","Epoch: 2, Loss: 0.7543457746505737\n","Epoch: 2, Loss: 0.7747422456741333\n","Epoch: 2, Loss: 0.6694916486740112\n","Epoch: 2, Loss: 0.6281164288520813\n","Epoch: 2, Loss: 0.663966715335846\n","Epoch: 2, Loss: 0.649661660194397\n","Epoch: 2, Loss: 0.657664954662323\n","Epoch: 2, Loss: 0.7343160510063171\n","Epoch: 2, Loss: 0.7229553461074829\n","Epoch: 2, Loss: 0.788650393486023\n","Epoch: 2, Loss: 0.7621787786483765\n","Epoch: 2, Loss: 0.6917291879653931\n","Epoch: 2, Loss: 0.6259807348251343\n","Epoch: 2, Loss: 0.7124506235122681\n","Epoch: 2, Loss: 0.6842643022537231\n","Epoch: 2, Loss: 0.7076081037521362\n","Epoch: 2, Loss: 0.7179819941520691\n","Epoch: 2, Loss: 0.7054335474967957\n","Epoch: 2, Loss: 0.6510245203971863\n","Epoch: 2, Loss: 0.6674774289131165\n","Epoch: 2, Loss: 0.7598229050636292\n","Epoch: 2, Loss: 0.6808277368545532\n","Epoch: 2, Loss: 0.6699453592300415\n","Epoch: 2, Loss: 0.6963596343994141\n","Epoch: 2, Loss: 0.7077691555023193\n","Epoch: 2, Loss: 0.6468506455421448\n","Epoch: 2, Loss: 0.6990753412246704\n","Epoch: 2, Loss: 0.7096570730209351\n","Epoch: 2, Loss: 0.6874326467514038\n","Epoch: 2, Loss: 0.693183422088623\n","Epoch: 2, Loss: 0.6869580149650574\n","Epoch: 2, Loss: 0.6980839967727661\n","Epoch: 2, Loss: 0.6658300161361694\n","Epoch: 2, Loss: 0.7370253205299377\n","Epoch: 2, Loss: 0.7002263069152832\n","Epoch: 2, Loss: 0.6901551485061646\n","Epoch: 2, Loss: 0.7404000163078308\n","Epoch: 2, Loss: 0.7543232440948486\n","Epoch: 2, Loss: 0.7867268919944763\n","Epoch: 2, Loss: 0.7209203839302063\n","Epoch: 2, Loss: 0.6916282773017883\n","Epoch: 2, Loss: 0.700533390045166\n","Epoch: 2, Loss: 0.672109842300415\n","Epoch: 2, Loss: 0.6732861995697021\n","Epoch: 2, Loss: 0.7007490992546082\n","Epoch: 2, Loss: 0.6906600594520569\n","Epoch: 2, Loss: 0.7151011824607849\n","Epoch: 2, Loss: 0.6608940362930298\n","Epoch: 2, Loss: 0.6417272686958313\n","Epoch: 2, Loss: 0.6535297632217407\n","Epoch: 2, Loss: 0.7161001563072205\n","Epoch: 2, Loss: 0.6395081281661987\n","Epoch: 2, Loss: 0.7821714282035828\n","Epoch: 2, Loss: 0.7273790836334229\n","Epoch: 2, Loss: 0.7848206162452698\n","Epoch: 2, Loss: 0.7761318683624268\n","Epoch: 2, Loss: 0.7475730180740356\n","Epoch: 2, Loss: 0.6702584028244019\n","Epoch: 2, Loss: 0.710724949836731\n","Epoch: 2, Loss: 0.7027597427368164\n","Epoch: 2, Loss: 0.6659363508224487\n","Epoch: 2, Loss: 0.6710872054100037\n","Epoch: 2, Loss: 0.6638973355293274\n","Epoch: 2, Loss: 0.7734904885292053\n","Epoch: 2, Loss: 0.6479210257530212\n","Epoch: 2, Loss: 0.6858833432197571\n","Epoch: 2, Loss: 0.7238653302192688\n","Epoch: 2, Loss: 0.7195970416069031\n","Epoch: 2, Loss: 0.6888322234153748\n","Epoch: 2, Loss: 0.7515257000923157\n","Epoch: 2, Loss: 0.6746156215667725\n","Epoch: 2, Loss: 0.7463687658309937\n","Epoch: 2, Loss: 0.6819735765457153\n","Epoch: 2, Loss: 0.7036442160606384\n","Epoch: 2, Loss: 0.7014888525009155\n","Epoch: 2, Loss: 0.7202648520469666\n","Epoch: 2, Loss: 0.7238976955413818\n","Epoch: 2, Loss: 0.6328234076499939\n","Epoch: 2, Loss: 0.6668489575386047\n","Epoch: 2, Loss: 0.695633590221405\n","Epoch: 2, Loss: 0.6720215082168579\n","Epoch: 2, Loss: 0.7015881538391113\n","Epoch: 2, Loss: 0.7271832227706909\n","Epoch: 2, Loss: 0.7073289752006531\n","Epoch: 2, Loss: 0.7326705455780029\n","Epoch: 2, Loss: 0.6964763402938843\n","Epoch: 2, Loss: 0.6967834830284119\n","Epoch: 2, Loss: 0.7095000147819519\n","Epoch: 2, Loss: 0.6795601844787598\n","Epoch: 2, Loss: 0.7087292075157166\n","Epoch: 2, Loss: 0.7156099081039429\n","Epoch: 2, Loss: 0.722628116607666\n","Epoch: 2, Loss: 0.6723477840423584\n","Epoch: 2, Loss: 0.6948635578155518\n","Epoch: 2, Loss: 0.7030067443847656\n","Epoch: 2, Loss: 0.7131075859069824\n","Epoch: 2, Loss: 0.7361713647842407\n","Epoch: 2, Loss: 0.6936306953430176\n","Epoch: 2, Loss: 0.6747644543647766\n","Epoch: 2, Loss: 0.6814448833465576\n","Epoch: 2, Loss: 0.718619167804718\n","Epoch: 2, Loss: 0.6968027353286743\n","Epoch: 2, Loss: 0.6763992309570312\n","Epoch: 2, Loss: 0.7295258641242981\n","Epoch: 2, Loss: 0.70842045545578\n","Epoch: 2, Loss: 0.6850817799568176\n","Epoch: 2, Loss: 0.6797226667404175\n","Epoch: 2, Loss: 0.6579288244247437\n","Epoch: 2, Loss: 0.7092445492744446\n","Epoch: 2, Loss: 0.6848467588424683\n","Epoch: 2, Loss: 0.7304925918579102\n","Epoch: 2, Loss: 0.6520553231239319\n","Epoch: 2, Loss: 0.6621562242507935\n","Epoch: 2, Loss: 0.7442947626113892\n","Epoch: 2, Loss: 0.6695435047149658\n","Epoch: 2, Loss: 0.7060521245002747\n","Epoch: 2, Loss: 0.7297666072845459\n","Epoch: 2, Loss: 0.6298374533653259\n","Epoch: 2, Loss: 0.7583515644073486\n","Epoch: 2, Loss: 0.6660879850387573\n","Epoch: 2, Loss: 0.6563866138458252\n","Epoch: 2, Loss: 0.6712177395820618\n","Epoch: 2, Loss: 0.7391234636306763\n","Epoch: 2, Loss: 0.7632822394371033\n","Epoch: 2, Loss: 0.7363840341567993\n","Epoch: 2, Loss: 0.7058483958244324\n","Epoch: 2, Loss: 0.7207354307174683\n","Epoch: 2, Loss: 0.734187662601471\n","Epoch: 2, Loss: 0.6978721618652344\n","Epoch: 2, Loss: 0.6965563297271729\n","Epoch: 2, Loss: 0.6637585163116455\n","Epoch: 2, Loss: 0.6801614761352539\n","Epoch: 2, Loss: 0.6371322274208069\n","Epoch: 2, Loss: 0.7102362513542175\n","Epoch: 2, Loss: 0.6244503259658813\n","Epoch: 2, Loss: 0.6752790212631226\n","Epoch: 2, Loss: 0.7600671052932739\n","Epoch: 2, Loss: 0.7368271946907043\n","Epoch: 2, Loss: 0.660293698310852\n","Epoch: 2, Loss: 0.7173187136650085\n","Epoch: 2, Loss: 0.7748013138771057\n","Epoch: 2, Loss: 0.7002695798873901\n","Epoch: 2, Loss: 0.7271219491958618\n","Epoch: 2, Loss: 0.6694426536560059\n","Epoch: 2, Loss: 0.654656708240509\n","Epoch: 2, Loss: 0.6833943128585815\n","Epoch: 2, Loss: 0.6876896619796753\n","Epoch: 2, Loss: 0.6571115851402283\n","Epoch: 2, Loss: 0.7102885246276855\n","Epoch: 2, Loss: 0.6567587852478027\n","Epoch: 2, Loss: 0.7177904844284058\n","Epoch: 2, Loss: 0.7309511303901672\n","Epoch: 2, Loss: 0.6246024370193481\n","Epoch: 2, Loss: 0.7018330693244934\n","Epoch: 2, Loss: 0.7461503744125366\n","Epoch: 2, Loss: 0.7181335687637329\n","Epoch: 2, Loss: 0.7049696445465088\n","Epoch: 2, Loss: 0.7099639177322388\n","Epoch: 2, Loss: 0.7082929611206055\n","Epoch: 2, Loss: 0.6479101181030273\n","Epoch: 2, Loss: 0.667559802532196\n","Epoch: 2, Loss: 0.6613702774047852\n","Epoch: 2, Loss: 0.6982370018959045\n","Epoch: 2, Loss: 0.6769008636474609\n","Epoch: 2, Loss: 0.6595567464828491\n","Epoch: 2, Loss: 0.6752879023551941\n","Epoch: 2, Loss: 0.6253308057785034\n","Epoch: 2, Loss: 0.6901134848594666\n","Epoch: 2, Loss: 0.6888290643692017\n","Epoch: 2, Loss: 0.668860912322998\n","Epoch: 2, Loss: 0.6767033934593201\n","Epoch: 2, Loss: 0.7249707579612732\n","Epoch: 2, Loss: 0.7423461079597473\n","Epoch: 2, Loss: 0.7236245274543762\n","Epoch: 2, Loss: 0.7410451173782349\n","Epoch: 2, Loss: 0.7305554151535034\n","Epoch: 2, Loss: 0.7166174054145813\n","Epoch: 2, Loss: 0.6413460373878479\n","Epoch: 2, Loss: 0.6937503814697266\n","Epoch: 2, Loss: 0.6782070398330688\n","Epoch: 2, Loss: 0.6989883780479431\n","Epoch: 2, Loss: 0.7159862518310547\n","Epoch: 2, Loss: 0.7255498170852661\n","Epoch: 2, Loss: 0.6530988812446594\n","Epoch: 2, Loss: 0.6817561388015747\n","Epoch: 2, Loss: 0.7103793025016785\n","Epoch: 2, Loss: 0.6665865778923035\n","Epoch: 2, Loss: 0.716120183467865\n","Epoch: 2, Loss: 0.6840366721153259\n","Epoch: 2, Loss: 0.7021533846855164\n","Epoch: 2, Loss: 0.6789063215255737\n","Epoch: 2, Loss: 0.6972132921218872\n","Epoch: 2, Loss: 0.7347924113273621\n","Epoch: 2, Loss: 0.7136483788490295\n","Epoch: 2, Loss: 0.7255877256393433\n","Epoch: 2, Loss: 0.6188889741897583\n","Epoch: 2, Loss: 0.7029950618743896\n","Epoch: 2, Loss: 0.6678417921066284\n","Epoch: 2, Loss: 0.6572028994560242\n","Epoch: 2, Loss: 0.6867008209228516\n","Epoch: 2, Loss: 0.7000330090522766\n","Epoch: 2, Loss: 0.7322234511375427\n","Epoch: 2, Loss: 0.7103161811828613\n","Epoch: 2, Loss: 0.7195606827735901\n","Epoch: 2, Loss: 0.6991640329360962\n","Epoch: 2, Loss: 0.6887741684913635\n","Epoch: 2, Loss: 0.6900816559791565\n","Epoch: 2, Loss: 0.6421126127243042\n","Epoch: 2, Loss: 0.7130293250083923\n","Epoch: 2, Loss: 0.7072534561157227\n","Epoch: 2, Loss: 0.6981549859046936\n","Epoch: 2, Loss: 0.7205353379249573\n","Epoch: 2, Loss: 0.7106936573982239\n","Epoch: 2, Loss: 0.7120168805122375\n","Epoch: 2, Loss: 0.6761366724967957\n","Epoch: 2, Loss: 0.761757493019104\n","Epoch: 2, Loss: 0.7207263708114624\n","Epoch: 2, Loss: 0.736443042755127\n","Epoch: 2, Loss: 0.7240371704101562\n","Epoch: 2, Loss: 0.716357946395874\n","Epoch: 2, Loss: 0.6793933510780334\n","Epoch: 2, Loss: 0.7100353837013245\n","Epoch: 2, Loss: 0.6764198541641235\n","Epoch: 2, Loss: 0.7525461912155151\n","Epoch: 2, Loss: 0.7287648916244507\n","Epoch: 2, Loss: 0.6610317230224609\n","Epoch: 2, Loss: 0.6834763288497925\n","Epoch: 2, Loss: 0.6869933605194092\n","Epoch: 2, Loss: 0.6425821185112\n","Epoch: 2, Loss: 0.67144376039505\n","Epoch: 2, Loss: 0.6588376760482788\n","Epoch: 2, Loss: 0.7161063551902771\n","Epoch: 2, Loss: 0.6969031095504761\n","Epoch: 2, Loss: 0.7356888055801392\n","Epoch: 2, Loss: 0.6664894819259644\n","Epoch: 2, Loss: 0.6477370262145996\n","Epoch: 2, Loss: 0.7488619685173035\n","Epoch: 2, Loss: 0.6555824875831604\n","Epoch: 2, Loss: 0.6965892314910889\n","Epoch: 2, Loss: 0.7052218914031982\n","Epoch: 2, Loss: 0.6904965043067932\n","Epoch: 2, Loss: 0.6232166290283203\n","Epoch: 2, Loss: 0.7053492069244385\n","Epoch: 2, Loss: 0.718792736530304\n","Epoch: 2, Loss: 0.7526848912239075\n","Epoch: 2, Loss: 0.6180548667907715\n","Epoch: 2, Loss: 0.7182322144508362\n","Epoch: 2, Loss: 0.6773240566253662\n","Epoch: 2, Loss: 0.7094438672065735\n","Epoch: 2, Loss: 0.6733251810073853\n","Epoch: 2, Loss: 0.751926600933075\n","Epoch: 2, Loss: 0.6831233501434326\n","Epoch: 2, Loss: 0.705585777759552\n","Epoch: 2, Loss: 0.7184834480285645\n","Epoch: 2, Loss: 0.6838906407356262\n","Epoch: 2, Loss: 0.6662365198135376\n","Epoch: 2, Loss: 0.7026710510253906\n","Epoch: 2, Loss: 0.7518773674964905\n","Epoch: 2, Loss: 0.7258007526397705\n","Epoch: 2, Loss: 0.7045517563819885\n","Epoch: 2, Loss: 0.6681323051452637\n","Epoch: 2, Loss: 0.7052224278450012\n","Epoch: 2, Loss: 0.693980872631073\n","Epoch: 2, Loss: 0.6239210963249207\n","Epoch: 2, Loss: 0.7010436058044434\n","Epoch: 2, Loss: 0.6936525106430054\n","Epoch: 2, Loss: 0.6355552077293396\n","Epoch: 2, Loss: 0.5945414304733276\n","Epoch: 2, Loss: 0.6120041608810425\n","Epoch: 2, Loss: 0.7978335022926331\n","Epoch: 2, Loss: 0.6871652603149414\n","Epoch: 2, Loss: 0.7451242804527283\n","Epoch: 2, Loss: 0.7046687602996826\n","Epoch: 2, Loss: 0.7855274081230164\n","Epoch: 2, Loss: 0.6790949702262878\n","Epoch: 2, Loss: 0.6162298321723938\n","Epoch: 2, Loss: 0.6108000874519348\n","Epoch: 2, Loss: 0.6580671668052673\n","Epoch: 2, Loss: 0.6902953386306763\n","Epoch: 2, Loss: 0.6295502185821533\n","Epoch: 2, Loss: 0.6597748398780823\n","Epoch: 2, Loss: 0.7693699598312378\n","Epoch: 2, Loss: 0.741836428642273\n","Epoch: 2, Loss: 0.8171073198318481\n","Epoch: 2, Loss: 0.7606267929077148\n","Epoch: 2, Loss: 0.6875797510147095\n","Epoch: 2, Loss: 0.7199800610542297\n","Epoch: 2, Loss: 0.7162659764289856\n","Epoch: 2, Loss: 0.6639178395271301\n","Epoch: 2, Loss: 0.6984792947769165\n","Epoch: 2, Loss: 0.6504542231559753\n","Epoch: 2, Loss: 0.695801854133606\n","Epoch: 2, Loss: 0.6955456137657166\n","Epoch: 2, Loss: 0.6937903165817261\n","Epoch: 2, Loss: 0.6692541241645813\n","Epoch: 2, Loss: 0.7023744583129883\n","Epoch: 2, Loss: 0.717610239982605\n","Epoch: 2, Loss: 0.7629755139350891\n","Epoch: 2, Loss: 0.6783554553985596\n","Epoch: 2, Loss: 0.6419795751571655\n","Epoch: 2, Loss: 0.655609130859375\n","Epoch: 2, Loss: 0.6633586883544922\n","Epoch: 2, Loss: 0.6179840564727783\n","Epoch: 2, Loss: 0.680718183517456\n","Epoch: 2, Loss: 0.7798848748207092\n","Epoch: 2, Loss: 0.7100968360900879\n","Epoch: 2, Loss: 0.7380704879760742\n","Epoch: 2, Loss: 0.7499749660491943\n","Epoch: 2, Loss: 0.6217683553695679\n","Epoch: 2, Loss: 0.7648021578788757\n","Epoch: 2, Loss: 0.6832715272903442\n","Epoch: 2, Loss: 0.647955596446991\n","Epoch: 2, Loss: 0.7218023538589478\n","Epoch: 2, Loss: 0.7452983260154724\n","Epoch: 2, Loss: 0.7660439014434814\n","Epoch: 2, Loss: 0.6447322964668274\n","Epoch: 2, Loss: 0.7251787781715393\n","Epoch: 2, Loss: 0.7247818112373352\n","Epoch: 2, Loss: 0.6867696046829224\n","Epoch: 2, Loss: 0.6263976097106934\n","Epoch: 2, Loss: 0.6562027931213379\n","Epoch: 2, Loss: 0.7342444658279419\n","Epoch: 2, Loss: 0.6745532751083374\n","Epoch: 2, Loss: 0.6787087917327881\n","Epoch: 2, Loss: 0.6584228873252869\n","Epoch: 2, Loss: 0.6825585961341858\n","Epoch: 2, Loss: 0.6564306616783142\n","Epoch: 2, Loss: 0.6541592478752136\n","Epoch: 2, Loss: 0.6801109313964844\n","Epoch: 2, Loss: 0.665317177772522\n","Epoch: 2, Loss: 0.6137117147445679\n","Epoch: 2, Loss: 0.7692832946777344\n","Epoch: 2, Loss: 0.6678041815757751\n","Epoch: 2, Loss: 0.6636894941329956\n","Epoch: 2, Loss: 0.6274121999740601\n","Epoch: 2, Loss: 0.645133912563324\n","Epoch: 2, Loss: 0.678155243396759\n","Epoch: 2, Loss: 0.6222711801528931\n","Epoch: 2, Loss: 0.763927698135376\n","Epoch: 2, Loss: 0.7328696250915527\n","Epoch: 2, Loss: 0.7830085754394531\n","Epoch: 2, Loss: 0.7480298280715942\n","Epoch: 2, Loss: 0.6722666621208191\n","Epoch: 2, Loss: 0.7022947072982788\n","Epoch: 2, Loss: 0.732012152671814\n","Epoch: 2, Loss: 0.6921820044517517\n","Epoch: 2, Loss: 0.694739580154419\n","Epoch: 2, Loss: 0.7008875608444214\n","Epoch: 2, Loss: 0.7400988936424255\n","Epoch: 2, Loss: 0.691095232963562\n","Epoch: 2, Loss: 0.6543360948562622\n","Epoch: 2, Loss: 0.6806434392929077\n","Epoch: 2, Loss: 0.623921811580658\n","Epoch: 2, Loss: 0.7534633874893188\n","Epoch: 2, Loss: 0.6032300591468811\n","Epoch: 2, Loss: 0.7391626834869385\n","Epoch: 2, Loss: 0.8265407085418701\n","Epoch: 2, Loss: 0.7360820174217224\n","Epoch: 2, Loss: 0.5602930784225464\n","Epoch: 2, Loss: 0.5874765515327454\n","Epoch: 2, Loss: 0.7373364567756653\n","Epoch: 2, Loss: 0.7069147229194641\n","Epoch: 2, Loss: 0.6000468134880066\n","Epoch: 2, Loss: 0.6325674653053284\n","Epoch: 2, Loss: 0.7044386863708496\n","Epoch: 2, Loss: 0.7022104263305664\n","Epoch: 2, Loss: 0.6606345772743225\n","Epoch: 2, Loss: 0.6567342877388\n","Epoch: 2, Loss: 0.6296824216842651\n","Epoch: 2, Loss: 0.70956951379776\n","Epoch: 2, Loss: 0.7616190910339355\n","Epoch: 2, Loss: 0.7049886584281921\n","Epoch: 2, Loss: 0.7798622250556946\n","Epoch: 2, Loss: 0.6650465726852417\n","Epoch: 2, Loss: 0.6458534002304077\n","Epoch: 2, Loss: 0.643126368522644\n","Epoch: 2, Loss: 0.7361524105072021\n","Epoch: 2, Loss: 0.7079252600669861\n","Epoch: 2, Loss: 0.7376067638397217\n","Epoch: 2, Loss: 0.6744486689567566\n","Epoch: 2, Loss: 0.7140344381332397\n","Epoch: 2, Loss: 0.7158935070037842\n","Epoch: 2, Loss: 0.7656828761100769\n","Epoch: 2, Loss: 0.7273823618888855\n","Epoch: 2, Loss: 0.7478387951850891\n","Epoch: 2, Loss: 0.7792673110961914\n","Epoch: 2, Loss: 0.6992952823638916\n","Epoch: 2, Loss: 0.6621783375740051\n","Epoch: 2, Loss: 0.7067030668258667\n","Epoch: 2, Loss: 0.7478581666946411\n","Epoch: 2, Loss: 0.6857601404190063\n","Epoch: 2, Loss: 0.673685610294342\n","Epoch: 2, Loss: 0.7181822657585144\n","Epoch: 2, Loss: 0.7299075722694397\n","Epoch: 2, Loss: 0.7256584167480469\n","Epoch: 2, Loss: 0.6805899143218994\n","Epoch: 2, Loss: 0.6952862739562988\n","Epoch: 2, Loss: 0.6141272187232971\n","Epoch: 2, Loss: 0.6336597204208374\n","Epoch: 2, Loss: 0.6194977164268494\n","Epoch: 2, Loss: 0.5906535387039185\n","Epoch: 2, Loss: 0.6180735230445862\n","Epoch: 2, Loss: 0.8553275465965271\n","Epoch: 2, Loss: 0.49956950545310974\n","Epoch: 2, Loss: 0.745009183883667\n","Epoch: 2, Loss: 0.6566711664199829\n","Epoch: 2, Loss: 0.6668484210968018\n","Epoch: 2, Loss: 0.8172110319137573\n","Epoch: 2, Loss: 0.8099809288978577\n","Epoch: 2, Loss: 0.696820855140686\n","Epoch: 2, Loss: 0.7339445352554321\n","Epoch: 2, Loss: 0.7826772332191467\n","Epoch: 2, Loss: 0.713604748249054\n","Epoch: 2, Loss: 0.6733296513557434\n","Epoch: 2, Loss: 0.6594992876052856\n","Epoch: 2, Loss: 0.7841066122055054\n","Epoch: 2, Loss: 0.7389326095581055\n","Epoch: 2, Loss: 0.7048088312149048\n","Epoch: 2, Loss: 0.6808237433433533\n","Epoch: 2, Loss: 0.8183950185775757\n","Epoch: 2, Loss: 0.6914356350898743\n","Epoch: 2, Loss: 0.7101709842681885\n","Epoch: 2, Loss: 0.7389185428619385\n","Epoch: 2, Loss: 0.7206860780715942\n","Epoch: 2, Loss: 0.7229046821594238\n","Epoch: 2, Loss: 0.7207891941070557\n","Epoch: 2, Loss: 0.7260786890983582\n","Epoch: 2, Loss: 0.6891543865203857\n","Epoch: 2, Loss: 0.7544482946395874\n","Epoch: 2, Loss: 0.6330347657203674\n","Epoch: 2, Loss: 0.6931092739105225\n","Epoch: 2, Loss: 0.6743803024291992\n","Epoch: 2, Loss: 0.6871064901351929\n","Epoch: 2, Loss: 0.6941614151000977\n","Epoch: 2, Loss: 0.7224712371826172\n","Epoch: 2, Loss: 0.7331736087799072\n","Epoch: 2, Loss: 0.7081753015518188\n","Epoch: 2, Loss: 0.6638691425323486\n","Epoch: 2, Loss: 0.7385197281837463\n","Epoch: 2, Loss: 0.6857292056083679\n","Epoch: 2, Loss: 0.7462196350097656\n","Epoch: 2, Loss: 0.7549513578414917\n","Epoch: 2, Loss: 0.7419078350067139\n","Epoch: 2, Loss: 0.7317388653755188\n","Epoch: 2, Loss: 0.713408350944519\n","Epoch: 2, Loss: 0.7094838619232178\n","Epoch: 2, Loss: 0.7332533001899719\n","Epoch: 2, Loss: 0.6861640214920044\n","Epoch: 2, Loss: 0.7463009357452393\n","Epoch: 2, Loss: 0.6691944599151611\n","Epoch: 2, Loss: 0.7010411024093628\n","Epoch: 2, Loss: 0.650682270526886\n","Epoch: 2, Loss: 0.6944230794906616\n","Epoch: 2, Loss: 0.672225296497345\n","Epoch: 2, Loss: 0.659248948097229\n","Epoch: 2, Loss: 0.7542301416397095\n","Epoch: 2, Loss: 0.6562250852584839\n","Epoch: 2, Loss: 0.6529957056045532\n","Epoch: 2, Loss: 0.7248629331588745\n","Epoch: 2, Loss: 0.6956644058227539\n","Epoch: 2, Loss: 0.6734216809272766\n","Epoch: 2, Loss: 0.7816771268844604\n","Epoch: 2, Loss: 0.6289172768592834\n","Epoch: 2, Loss: 0.6274425387382507\n","Epoch: 2, Loss: 0.6455032229423523\n","Epoch: 2, Loss: 0.733354926109314\n","Epoch: 2, Loss: 0.7022672891616821\n","Epoch: 2, Loss: 0.8428211212158203\n","Epoch: 2, Loss: 0.7590299248695374\n","Epoch: 2, Loss: 0.7476683855056763\n","Epoch: 2, Loss: 0.7426969408988953\n","Epoch: 2, Loss: 0.7219324707984924\n","Epoch: 2, Loss: 0.6769421696662903\n","Epoch: 2, Loss: 0.672966718673706\n","Epoch: 2, Loss: 0.7006433606147766\n","Epoch: 2, Loss: 0.6645488739013672\n","Epoch: 2, Loss: 0.6776214838027954\n","Epoch: 2, Loss: 0.7279965281486511\n","Epoch: 2, Loss: 0.6653580069541931\n","Epoch: 2, Loss: 0.6807064414024353\n","Epoch: 2, Loss: 0.723686933517456\n","Epoch: 2, Loss: 0.7162286639213562\n","Epoch: 2, Loss: 0.6925843358039856\n","Epoch: 2, Loss: 0.6697007417678833\n","Epoch: 2, Loss: 0.7512969970703125\n","Epoch: 2, Loss: 0.7393299341201782\n","Epoch: 2, Loss: 0.7150620222091675\n","Epoch: 2, Loss: 0.7480840086936951\n","Epoch: 2, Loss: 0.6313660740852356\n","Epoch: 2, Loss: 0.6802171468734741\n","Epoch: 2, Loss: 0.675148069858551\n","Epoch: 2, Loss: 0.6568483710289001\n","Epoch: 2, Loss: 0.6859946846961975\n","Epoch: 2, Loss: 0.6908209919929504\n","Epoch: 2, Loss: 0.707484781742096\n","Epoch: 2, Loss: 0.7334405183792114\n","Epoch: 2, Loss: 0.7074453830718994\n","Epoch: 2, Loss: 0.7200555205345154\n","Epoch: 2, Loss: 0.6981135606765747\n","Epoch: 2, Loss: 0.7331603765487671\n","Epoch: 2, Loss: 0.7309191226959229\n","Epoch: 2, Loss: 0.6793752908706665\n","Epoch: 2, Loss: 0.6856259703636169\n","Epoch: 2, Loss: 0.655933141708374\n","Epoch: 2, Loss: 0.7193315029144287\n","Epoch: 2, Loss: 0.7038840055465698\n","Epoch: 2, Loss: 0.7017334699630737\n","Epoch: 2, Loss: 0.655300498008728\n","Epoch: 2, Loss: 0.6453725099563599\n","Epoch: 2, Loss: 0.7342097163200378\n","Epoch: 2, Loss: 0.704226016998291\n","Epoch: 2, Loss: 0.6672819256782532\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss: 0.6381915211677551\n","Epoch: 0, Loss: 0.6773461103439331\n","Epoch: 0, Loss: 0.7261770367622375\n","Epoch: 0, Loss: 0.8103539943695068\n","Epoch: 0, Loss: 0.7097475528717041\n","Epoch: 0, Loss: 0.7060690522193909\n","Epoch: 0, Loss: 0.6940104961395264\n","Epoch: 0, Loss: 0.7255996465682983\n","Epoch: 0, Loss: 0.5800290107727051\n","Epoch: 0, Loss: 0.7122715711593628\n","Epoch: 0, Loss: 0.6407536268234253\n","Epoch: 0, Loss: 0.8295813798904419\n","Epoch: 0, Loss: 0.8265315294265747\n","Epoch: 0, Loss: 0.8006658554077148\n","Epoch: 0, Loss: 0.6460821032524109\n","Epoch: 0, Loss: 0.6495458483695984\n","Epoch: 0, Loss: 0.830792248249054\n","Epoch: 0, Loss: 0.6973820924758911\n","Epoch: 0, Loss: 0.7540647983551025\n","Epoch: 0, Loss: 0.7883762121200562\n","Epoch: 0, Loss: 0.6903672218322754\n","Epoch: 0, Loss: 0.7147390842437744\n","Epoch: 0, Loss: 0.7073312997817993\n","Epoch: 0, Loss: 0.7124758362770081\n","Epoch: 0, Loss: 0.6670262813568115\n","Epoch: 0, Loss: 0.7734679579734802\n","Epoch: 0, Loss: 0.6931817531585693\n","Epoch: 0, Loss: 0.7238274216651917\n","Epoch: 0, Loss: 0.6962254047393799\n","Epoch: 0, Loss: 0.7643163204193115\n","Epoch: 0, Loss: 0.6549773216247559\n","Epoch: 0, Loss: 0.674596905708313\n","Epoch: 0, Loss: 0.720497190952301\n","Epoch: 0, Loss: 0.7245609164237976\n","Epoch: 0, Loss: 0.7236152291297913\n","Epoch: 0, Loss: 0.7334640026092529\n","Epoch: 0, Loss: 0.7364049553871155\n","Epoch: 0, Loss: 0.6836097836494446\n","Epoch: 0, Loss: 0.6626477241516113\n","Epoch: 0, Loss: 0.7374513149261475\n","Epoch: 0, Loss: 0.6606339812278748\n","Epoch: 0, Loss: 0.687442421913147\n","Epoch: 0, Loss: 0.7178276181221008\n","Epoch: 0, Loss: 0.6800304651260376\n","Epoch: 0, Loss: 0.6937727928161621\n","Epoch: 0, Loss: 0.6906698346138\n","Epoch: 0, Loss: 0.7902665138244629\n","Epoch: 0, Loss: 0.7500845193862915\n","Epoch: 0, Loss: 0.7727092504501343\n","Epoch: 0, Loss: 0.668362021446228\n","Epoch: 0, Loss: 0.6856762170791626\n","Epoch: 0, Loss: 0.6816865801811218\n","Epoch: 0, Loss: 0.758050799369812\n","Epoch: 0, Loss: 0.6778521537780762\n","Epoch: 0, Loss: 0.6616353988647461\n","Epoch: 0, Loss: 0.7756598591804504\n","Epoch: 0, Loss: 0.6797223687171936\n","Epoch: 0, Loss: 0.6424301862716675\n","Epoch: 0, Loss: 0.7838923335075378\n","Epoch: 0, Loss: 0.6538242101669312\n","Epoch: 0, Loss: 0.6347708106040955\n","Epoch: 0, Loss: 0.6690437197685242\n","Epoch: 0, Loss: 0.6806052923202515\n","Epoch: 0, Loss: 0.7276402711868286\n","Epoch: 0, Loss: 0.7153863310813904\n","Epoch: 0, Loss: 0.6094344258308411\n","Epoch: 0, Loss: 0.7979201078414917\n","Epoch: 0, Loss: 0.6978969573974609\n","Epoch: 0, Loss: 0.7204367518424988\n","Epoch: 0, Loss: 0.6782678961753845\n","Epoch: 0, Loss: 0.7178813219070435\n","Epoch: 0, Loss: 0.6880531907081604\n","Epoch: 0, Loss: 0.7128161787986755\n","Epoch: 0, Loss: 0.7409325242042542\n","Epoch: 0, Loss: 0.6434458494186401\n","Epoch: 0, Loss: 0.7262059450149536\n","Epoch: 0, Loss: 0.6907913684844971\n","Epoch: 0, Loss: 0.7239784002304077\n","Epoch: 0, Loss: 0.709290087223053\n","Epoch: 0, Loss: 0.6911489963531494\n","Epoch: 0, Loss: 0.699036717414856\n","Epoch: 0, Loss: 0.7047457098960876\n","Epoch: 0, Loss: 0.6760318875312805\n","Epoch: 0, Loss: 0.747051477432251\n","Epoch: 0, Loss: 0.7157269716262817\n","Epoch: 0, Loss: 0.702048659324646\n","Epoch: 0, Loss: 0.7790181636810303\n","Epoch: 0, Loss: 0.6178502440452576\n","Epoch: 0, Loss: 0.686231255531311\n","Epoch: 0, Loss: 0.732017993927002\n","Epoch: 0, Loss: 0.6583282351493835\n","Epoch: 0, Loss: 0.6958897113800049\n","Epoch: 0, Loss: 0.6824969053268433\n","Epoch: 0, Loss: 0.7175533771514893\n","Epoch: 0, Loss: 0.6952515840530396\n","Epoch: 0, Loss: 0.6774831414222717\n","Epoch: 0, Loss: 0.7400336861610413\n","Epoch: 0, Loss: 0.7516721487045288\n","Epoch: 0, Loss: 0.6481072902679443\n","Epoch: 0, Loss: 0.719478964805603\n","Epoch: 0, Loss: 0.7296229004859924\n","Epoch: 0, Loss: 0.6834589242935181\n","Epoch: 0, Loss: 0.6959593892097473\n","Epoch: 0, Loss: 0.7462530136108398\n","Epoch: 0, Loss: 0.6840354204177856\n","Epoch: 0, Loss: 0.7015933394432068\n","Epoch: 0, Loss: 0.6941236257553101\n","Epoch: 0, Loss: 0.7335970401763916\n","Epoch: 0, Loss: 0.6915417313575745\n","Epoch: 0, Loss: 0.7321904897689819\n","Epoch: 0, Loss: 0.7044243812561035\n","Epoch: 0, Loss: 0.6933581829071045\n","Epoch: 0, Loss: 0.6806435585021973\n","Epoch: 0, Loss: 0.7113527655601501\n","Epoch: 0, Loss: 0.6117343902587891\n","Epoch: 0, Loss: 0.7526572942733765\n","Epoch: 0, Loss: 0.7441962957382202\n","Epoch: 0, Loss: 0.6250787377357483\n","Epoch: 0, Loss: 0.7291278839111328\n","Epoch: 0, Loss: 0.6279920935630798\n","Epoch: 0, Loss: 0.693651556968689\n","Epoch: 0, Loss: 0.7455055117607117\n","Epoch: 0, Loss: 0.6928899884223938\n","Epoch: 0, Loss: 0.6818843483924866\n","Epoch: 0, Loss: 0.7424677610397339\n","Epoch: 0, Loss: 0.7217766642570496\n","Epoch: 0, Loss: 0.6998509168624878\n","Epoch: 0, Loss: 0.6763800978660583\n","Epoch: 0, Loss: 0.7208766937255859\n","Epoch: 0, Loss: 0.6398073434829712\n","Epoch: 0, Loss: 0.7610535621643066\n","Epoch: 0, Loss: 0.6647987365722656\n","Epoch: 0, Loss: 0.7417179942131042\n","Epoch: 0, Loss: 0.697166383266449\n","Epoch: 0, Loss: 0.6933414936065674\n","Epoch: 0, Loss: 0.7472823262214661\n","Epoch: 0, Loss: 0.7109183669090271\n","Epoch: 0, Loss: 0.6640865802764893\n","Epoch: 0, Loss: 0.6583735942840576\n","Epoch: 0, Loss: 0.7149971723556519\n","Epoch: 0, Loss: 0.7053751945495605\n","Epoch: 0, Loss: 0.7310819625854492\n","Epoch: 0, Loss: 0.7053185105323792\n","Epoch: 0, Loss: 0.7141430377960205\n","Epoch: 0, Loss: 0.7723867893218994\n","Epoch: 0, Loss: 0.6748397350311279\n","Epoch: 0, Loss: 0.7355092763900757\n","Epoch: 0, Loss: 0.7016602754592896\n","Epoch: 0, Loss: 0.7040199041366577\n","Epoch: 0, Loss: 0.6690601110458374\n","Epoch: 0, Loss: 0.7439508438110352\n","Epoch: 0, Loss: 0.6416502594947815\n","Epoch: 0, Loss: 0.70905601978302\n","Epoch: 0, Loss: 0.7045315504074097\n","Epoch: 0, Loss: 0.6837018132209778\n","Epoch: 0, Loss: 0.6796522736549377\n","Epoch: 0, Loss: 0.7413328289985657\n","Epoch: 0, Loss: 0.6215999126434326\n","Epoch: 0, Loss: 0.6695656776428223\n","Epoch: 0, Loss: 0.7417418956756592\n","Epoch: 0, Loss: 0.7507284283638\n","Epoch: 0, Loss: 0.6721886396408081\n","Epoch: 0, Loss: 0.6607335805892944\n","Epoch: 0, Loss: 0.6958743929862976\n","Epoch: 0, Loss: 0.7582719326019287\n","Epoch: 0, Loss: 0.6924349665641785\n","Epoch: 0, Loss: 0.7400181889533997\n","Epoch: 0, Loss: 0.6607621312141418\n","Epoch: 0, Loss: 0.6709116101264954\n","Epoch: 0, Loss: 0.7146850824356079\n","Epoch: 0, Loss: 0.7259045243263245\n","Epoch: 0, Loss: 0.6907024383544922\n","Epoch: 0, Loss: 0.6794519424438477\n","Epoch: 0, Loss: 0.7475472688674927\n","Epoch: 0, Loss: 0.6523435115814209\n","Epoch: 0, Loss: 0.6753809452056885\n","Epoch: 0, Loss: 0.6519641280174255\n","Epoch: 0, Loss: 0.6516599655151367\n","Epoch: 0, Loss: 0.7670114636421204\n","Epoch: 0, Loss: 0.6875195503234863\n","Epoch: 0, Loss: 0.654952347278595\n","Epoch: 0, Loss: 0.7628254294395447\n","Epoch: 0, Loss: 0.6630153656005859\n","Epoch: 0, Loss: 0.5854331254959106\n","Epoch: 0, Loss: 0.676403284072876\n","Epoch: 0, Loss: 0.7364753484725952\n","Epoch: 0, Loss: 0.6132262945175171\n","Epoch: 0, Loss: 0.8407555818557739\n","Epoch: 0, Loss: 0.7619478106498718\n","Epoch: 0, Loss: 0.7810966968536377\n","Epoch: 0, Loss: 0.6857984662055969\n","Epoch: 0, Loss: 0.611336886882782\n","Epoch: 0, Loss: 0.6434685587882996\n","Epoch: 0, Loss: 0.7071606516838074\n","Epoch: 0, Loss: 0.6536137461662292\n","Epoch: 0, Loss: 0.6735758185386658\n","Epoch: 0, Loss: 0.6782166957855225\n","Epoch: 0, Loss: 0.6338130235671997\n","Epoch: 0, Loss: 0.8055190443992615\n","Epoch: 0, Loss: 0.658674418926239\n","Epoch: 0, Loss: 0.6926286220550537\n","Epoch: 0, Loss: 0.6859105229377747\n","Epoch: 0, Loss: 0.7588725090026855\n","Epoch: 0, Loss: 0.7454577088356018\n","Epoch: 0, Loss: 0.6060500741004944\n","Epoch: 0, Loss: 0.6895533800125122\n","Epoch: 0, Loss: 0.6675977110862732\n","Epoch: 0, Loss: 0.6825951337814331\n","Epoch: 0, Loss: 0.7423616051673889\n","Epoch: 0, Loss: 0.6238911151885986\n","Epoch: 0, Loss: 0.6951885223388672\n","Epoch: 0, Loss: 0.6907575726509094\n","Epoch: 0, Loss: 0.6922639608383179\n","Epoch: 0, Loss: 0.6773590445518494\n","Epoch: 0, Loss: 0.7896368503570557\n","Epoch: 0, Loss: 0.6939507722854614\n","Epoch: 0, Loss: 0.6942621469497681\n","Epoch: 0, Loss: 0.7875394225120544\n","Epoch: 0, Loss: 0.7336677312850952\n","Epoch: 0, Loss: 0.6985090374946594\n","Epoch: 0, Loss: 0.7163256406784058\n","Epoch: 0, Loss: 0.7017243504524231\n","Epoch: 0, Loss: 0.6604995727539062\n","Epoch: 0, Loss: 0.7723687887191772\n","Epoch: 0, Loss: 0.7509069442749023\n","Epoch: 0, Loss: 0.6243352293968201\n","Epoch: 0, Loss: 0.695027768611908\n","Epoch: 0, Loss: 0.6799004077911377\n","Epoch: 0, Loss: 0.7237216830253601\n","Epoch: 0, Loss: 0.7018791437149048\n","Epoch: 0, Loss: 0.750385046005249\n","Epoch: 0, Loss: 0.64925616979599\n","Epoch: 0, Loss: 0.6694070100784302\n","Epoch: 0, Loss: 0.7015374302864075\n","Epoch: 0, Loss: 0.6916404962539673\n","Epoch: 0, Loss: 0.6687527298927307\n","Epoch: 0, Loss: 0.6655889749526978\n","Epoch: 0, Loss: 0.7038359642028809\n","Epoch: 0, Loss: 0.8049353957176208\n","Epoch: 0, Loss: 0.7376496195793152\n","Epoch: 0, Loss: 0.6608325242996216\n","Epoch: 0, Loss: 0.7502017617225647\n","Epoch: 0, Loss: 0.6722568869590759\n","Epoch: 0, Loss: 0.7199916839599609\n","Epoch: 0, Loss: 0.6736066341400146\n","Epoch: 0, Loss: 0.6087641716003418\n","Epoch: 0, Loss: 0.6654373407363892\n","Epoch: 0, Loss: 0.7413352131843567\n","Epoch: 0, Loss: 0.6662026047706604\n","Epoch: 0, Loss: 0.6401520371437073\n","Epoch: 0, Loss: 0.6455882787704468\n","Epoch: 0, Loss: 0.6893576979637146\n","Epoch: 0, Loss: 0.7483481168746948\n","Epoch: 0, Loss: 0.6842756867408752\n","Epoch: 0, Loss: 0.7780995965003967\n","Epoch: 0, Loss: 0.6763001084327698\n","Epoch: 0, Loss: 0.7090469002723694\n","Epoch: 0, Loss: 0.6480575203895569\n","Epoch: 0, Loss: 0.736455500125885\n","Epoch: 0, Loss: 0.7074671983718872\n","Epoch: 0, Loss: 0.6692062616348267\n","Epoch: 0, Loss: 0.722771942615509\n","Epoch: 0, Loss: 0.6803383827209473\n","Epoch: 0, Loss: 0.7146483659744263\n","Epoch: 0, Loss: 0.7181937098503113\n","Epoch: 0, Loss: 0.6474318504333496\n","Epoch: 0, Loss: 0.6803585886955261\n","Epoch: 0, Loss: 0.7522642016410828\n","Epoch: 0, Loss: 0.7188551425933838\n","Epoch: 0, Loss: 0.660835862159729\n","Epoch: 0, Loss: 0.6901840567588806\n","Epoch: 0, Loss: 0.6502407789230347\n","Epoch: 0, Loss: 0.6673834919929504\n","Epoch: 0, Loss: 0.6905690431594849\n","Epoch: 0, Loss: 0.659940242767334\n","Epoch: 0, Loss: 0.7534405589103699\n","Epoch: 0, Loss: 0.790134608745575\n","Epoch: 0, Loss: 0.7156990766525269\n","Epoch: 0, Loss: 0.6232345700263977\n","Epoch: 0, Loss: 0.7389947175979614\n","Epoch: 0, Loss: 0.7145520448684692\n","Epoch: 0, Loss: 0.7352043986320496\n","Epoch: 0, Loss: 0.7123937606811523\n","Epoch: 0, Loss: 0.6859263181686401\n","Epoch: 0, Loss: 0.6711992025375366\n","Epoch: 0, Loss: 0.8086115121841431\n","Epoch: 0, Loss: 0.5855865478515625\n","Epoch: 0, Loss: 0.7505859136581421\n","Epoch: 0, Loss: 0.7278881669044495\n","Epoch: 0, Loss: 0.7188735008239746\n","Epoch: 0, Loss: 0.6484489440917969\n","Epoch: 0, Loss: 0.7264041304588318\n","Epoch: 0, Loss: 0.6513795256614685\n","Epoch: 0, Loss: 0.7012432217597961\n","Epoch: 0, Loss: 0.564037024974823\n","Epoch: 0, Loss: 0.9055258631706238\n","Epoch: 0, Loss: 0.7411733269691467\n","Epoch: 0, Loss: 0.8220620155334473\n","Epoch: 0, Loss: 0.6503140926361084\n","Epoch: 0, Loss: 0.6675392389297485\n","Epoch: 0, Loss: 0.6271296739578247\n","Epoch: 0, Loss: 0.7273247838020325\n","Epoch: 0, Loss: 0.7172070145606995\n","Epoch: 0, Loss: 0.7094124555587769\n","Epoch: 0, Loss: 0.7277500629425049\n","Epoch: 0, Loss: 0.6746003031730652\n","Epoch: 0, Loss: 0.687508225440979\n","Epoch: 0, Loss: 0.6432757377624512\n","Epoch: 0, Loss: 0.7015339732170105\n","Epoch: 0, Loss: 0.6606824398040771\n","Epoch: 0, Loss: 0.7122742533683777\n","Epoch: 0, Loss: 0.7678384780883789\n","Epoch: 0, Loss: 0.7155413031578064\n","Epoch: 0, Loss: 0.6594229340553284\n","Epoch: 0, Loss: 0.7049548029899597\n","Epoch: 0, Loss: 0.7515054941177368\n","Epoch: 0, Loss: 0.5859110355377197\n","Epoch: 0, Loss: 0.6709086894989014\n","Epoch: 0, Loss: 0.7336828112602234\n","Epoch: 0, Loss: 0.6255912780761719\n","Epoch: 0, Loss: 0.6493788957595825\n","Epoch: 0, Loss: 0.8272989988327026\n","Epoch: 0, Loss: 0.7647868990898132\n","Epoch: 0, Loss: 0.6717491745948792\n","Epoch: 0, Loss: 0.6890721917152405\n","Epoch: 0, Loss: 0.768134355545044\n","Epoch: 0, Loss: 0.6568558812141418\n","Epoch: 0, Loss: 0.6682230830192566\n","Epoch: 0, Loss: 0.6748155355453491\n","Epoch: 0, Loss: 0.6397501230239868\n","Epoch: 0, Loss: 0.6469619274139404\n","Epoch: 0, Loss: 0.6541564464569092\n","Epoch: 0, Loss: 0.6477058529853821\n","Epoch: 0, Loss: 0.6263328790664673\n","Epoch: 0, Loss: 0.6876380443572998\n","Epoch: 0, Loss: 0.6533527374267578\n","Epoch: 0, Loss: 0.7442210912704468\n","Epoch: 0, Loss: 0.6206240653991699\n","Epoch: 0, Loss: 0.7710732221603394\n","Epoch: 0, Loss: 0.703591525554657\n","Epoch: 0, Loss: 0.6583647727966309\n","Epoch: 0, Loss: 0.7419407367706299\n","Epoch: 0, Loss: 0.6470466256141663\n","Epoch: 0, Loss: 0.6635093092918396\n","Epoch: 0, Loss: 0.7017624974250793\n","Epoch: 0, Loss: 0.6437128186225891\n","Epoch: 0, Loss: 0.6665871143341064\n","Epoch: 0, Loss: 0.6487929224967957\n","Epoch: 0, Loss: 0.662211537361145\n","Epoch: 0, Loss: 0.686863899230957\n","Epoch: 0, Loss: 0.6039304733276367\n","Epoch: 0, Loss: 0.7289482355117798\n","Epoch: 0, Loss: 0.6864369511604309\n","Epoch: 0, Loss: 0.6481389403343201\n","Epoch: 0, Loss: 0.6038971543312073\n","Epoch: 0, Loss: 0.7448202967643738\n","Epoch: 0, Loss: 0.8517261147499084\n","Epoch: 0, Loss: 0.6743624210357666\n","Epoch: 0, Loss: 0.8040323853492737\n","Epoch: 0, Loss: 0.6611813306808472\n","Epoch: 0, Loss: 0.72574782371521\n","Epoch: 0, Loss: 0.7741372585296631\n","Epoch: 0, Loss: 0.6911706328392029\n","Epoch: 0, Loss: 0.6878647208213806\n","Epoch: 0, Loss: 0.7245211005210876\n","Epoch: 0, Loss: 0.7141554355621338\n","Epoch: 0, Loss: 0.7377809882164001\n","Epoch: 0, Loss: 0.7207097411155701\n","Epoch: 0, Loss: 0.7387098670005798\n","Epoch: 0, Loss: 0.7022987008094788\n","Epoch: 0, Loss: 0.6892381906509399\n","Epoch: 0, Loss: 0.7185494303703308\n","Epoch: 0, Loss: 0.7862313389778137\n","Epoch: 0, Loss: 0.6653908491134644\n","Epoch: 0, Loss: 0.716745913028717\n","Epoch: 0, Loss: 0.6732132434844971\n","Epoch: 0, Loss: 0.7664093971252441\n","Epoch: 0, Loss: 0.7845839262008667\n","Epoch: 0, Loss: 0.6812090277671814\n","Epoch: 0, Loss: 0.646843433380127\n","Epoch: 0, Loss: 0.7672860026359558\n","Epoch: 0, Loss: 0.6860744953155518\n","Epoch: 0, Loss: 0.6641235947608948\n","Epoch: 0, Loss: 0.6810615062713623\n","Epoch: 0, Loss: 0.6511672139167786\n","Epoch: 0, Loss: 0.7126795649528503\n","Epoch: 0, Loss: 0.6157787442207336\n","Epoch: 0, Loss: 0.7956414222717285\n","Epoch: 0, Loss: 0.6748725175857544\n","Epoch: 0, Loss: 0.8508776426315308\n","Epoch: 0, Loss: 0.8146630525588989\n","Epoch: 0, Loss: 0.7733676433563232\n","Epoch: 0, Loss: 0.7344834804534912\n","Epoch: 0, Loss: 0.8014246225357056\n","Epoch: 0, Loss: 0.6770937442779541\n","Epoch: 0, Loss: 0.6784883737564087\n","Epoch: 0, Loss: 0.6268838047981262\n","Epoch: 0, Loss: 0.6571072936058044\n","Epoch: 0, Loss: 0.7877972722053528\n","Epoch: 0, Loss: 0.512540876865387\n","Epoch: 0, Loss: 0.8178761005401611\n","Epoch: 0, Loss: 0.789115846157074\n","Epoch: 0, Loss: 0.6089329719543457\n","Epoch: 0, Loss: 0.6167292594909668\n","Epoch: 0, Loss: 0.7178715467453003\n","Epoch: 0, Loss: 0.5982840061187744\n","Epoch: 0, Loss: 0.7402967810630798\n","Epoch: 0, Loss: 0.6179844737052917\n","Epoch: 0, Loss: 0.580095648765564\n","Epoch: 0, Loss: 0.6272791624069214\n","Epoch: 0, Loss: 0.7372901439666748\n","Epoch: 0, Loss: 0.7040318250656128\n","Epoch: 0, Loss: 0.6678353548049927\n","Epoch: 0, Loss: 0.6884620785713196\n","Epoch: 0, Loss: 0.8249678015708923\n","Epoch: 0, Loss: 0.8101709485054016\n","Epoch: 0, Loss: 0.6898945569992065\n","Epoch: 0, Loss: 0.8436233997344971\n","Epoch: 0, Loss: 0.6090764403343201\n","Epoch: 0, Loss: 0.6635609865188599\n","Epoch: 0, Loss: 0.701614499092102\n","Epoch: 0, Loss: 0.6990907788276672\n","Epoch: 0, Loss: 0.7520368099212646\n","Epoch: 0, Loss: 0.8763802647590637\n","Epoch: 0, Loss: 0.695326566696167\n","Epoch: 0, Loss: 0.688356876373291\n","Epoch: 0, Loss: 0.6302987337112427\n","Epoch: 0, Loss: 0.715469241142273\n","Epoch: 0, Loss: 0.7206770181655884\n","Epoch: 0, Loss: 0.7963534593582153\n","Epoch: 0, Loss: 0.7425915002822876\n","Epoch: 0, Loss: 0.7424635887145996\n","Epoch: 0, Loss: 0.6598911285400391\n","Epoch: 0, Loss: 0.6412017941474915\n","Epoch: 0, Loss: 0.6821274161338806\n","Epoch: 0, Loss: 0.7487168312072754\n","Epoch: 0, Loss: 0.7324812412261963\n","Epoch: 0, Loss: 0.7282108068466187\n","Epoch: 0, Loss: 0.7042469382286072\n","Epoch: 0, Loss: 0.6942174434661865\n","Epoch: 0, Loss: 0.627311646938324\n","Epoch: 0, Loss: 0.6651729345321655\n","Epoch: 0, Loss: 0.7675645351409912\n","Epoch: 0, Loss: 0.7246109247207642\n","Epoch: 0, Loss: 0.685880184173584\n","Epoch: 0, Loss: 0.8535299897193909\n","Epoch: 0, Loss: 0.7713172435760498\n","Epoch: 0, Loss: 0.7437055706977844\n","Epoch: 0, Loss: 0.6936927437782288\n","Epoch: 0, Loss: 0.6876657605171204\n","Epoch: 0, Loss: 0.7042291164398193\n","Epoch: 0, Loss: 0.7886667847633362\n","Epoch: 0, Loss: 0.7176496982574463\n","Epoch: 0, Loss: 0.6384990215301514\n","Epoch: 0, Loss: 0.7718515992164612\n","Epoch: 0, Loss: 0.6353264451026917\n","Epoch: 0, Loss: 0.6186127066612244\n","Epoch: 0, Loss: 0.8846709728240967\n","Epoch: 0, Loss: 0.6771280169487\n","Epoch: 0, Loss: 0.6586723327636719\n","Epoch: 0, Loss: 1.0865405797958374\n","Epoch: 0, Loss: 0.8531370162963867\n","Epoch: 0, Loss: 0.5216972827911377\n","Epoch: 0, Loss: 0.6161007285118103\n","Epoch: 0, Loss: 0.7576380968093872\n","Epoch: 0, Loss: 0.8593208193778992\n","Epoch: 0, Loss: 0.6805484294891357\n","Epoch: 0, Loss: 0.6364341378211975\n","Epoch: 0, Loss: 0.7054964303970337\n","Epoch: 0, Loss: 0.7541643977165222\n","Epoch: 0, Loss: 0.7382192611694336\n","Epoch: 0, Loss: 0.7173634171485901\n","Epoch: 0, Loss: 0.6312210559844971\n","Epoch: 0, Loss: 0.7145301103591919\n","Epoch: 0, Loss: 0.6707257032394409\n","Epoch: 0, Loss: 0.829359233379364\n","Epoch: 0, Loss: 0.7267460227012634\n","Epoch: 0, Loss: 0.5948202013969421\n","Epoch: 0, Loss: 0.790878415107727\n","Epoch: 0, Loss: 0.6721910238265991\n","Epoch: 0, Loss: 0.6625657081604004\n","Epoch: 0, Loss: 0.521725058555603\n","Epoch: 0, Loss: 0.7881402969360352\n","Epoch: 0, Loss: 0.7017157077789307\n","Epoch: 0, Loss: 0.8002387881278992\n","Epoch: 0, Loss: 0.5886672139167786\n","Epoch: 0, Loss: 0.8750923871994019\n","Epoch: 0, Loss: 0.737445592880249\n","Epoch: 0, Loss: 0.6899361610412598\n","Epoch: 0, Loss: 0.7117539048194885\n","Epoch: 0, Loss: 0.7256444692611694\n","Epoch: 0, Loss: 0.8186128735542297\n","Epoch: 0, Loss: 0.6999080777168274\n","Epoch: 0, Loss: 0.6623421311378479\n","Epoch: 0, Loss: 0.6628612875938416\n","Epoch: 0, Loss: 0.6699493527412415\n","Epoch: 0, Loss: 0.6860179901123047\n","Epoch: 0, Loss: 0.6533017754554749\n","Epoch: 0, Loss: 0.6306048631668091\n","Epoch: 0, Loss: 0.7577372789382935\n","Epoch: 0, Loss: 0.8055090308189392\n","Epoch: 0, Loss: 0.7548062801361084\n","Epoch: 0, Loss: 0.6803306341171265\n","Epoch: 0, Loss: 0.6520493626594543\n","Epoch: 0, Loss: 0.6709336638450623\n","Epoch: 0, Loss: 0.7077817320823669\n","Epoch: 0, Loss: 0.7571715712547302\n","Epoch: 0, Loss: 0.7787356376647949\n","Epoch: 0, Loss: 0.6739474534988403\n","Epoch: 0, Loss: 0.7531503438949585\n","Epoch: 0, Loss: 0.6782991886138916\n","Epoch: 0, Loss: 0.6538893580436707\n","Epoch: 0, Loss: 0.684395432472229\n","Epoch: 0, Loss: 0.6558263301849365\n","Epoch: 0, Loss: 0.6731753349304199\n","Epoch: 0, Loss: 0.6626582145690918\n","Epoch: 0, Loss: 0.7534996867179871\n","Epoch: 0, Loss: 0.6551355719566345\n","Epoch: 0, Loss: 0.9200122952461243\n","Epoch: 0, Loss: 0.6942642331123352\n","Epoch: 0, Loss: 0.6567409038543701\n","Epoch: 0, Loss: 0.7049674987792969\n","Epoch: 0, Loss: 0.7761315703392029\n","Epoch: 0, Loss: 0.6208292245864868\n","Epoch: 0, Loss: 0.6955550909042358\n","Epoch: 0, Loss: 0.7152845859527588\n","Epoch: 0, Loss: 0.6774319410324097\n","Epoch: 0, Loss: 0.7193772792816162\n","Epoch: 0, Loss: 0.7801011204719543\n","Epoch: 0, Loss: 0.7088942527770996\n","Epoch: 0, Loss: 0.6521648168563843\n","Epoch: 0, Loss: 0.7552222609519958\n","Epoch: 0, Loss: 0.7170214056968689\n","Epoch: 0, Loss: 0.7358438372612\n","Epoch: 0, Loss: 0.7194730639457703\n","Epoch: 0, Loss: 0.7176027894020081\n","Epoch: 0, Loss: 0.6706061959266663\n","Epoch: 0, Loss: 0.6493449807167053\n","Epoch: 0, Loss: 0.6875913739204407\n","Epoch: 0, Loss: 0.7106484174728394\n","Epoch: 0, Loss: 0.7284733057022095\n","Epoch: 0, Loss: 0.6575014591217041\n","Epoch: 0, Loss: 0.6718834638595581\n","Epoch: 0, Loss: 0.70701003074646\n","Epoch: 0, Loss: 0.697053849697113\n","Epoch: 0, Loss: 0.793109118938446\n","Epoch: 0, Loss: 0.7072694301605225\n","Epoch: 0, Loss: 0.7310600876808167\n","Epoch: 0, Loss: 0.748344898223877\n","Epoch: 0, Loss: 0.7244682312011719\n","Epoch: 0, Loss: 0.6330512762069702\n","Epoch: 0, Loss: 0.6966133117675781\n","Epoch: 0, Loss: 0.6525536775588989\n","Epoch: 0, Loss: 0.7471895217895508\n","Epoch: 0, Loss: 0.6617783308029175\n","Epoch: 0, Loss: 0.68377685546875\n","Epoch: 0, Loss: 0.7277724742889404\n","Epoch: 0, Loss: 0.7510220408439636\n","Epoch: 0, Loss: 0.7422835230827332\n","Epoch: 0, Loss: 0.606256902217865\n","Epoch: 0, Loss: 0.7913267612457275\n","Epoch: 0, Loss: 0.693500816822052\n","Epoch: 0, Loss: 0.702284038066864\n","Epoch: 0, Loss: 0.8515812158584595\n","Epoch: 0, Loss: 0.9164477586746216\n","Epoch: 0, Loss: 0.700434148311615\n","Epoch: 0, Loss: 0.6772021055221558\n","Epoch: 0, Loss: 0.716961145401001\n","Epoch: 0, Loss: 0.7197490334510803\n","Epoch: 0, Loss: 0.7211726307868958\n","Epoch: 0, Loss: 0.7604227066040039\n","Epoch: 0, Loss: 0.6922188997268677\n","Epoch: 0, Loss: 0.619700014591217\n","Epoch: 0, Loss: 0.6866111755371094\n","Epoch: 0, Loss: 0.7118220329284668\n","Epoch: 0, Loss: 0.6062164306640625\n","Epoch: 0, Loss: 0.7049034833908081\n","Epoch: 0, Loss: 0.6971437335014343\n","Epoch: 0, Loss: 0.7006558179855347\n","Epoch: 0, Loss: 0.6636768579483032\n","Epoch: 0, Loss: 0.6431958079338074\n","Epoch: 0, Loss: 0.7222961187362671\n","Epoch: 0, Loss: 0.7261914014816284\n","Epoch: 0, Loss: 0.7366212606430054\n","Epoch: 0, Loss: 0.6836973428726196\n","Epoch: 0, Loss: 0.7626243829727173\n","Epoch: 0, Loss: 0.7653186321258545\n","Epoch: 0, Loss: 0.6685009002685547\n","Epoch: 0, Loss: 0.6934635639190674\n","Epoch: 0, Loss: 0.6227113604545593\n","Epoch: 0, Loss: 0.7320508360862732\n","Epoch: 0, Loss: 0.6993748545646667\n","Epoch: 0, Loss: 0.6659764647483826\n","Epoch: 0, Loss: 0.7045267820358276\n","Epoch: 0, Loss: 0.7543413043022156\n","Epoch: 0, Loss: 0.6424691677093506\n","Epoch: 0, Loss: 0.6870681047439575\n","Epoch: 0, Loss: 0.6305369734764099\n","Epoch: 0, Loss: 0.6671749353408813\n","Epoch: 0, Loss: 0.7175567746162415\n","Epoch: 0, Loss: 0.6047918200492859\n","Epoch: 0, Loss: 0.7046926021575928\n","Epoch: 0, Loss: 0.7034721374511719\n","Epoch: 0, Loss: 0.8054371476173401\n","Epoch: 0, Loss: 0.729150116443634\n","Epoch: 0, Loss: 0.6145414113998413\n","Epoch: 0, Loss: 0.7342401742935181\n","Epoch: 0, Loss: 0.675345778465271\n","Epoch: 0, Loss: 0.6609972715377808\n","Epoch: 0, Loss: 0.7192363739013672\n","Epoch: 0, Loss: 0.7282393574714661\n","Epoch: 0, Loss: 0.7261927127838135\n","Epoch: 0, Loss: 0.6374045610427856\n","Epoch: 0, Loss: 0.7523139715194702\n","Epoch: 0, Loss: 0.7420849800109863\n","Epoch: 0, Loss: 0.741838812828064\n","Epoch: 0, Loss: 0.7868706583976746\n","Epoch: 0, Loss: 0.7241973280906677\n","Epoch: 0, Loss: 0.6627246737480164\n","Epoch: 0, Loss: 0.6320652961730957\n","Epoch: 0, Loss: 0.6763778328895569\n","Epoch: 0, Loss: 0.6811297535896301\n","Epoch: 0, Loss: 0.7027194499969482\n","Epoch: 0, Loss: 0.704985499382019\n","Epoch: 0, Loss: 0.6775165796279907\n","Epoch: 0, Loss: 0.6992466449737549\n","Epoch: 0, Loss: 0.6230732202529907\n","Epoch: 0, Loss: 0.6653400659561157\n","Epoch: 0, Loss: 0.7023955583572388\n","Epoch: 0, Loss: 0.7678312659263611\n","Epoch: 0, Loss: 0.6496360301971436\n","Epoch: 0, Loss: 0.7243756055831909\n","Epoch: 0, Loss: 0.6776654720306396\n","Epoch: 0, Loss: 0.6977648735046387\n","Epoch: 0, Loss: 0.6930797100067139\n","Epoch: 0, Loss: 0.7146323323249817\n","Epoch: 0, Loss: 0.71577388048172\n","Epoch: 0, Loss: 0.727600634098053\n","Epoch: 0, Loss: 0.7303838133811951\n","Epoch: 0, Loss: 0.6824785470962524\n","Epoch: 0, Loss: 0.7046403884887695\n","Epoch: 0, Loss: 0.7825303673744202\n","Epoch: 0, Loss: 0.74452143907547\n","Epoch: 0, Loss: 0.6759551763534546\n","Epoch: 0, Loss: 0.7257430553436279\n","Epoch: 0, Loss: 0.7539001703262329\n","Epoch: 0, Loss: 0.7368271350860596\n","Epoch: 0, Loss: 0.6889643669128418\n","Epoch: 0, Loss: 0.6533951163291931\n","Epoch: 0, Loss: 0.6674199104309082\n","Epoch: 0, Loss: 0.750314474105835\n","Epoch: 0, Loss: 0.7312315106391907\n","Epoch: 0, Loss: 0.6849508285522461\n","Epoch: 0, Loss: 0.6886748671531677\n","Epoch: 0, Loss: 0.7068909406661987\n","Epoch: 0, Loss: 0.6863376498222351\n","Epoch: 0, Loss: 0.7288880348205566\n","Epoch: 0, Loss: 0.7305856347084045\n","Epoch: 0, Loss: 0.7192225456237793\n","Epoch: 0, Loss: 0.6791249513626099\n","Epoch: 0, Loss: 0.6430748701095581\n","Epoch: 0, Loss: 0.7588083148002625\n","Epoch: 0, Loss: 0.6026719212532043\n","Epoch: 0, Loss: 0.6261082291603088\n","Epoch: 0, Loss: 0.7425598502159119\n","Epoch: 0, Loss: 0.7718865871429443\n","Epoch: 0, Loss: 0.7015801668167114\n","Epoch: 0, Loss: 0.7087198495864868\n","Epoch: 0, Loss: 0.6270765066146851\n","Epoch: 0, Loss: 0.6912028789520264\n","Epoch: 0, Loss: 0.7040277719497681\n","Epoch: 0, Loss: 0.7703359723091125\n","Epoch: 0, Loss: 0.6728171706199646\n","Epoch: 0, Loss: 0.6915899515151978\n","Epoch: 0, Loss: 0.598309338092804\n","Epoch: 0, Loss: 0.6653469204902649\n","Epoch: 0, Loss: 0.7748795747756958\n","Epoch: 0, Loss: 0.6390174627304077\n","Epoch: 0, Loss: 0.6849275827407837\n","Epoch: 0, Loss: 0.7456228137016296\n","Epoch: 0, Loss: 0.7008228302001953\n","Epoch: 0, Loss: 0.7396780848503113\n","Epoch: 0, Loss: 0.7342543005943298\n","Epoch: 0, Loss: 0.6777445077896118\n","Epoch: 0, Loss: 0.6184340119361877\n","Epoch: 0, Loss: 0.7209927439689636\n","Epoch: 0, Loss: 0.6860901713371277\n","Epoch: 0, Loss: 0.6402238607406616\n","Epoch: 0, Loss: 0.7186893224716187\n","Epoch: 0, Loss: 0.6637778282165527\n","Epoch: 0, Loss: 0.8089978694915771\n","Epoch: 0, Loss: 0.7150723338127136\n","Epoch: 0, Loss: 0.6303630471229553\n","Epoch: 0, Loss: 0.6637975573539734\n","Epoch: 0, Loss: 0.7033843994140625\n","Epoch: 0, Loss: 0.6155481338500977\n","Epoch: 0, Loss: 0.6783729791641235\n","Epoch: 0, Loss: 0.6861494779586792\n","Epoch: 0, Loss: 0.6592532992362976\n","Epoch: 0, Loss: 0.6002950668334961\n","Epoch: 0, Loss: 0.7295218706130981\n","Epoch: 0, Loss: 0.7908443808555603\n","Epoch: 0, Loss: 0.6416271924972534\n","Epoch: 0, Loss: 0.7175849080085754\n","Epoch: 0, Loss: 0.7521770000457764\n","Epoch: 0, Loss: 0.7836148738861084\n","Epoch: 0, Loss: 0.7514970302581787\n","Epoch: 0, Loss: 0.7904316186904907\n","Epoch: 0, Loss: 0.7048800587654114\n","Epoch: 0, Loss: 0.7176113128662109\n","Epoch: 0, Loss: 0.8068338632583618\n","Epoch: 0, Loss: 0.6824231147766113\n","Epoch: 0, Loss: 0.7046574354171753\n","Epoch: 0, Loss: 0.6934881210327148\n","Epoch: 0, Loss: 0.728568971157074\n","Epoch: 0, Loss: 0.7298089265823364\n","Epoch: 0, Loss: 0.6940963268280029\n","Epoch: 0, Loss: 0.7678549885749817\n","Epoch: 0, Loss: 0.7018778324127197\n","Epoch: 0, Loss: 0.7513399720191956\n","Epoch: 0, Loss: 0.7482969164848328\n","Epoch: 0, Loss: 0.7040905356407166\n","Epoch: 0, Loss: 0.6894925832748413\n","Epoch: 0, Loss: 0.7545688152313232\n","Epoch: 0, Loss: 0.7527994513511658\n","Epoch: 0, Loss: 0.6460784673690796\n","Epoch: 0, Loss: 0.628766655921936\n","Epoch: 0, Loss: 0.6573176383972168\n","Epoch: 0, Loss: 0.6730673909187317\n","Epoch: 0, Loss: 0.7234514951705933\n","Epoch: 0, Loss: 0.6826804280281067\n","Epoch: 0, Loss: 0.6846064329147339\n","Epoch: 0, Loss: 0.6547623872756958\n","Epoch: 0, Loss: 0.6590585708618164\n","Epoch: 0, Loss: 0.6316025853157043\n","Epoch: 0, Loss: 0.672322690486908\n","Epoch: 0, Loss: 0.7414539456367493\n","Epoch: 0, Loss: 0.6424987316131592\n","Epoch: 0, Loss: 0.7183355093002319\n","Epoch: 0, Loss: 0.7786210179328918\n","Epoch: 0, Loss: 0.8547348976135254\n","Epoch: 0, Loss: 0.6686221361160278\n","Epoch: 0, Loss: 0.7547757625579834\n","Epoch: 0, Loss: 0.7628253698348999\n","Epoch: 0, Loss: 0.6303137540817261\n","Epoch: 0, Loss: 0.6826925277709961\n","Epoch: 0, Loss: 0.588990330696106\n","Epoch: 0, Loss: 0.7774257063865662\n","Epoch: 0, Loss: 0.753049373626709\n","Epoch: 0, Loss: 0.6933025121688843\n","Epoch: 0, Loss: 0.7097105979919434\n","Epoch: 0, Loss: 0.7382756471633911\n","Epoch: 0, Loss: 0.7053148746490479\n","Epoch: 0, Loss: 0.7071534991264343\n","Epoch: 0, Loss: 0.6701774001121521\n","Epoch: 0, Loss: 0.7422792315483093\n","Epoch: 0, Loss: 0.7739028930664062\n","Epoch: 0, Loss: 0.6963788270950317\n","Epoch: 0, Loss: 0.678622841835022\n","Epoch: 0, Loss: 0.7179384827613831\n","Epoch: 0, Loss: 0.6230654716491699\n","Epoch: 0, Loss: 0.7646762132644653\n","Epoch: 0, Loss: 0.6945358514785767\n","Epoch: 0, Loss: 0.7256025075912476\n","Epoch: 0, Loss: 0.7980507612228394\n","Epoch: 0, Loss: 0.7608622312545776\n","Epoch: 0, Loss: 0.7880122065544128\n","Epoch: 0, Loss: 0.6985725164413452\n","Epoch: 0, Loss: 0.7139797210693359\n","Epoch: 0, Loss: 0.7259047627449036\n","Epoch: 0, Loss: 0.6876426935195923\n","Epoch: 0, Loss: 0.7031952738761902\n","Epoch: 0, Loss: 0.781505823135376\n","Epoch: 0, Loss: 0.6548798084259033\n","Epoch: 0, Loss: 0.7527427077293396\n","Epoch: 0, Loss: 0.706476628780365\n","Epoch: 0, Loss: 0.726832926273346\n","Epoch: 0, Loss: 0.8088524341583252\n","Epoch: 0, Loss: 0.6767808198928833\n","Epoch: 0, Loss: 0.6841087937355042\n","Epoch: 0, Loss: 0.672777533531189\n","Epoch: 0, Loss: 0.6284208297729492\n","Epoch: 0, Loss: 0.5829225182533264\n","Epoch: 0, Loss: 0.6370295286178589\n","Epoch: 0, Loss: 0.6688284277915955\n","Epoch: 0, Loss: 0.7066041827201843\n","Epoch: 0, Loss: 0.6485375165939331\n","Epoch: 0, Loss: 0.7636200189590454\n","Epoch: 0, Loss: 0.8737624287605286\n","Epoch: 0, Loss: 0.8181108236312866\n","Epoch: 0, Loss: 0.6122428178787231\n","Epoch: 0, Loss: 0.8504331111907959\n","Epoch: 0, Loss: 0.7197210788726807\n","Epoch: 0, Loss: 0.7896323800086975\n","Epoch: 0, Loss: 0.6401196122169495\n","Epoch: 0, Loss: 0.6587769389152527\n","Epoch: 0, Loss: 0.696533203125\n","Epoch: 0, Loss: 0.7294844388961792\n","Epoch: 0, Loss: 0.7086967825889587\n","Epoch: 0, Loss: 0.7396720051765442\n","Epoch: 0, Loss: 0.5856115221977234\n","Epoch: 0, Loss: 0.7253896594047546\n","Epoch: 0, Loss: 0.826281726360321\n","Epoch: 0, Loss: 0.7353945970535278\n","Epoch: 0, Loss: 0.7382111549377441\n","Epoch: 0, Loss: 0.7952460050582886\n","Epoch: 0, Loss: 0.6715395450592041\n","Epoch: 0, Loss: 0.6335915327072144\n","Epoch: 0, Loss: 0.7529111504554749\n","Epoch: 0, Loss: 0.6382908821105957\n","Epoch: 0, Loss: 0.6597490906715393\n","Epoch: 0, Loss: 0.6645622849464417\n","Epoch: 0, Loss: 0.7227175831794739\n","Epoch: 0, Loss: 0.7690463066101074\n","Epoch: 0, Loss: 0.7693033218383789\n","Epoch: 0, Loss: 0.6730380058288574\n","Epoch: 0, Loss: 0.6369332671165466\n","Epoch: 0, Loss: 0.7248724699020386\n","Epoch: 0, Loss: 0.6801424026489258\n","Epoch: 0, Loss: 0.8114417791366577\n","Epoch: 0, Loss: 0.6268392205238342\n","Epoch: 0, Loss: 0.6625685095787048\n","Epoch: 0, Loss: 0.807080864906311\n","Epoch: 0, Loss: 0.7000905871391296\n","Epoch: 0, Loss: 0.6802986860275269\n","Epoch: 0, Loss: 0.686392068862915\n","Epoch: 0, Loss: 0.6494885683059692\n","Epoch: 0, Loss: 0.7235251069068909\n","Epoch: 0, Loss: 0.6200360655784607\n","Epoch: 0, Loss: 0.7006738185882568\n","Epoch: 0, Loss: 0.7896319031715393\n","Epoch: 0, Loss: 0.6524401903152466\n","Epoch: 0, Loss: 0.6887084245681763\n","Epoch: 0, Loss: 0.7270954847335815\n","Epoch: 0, Loss: 0.6917427778244019\n","Epoch: 0, Loss: 0.7813985347747803\n","Epoch: 0, Loss: 0.7349768280982971\n","Epoch: 0, Loss: 0.6670842170715332\n","Epoch: 0, Loss: 0.6814829111099243\n","Epoch: 0, Loss: 0.7015371322631836\n","Epoch: 0, Loss: 0.5995776653289795\n","Epoch: 0, Loss: 0.7201068997383118\n","Epoch: 0, Loss: 0.6577109694480896\n","Epoch: 0, Loss: 0.6416876316070557\n","Epoch: 0, Loss: 0.667802095413208\n","Epoch: 0, Loss: 0.6272299885749817\n","Epoch: 0, Loss: 0.6761832237243652\n","Epoch: 0, Loss: 0.6411130428314209\n","Epoch: 0, Loss: 0.7161005139350891\n","Epoch: 0, Loss: 0.7215394973754883\n","Epoch: 0, Loss: 0.6674501895904541\n","Epoch: 0, Loss: 0.8082922697067261\n","Epoch: 0, Loss: 0.5363247990608215\n","Epoch: 0, Loss: 0.6562795639038086\n","Epoch: 0, Loss: 0.7059303522109985\n","Epoch: 0, Loss: 0.697632372379303\n","Epoch: 0, Loss: 0.7596927881240845\n","Epoch: 0, Loss: 0.6465932726860046\n","Epoch: 0, Loss: 0.7614144682884216\n","Epoch: 0, Loss: 0.7206911444664001\n","Epoch: 0, Loss: 0.7406551837921143\n","Epoch: 0, Loss: 0.639072835445404\n","Epoch: 0, Loss: 0.6575421094894409\n","Epoch: 0, Loss: 0.6472457647323608\n","Epoch: 0, Loss: 0.7082820534706116\n","Epoch: 0, Loss: 0.6471868753433228\n","Epoch: 0, Loss: 0.6903800368309021\n","Epoch: 0, Loss: 0.7768456339836121\n","Epoch: 0, Loss: 0.7511152029037476\n","Epoch: 0, Loss: 0.8498810529708862\n","Epoch: 0, Loss: 0.7932240962982178\n","Epoch: 0, Loss: 0.6841623187065125\n","Epoch: 0, Loss: 0.700336217880249\n","Epoch: 0, Loss: 0.7218902707099915\n","Epoch: 0, Loss: 0.7838392853736877\n","Epoch: 0, Loss: 0.6922764182090759\n","Epoch: 0, Loss: 0.7136375904083252\n","Epoch: 0, Loss: 0.6880713701248169\n","Epoch: 0, Loss: 0.6433477401733398\n","Epoch: 0, Loss: 0.664804220199585\n","Epoch: 0, Loss: 0.7356998920440674\n","Epoch: 0, Loss: 0.7152702212333679\n","Epoch: 0, Loss: 0.7008439302444458\n","Epoch: 0, Loss: 0.6501071453094482\n","Epoch: 0, Loss: 0.6645379066467285\n","Epoch: 0, Loss: 0.8368390798568726\n","Epoch: 0, Loss: 0.7422205805778503\n","Epoch: 0, Loss: 0.674828290939331\n","Epoch: 0, Loss: 0.7634308934211731\n","Epoch: 0, Loss: 0.6598172187805176\n","Epoch: 0, Loss: 0.8321232795715332\n","Epoch: 0, Loss: 0.6045039892196655\n","Epoch: 0, Loss: 0.8308544158935547\n","Epoch: 0, Loss: 0.7279988527297974\n","Epoch: 0, Loss: 0.613386332988739\n","Epoch: 0, Loss: 0.7515658140182495\n","Epoch: 0, Loss: 0.7613961696624756\n","Epoch: 0, Loss: 0.695436954498291\n","Epoch: 0, Loss: 0.7085338234901428\n","Epoch: 0, Loss: 0.7156707048416138\n","Epoch: 0, Loss: 0.6827099919319153\n","Epoch: 0, Loss: 0.6702263951301575\n","Epoch: 0, Loss: 0.6324622631072998\n","Epoch: 0, Loss: 0.7385721206665039\n","Epoch: 0, Loss: 0.7291987538337708\n","Epoch: 0, Loss: 0.668306291103363\n","Epoch: 0, Loss: 0.7243884205818176\n","Epoch: 0, Loss: 0.6711279153823853\n","Epoch: 0, Loss: 0.6973564028739929\n","Epoch: 0, Loss: 0.7286828756332397\n","Epoch: 0, Loss: 0.6281368136405945\n","Epoch: 0, Loss: 0.7295821905136108\n","Epoch: 0, Loss: 0.8218666911125183\n","Epoch: 0, Loss: 0.6775385141372681\n","Epoch: 0, Loss: 0.7302109599113464\n","Epoch: 0, Loss: 0.7593984603881836\n","Epoch: 0, Loss: 0.6873641610145569\n","Epoch: 0, Loss: 0.7502923011779785\n","Epoch: 0, Loss: 0.7022560238838196\n","Epoch: 0, Loss: 0.7208857536315918\n","Epoch: 0, Loss: 0.7228034138679504\n","Epoch: 0, Loss: 0.6725000739097595\n","Epoch: 0, Loss: 0.6956453919410706\n","Epoch: 0, Loss: 0.7120358347892761\n","Epoch: 0, Loss: 0.6862043142318726\n","Epoch: 0, Loss: 0.7608696222305298\n","Epoch: 0, Loss: 0.6467442512512207\n","Epoch: 0, Loss: 0.7352008819580078\n","Epoch: 0, Loss: 0.7431530952453613\n","Epoch: 0, Loss: 0.6659870147705078\n","Epoch: 0, Loss: 0.6514308452606201\n","Epoch: 0, Loss: 0.6836181282997131\n","Epoch: 0, Loss: 0.7123344540596008\n","Epoch: 0, Loss: 0.6331562399864197\n","Epoch: 0, Loss: 0.6946418285369873\n","Epoch: 0, Loss: 0.6845228672027588\n","Epoch: 0, Loss: 0.7747026085853577\n","Epoch: 0, Loss: 0.724161684513092\n","Epoch: 0, Loss: 0.7410109639167786\n","Epoch: 0, Loss: 0.6497779488563538\n","Epoch: 0, Loss: 0.7040535807609558\n","Epoch: 0, Loss: 0.7513659000396729\n","Epoch: 0, Loss: 0.6855801939964294\n","Epoch: 0, Loss: 0.7027071118354797\n","Epoch: 0, Loss: 0.7273696660995483\n","Epoch: 0, Loss: 0.7237838506698608\n","Epoch: 0, Loss: 0.688876211643219\n","Epoch: 0, Loss: 0.693091869354248\n","Epoch: 1, Loss: 0.672009289264679\n","Epoch: 1, Loss: 0.6609278917312622\n","Epoch: 1, Loss: 0.6733026504516602\n","Epoch: 1, Loss: 0.6641665697097778\n","Epoch: 1, Loss: 0.6930935382843018\n","Epoch: 1, Loss: 0.7104188203811646\n","Epoch: 1, Loss: 0.7037196755409241\n","Epoch: 1, Loss: 0.6985962390899658\n","Epoch: 1, Loss: 0.6593184471130371\n","Epoch: 1, Loss: 0.7340661883354187\n","Epoch: 1, Loss: 0.6516817808151245\n","Epoch: 1, Loss: 0.6919333338737488\n","Epoch: 1, Loss: 0.7297196984291077\n","Epoch: 1, Loss: 0.6740138530731201\n","Epoch: 1, Loss: 0.7025845646858215\n","Epoch: 1, Loss: 0.8016698956489563\n","Epoch: 1, Loss: 0.8084645867347717\n","Epoch: 1, Loss: 0.7263153195381165\n","Epoch: 1, Loss: 0.6624395251274109\n","Epoch: 1, Loss: 0.7183274030685425\n","Epoch: 1, Loss: 0.6319196820259094\n","Epoch: 1, Loss: 0.6556782126426697\n","Epoch: 1, Loss: 0.6586571931838989\n","Epoch: 1, Loss: 0.8044368028640747\n","Epoch: 1, Loss: 0.7265933156013489\n","Epoch: 1, Loss: 0.7215908765792847\n","Epoch: 1, Loss: 0.690743088722229\n","Epoch: 1, Loss: 0.731564462184906\n","Epoch: 1, Loss: 0.692328691482544\n","Epoch: 1, Loss: 0.7151107788085938\n","Epoch: 1, Loss: 0.6638634204864502\n","Epoch: 1, Loss: 0.7192131280899048\n","Epoch: 1, Loss: 0.68975830078125\n","Epoch: 1, Loss: 0.7807631492614746\n","Epoch: 1, Loss: 0.7536565065383911\n","Epoch: 1, Loss: 0.683638334274292\n","Epoch: 1, Loss: 0.7372908592224121\n","Epoch: 1, Loss: 0.7177255153656006\n","Epoch: 1, Loss: 0.719414472579956\n","Epoch: 1, Loss: 0.7030206918716431\n","Epoch: 1, Loss: 0.7037990093231201\n","Epoch: 1, Loss: 0.6822609901428223\n","Epoch: 1, Loss: 0.6975597143173218\n","Epoch: 1, Loss: 0.8013650178909302\n","Epoch: 1, Loss: 0.6939265727996826\n","Epoch: 1, Loss: 0.6344699263572693\n","Epoch: 1, Loss: 0.6555821299552917\n","Epoch: 1, Loss: 0.6865062713623047\n","Epoch: 1, Loss: 0.7028089165687561\n","Epoch: 1, Loss: 0.6477309465408325\n","Epoch: 1, Loss: 0.6708899736404419\n","Epoch: 1, Loss: 0.6889033913612366\n","Epoch: 1, Loss: 0.6990631818771362\n","Epoch: 1, Loss: 0.7473401427268982\n","Epoch: 1, Loss: 0.7087980508804321\n","Epoch: 1, Loss: 0.7409858703613281\n","Epoch: 1, Loss: 0.7028902173042297\n","Epoch: 1, Loss: 0.7682511806488037\n","Epoch: 1, Loss: 0.705708920955658\n","Epoch: 1, Loss: 0.726305365562439\n","Epoch: 1, Loss: 0.7344509959220886\n","Epoch: 1, Loss: 0.744120717048645\n","Epoch: 1, Loss: 0.751278281211853\n","Epoch: 1, Loss: 0.7153428196907043\n","Epoch: 1, Loss: 0.7395102381706238\n","Epoch: 1, Loss: 0.757850706577301\n","Epoch: 1, Loss: 0.6541393995285034\n","Epoch: 1, Loss: 0.652121901512146\n","Epoch: 1, Loss: 0.7188423275947571\n","Epoch: 1, Loss: 0.7247527241706848\n","Epoch: 1, Loss: 0.7306522130966187\n","Epoch: 1, Loss: 0.7959340214729309\n","Epoch: 1, Loss: 0.7269100546836853\n","Epoch: 1, Loss: 0.7241196036338806\n","Epoch: 1, Loss: 0.6571053862571716\n","Epoch: 1, Loss: 0.7030072808265686\n","Epoch: 1, Loss: 0.6872100234031677\n","Epoch: 1, Loss: 0.697991132736206\n","Epoch: 1, Loss: 0.7413475513458252\n","Epoch: 1, Loss: 0.6553415060043335\n","Epoch: 1, Loss: 0.7668169736862183\n","Epoch: 1, Loss: 0.7059819102287292\n","Epoch: 1, Loss: 0.6988754868507385\n","Epoch: 1, Loss: 0.6993114948272705\n","Epoch: 1, Loss: 0.6698818206787109\n","Epoch: 1, Loss: 0.6376228928565979\n","Epoch: 1, Loss: 0.7310588955879211\n","Epoch: 1, Loss: 0.726814866065979\n","Epoch: 1, Loss: 0.6301016211509705\n","Epoch: 1, Loss: 0.653171181678772\n","Epoch: 1, Loss: 0.6687827706336975\n","Epoch: 1, Loss: 0.6839354634284973\n","Epoch: 1, Loss: 0.7138354182243347\n","Epoch: 1, Loss: 0.6911873817443848\n","Epoch: 1, Loss: 0.7617572546005249\n","Epoch: 1, Loss: 0.7355414628982544\n","Epoch: 1, Loss: 0.6415846347808838\n","Epoch: 1, Loss: 0.6435708403587341\n","Epoch: 1, Loss: 0.7303591370582581\n","Epoch: 1, Loss: 0.7510890960693359\n","Epoch: 1, Loss: 0.7184253334999084\n","Epoch: 1, Loss: 0.7473540306091309\n","Epoch: 1, Loss: 0.7747781276702881\n","Epoch: 1, Loss: 0.7025156021118164\n","Epoch: 1, Loss: 0.7124828696250916\n","Epoch: 1, Loss: 0.679072380065918\n","Epoch: 1, Loss: 0.7027209997177124\n","Epoch: 1, Loss: 0.7885976433753967\n","Epoch: 1, Loss: 0.7236697673797607\n","Epoch: 1, Loss: 0.6777440309524536\n","Epoch: 1, Loss: 0.6387141942977905\n","Epoch: 1, Loss: 0.7102175951004028\n","Epoch: 1, Loss: 0.7201606035232544\n","Epoch: 1, Loss: 0.6669344305992126\n","Epoch: 1, Loss: 0.619235634803772\n","Epoch: 1, Loss: 0.7018417119979858\n","Epoch: 1, Loss: 0.718808650970459\n","Epoch: 1, Loss: 0.6898526549339294\n","Epoch: 1, Loss: 0.6808986663818359\n","Epoch: 1, Loss: 0.7044551968574524\n","Epoch: 1, Loss: 0.6539351940155029\n","Epoch: 1, Loss: 0.7043747305870056\n","Epoch: 1, Loss: 0.6901698708534241\n","Epoch: 1, Loss: 0.6822407245635986\n","Epoch: 1, Loss: 0.7308090329170227\n","Epoch: 1, Loss: 0.7060648798942566\n","Epoch: 1, Loss: 0.6493967771530151\n","Epoch: 1, Loss: 0.7038642168045044\n","Epoch: 1, Loss: 0.780685544013977\n","Epoch: 1, Loss: 0.7038730978965759\n","Epoch: 1, Loss: 0.7154923677444458\n","Epoch: 1, Loss: 0.7654988169670105\n","Epoch: 1, Loss: 0.7081599235534668\n","Epoch: 1, Loss: 0.6512790322303772\n","Epoch: 1, Loss: 0.6929519772529602\n","Epoch: 1, Loss: 0.6686476469039917\n","Epoch: 1, Loss: 0.6768887639045715\n","Epoch: 1, Loss: 0.6902377009391785\n","Epoch: 1, Loss: 0.7113556861877441\n","Epoch: 1, Loss: 0.6361449956893921\n","Epoch: 1, Loss: 0.7251092195510864\n","Epoch: 1, Loss: 0.6836494207382202\n","Epoch: 1, Loss: 0.7219850420951843\n","Epoch: 1, Loss: 0.7318985462188721\n","Epoch: 1, Loss: 0.6545560359954834\n","Epoch: 1, Loss: 0.7501676082611084\n","Epoch: 1, Loss: 0.6352460384368896\n","Epoch: 1, Loss: 0.7038615345954895\n","Epoch: 1, Loss: 0.7358810901641846\n","Epoch: 1, Loss: 0.7316263914108276\n","Epoch: 1, Loss: 0.7454059720039368\n","Epoch: 1, Loss: 0.625406801700592\n","Epoch: 1, Loss: 0.7828921675682068\n","Epoch: 1, Loss: 0.735993504524231\n","Epoch: 1, Loss: 0.6330743432044983\n","Epoch: 1, Loss: 0.6397337317466736\n","Epoch: 1, Loss: 0.6982873678207397\n","Epoch: 1, Loss: 0.754135012626648\n","Epoch: 1, Loss: 0.6682903170585632\n","Epoch: 1, Loss: 0.7611082792282104\n","Epoch: 1, Loss: 0.7492361068725586\n","Epoch: 1, Loss: 0.6844896078109741\n","Epoch: 1, Loss: 0.7682482004165649\n","Epoch: 1, Loss: 0.6945778131484985\n","Epoch: 1, Loss: 0.7148497104644775\n","Epoch: 1, Loss: 0.7369139194488525\n","Epoch: 1, Loss: 0.6729112863540649\n","Epoch: 1, Loss: 0.7343780398368835\n","Epoch: 1, Loss: 0.7128939032554626\n","Epoch: 1, Loss: 0.6613205671310425\n","Epoch: 1, Loss: 0.7563521265983582\n","Epoch: 1, Loss: 0.7088770270347595\n","Epoch: 1, Loss: 0.6735811829566956\n","Epoch: 1, Loss: 0.7716987729072571\n","Epoch: 1, Loss: 0.8494006991386414\n","Epoch: 1, Loss: 0.7003105282783508\n","Epoch: 1, Loss: 0.7255601286888123\n","Epoch: 1, Loss: 0.6650739312171936\n","Epoch: 1, Loss: 0.605573832988739\n","Epoch: 1, Loss: 0.7703686952590942\n","Epoch: 1, Loss: 0.6734548807144165\n","Epoch: 1, Loss: 0.7195855379104614\n","Epoch: 1, Loss: 0.6319417357444763\n","Epoch: 1, Loss: 0.6373904943466187\n","Epoch: 1, Loss: 0.6531956195831299\n","Epoch: 1, Loss: 0.733049750328064\n","Epoch: 1, Loss: 0.6953295469284058\n","Epoch: 1, Loss: 0.8098870515823364\n","Epoch: 1, Loss: 0.6970335841178894\n","Epoch: 1, Loss: 0.6613999605178833\n","Epoch: 1, Loss: 0.7660683989524841\n","Epoch: 1, Loss: 0.6982702612876892\n","Epoch: 1, Loss: 0.653292179107666\n","Epoch: 1, Loss: 0.6627975106239319\n","Epoch: 1, Loss: 0.676194429397583\n","Epoch: 1, Loss: 0.7295185327529907\n","Epoch: 1, Loss: 0.6917586326599121\n","Epoch: 1, Loss: 0.693418025970459\n","Epoch: 1, Loss: 0.6856002807617188\n","Epoch: 1, Loss: 0.728958010673523\n","Epoch: 1, Loss: 0.6929935216903687\n","Epoch: 1, Loss: 0.7529339790344238\n","Epoch: 1, Loss: 0.6567373275756836\n","Epoch: 1, Loss: 0.7302481532096863\n","Epoch: 1, Loss: 0.6868791580200195\n","Epoch: 1, Loss: 0.6682665348052979\n","Epoch: 1, Loss: 0.6842999458312988\n","Epoch: 1, Loss: 0.7840912938117981\n","Epoch: 1, Loss: 0.7423349022865295\n","Epoch: 1, Loss: 0.7183070778846741\n","Epoch: 1, Loss: 0.6579152941703796\n","Epoch: 1, Loss: 0.7306352853775024\n","Epoch: 1, Loss: 0.7736293077468872\n","Epoch: 1, Loss: 0.7077771425247192\n","Epoch: 1, Loss: 0.7579087615013123\n","Epoch: 1, Loss: 0.7026891112327576\n","Epoch: 1, Loss: 0.7487229704856873\n","Epoch: 1, Loss: 0.6394298076629639\n","Epoch: 1, Loss: 0.6734357476234436\n","Epoch: 1, Loss: 0.7092468738555908\n","Epoch: 1, Loss: 0.7242651581764221\n","Epoch: 1, Loss: 0.6474860906600952\n","Epoch: 1, Loss: 0.6689828634262085\n","Epoch: 1, Loss: 0.6844277381896973\n","Epoch: 1, Loss: 0.684016227722168\n","Epoch: 1, Loss: 0.6525854468345642\n","Epoch: 1, Loss: 0.725073516368866\n","Epoch: 1, Loss: 0.7518181204795837\n","Epoch: 1, Loss: 0.7136819958686829\n","Epoch: 1, Loss: 0.644108772277832\n","Epoch: 1, Loss: 0.6548064947128296\n","Epoch: 1, Loss: 0.7236111164093018\n","Epoch: 1, Loss: 0.7327326536178589\n","Epoch: 1, Loss: 0.6892395615577698\n","Epoch: 1, Loss: 0.6203992962837219\n","Epoch: 1, Loss: 0.7328752875328064\n","Epoch: 1, Loss: 0.7337340116500854\n","Epoch: 1, Loss: 0.6479475498199463\n","Epoch: 1, Loss: 0.7526402473449707\n","Epoch: 1, Loss: 0.7362268567085266\n","Epoch: 1, Loss: 0.7767853736877441\n","Epoch: 1, Loss: 0.8068103194236755\n","Epoch: 1, Loss: 0.7271493673324585\n","Epoch: 1, Loss: 0.7111893892288208\n","Epoch: 1, Loss: 0.6916050910949707\n","Epoch: 1, Loss: 0.748867928981781\n","Epoch: 1, Loss: 0.7376676797866821\n","Epoch: 1, Loss: 0.7043272852897644\n","Epoch: 1, Loss: 0.712906539440155\n","Epoch: 1, Loss: 0.7107574343681335\n","Epoch: 1, Loss: 0.6985256671905518\n","Epoch: 1, Loss: 0.7335651516914368\n","Epoch: 1, Loss: 0.7642550468444824\n","Epoch: 1, Loss: 0.7324978113174438\n","Epoch: 1, Loss: 0.6911022663116455\n","Epoch: 1, Loss: 0.6957135200500488\n","Epoch: 1, Loss: 0.6841307878494263\n","Epoch: 1, Loss: 0.6997215151786804\n","Epoch: 1, Loss: 0.7042019963264465\n","Epoch: 1, Loss: 0.6604503393173218\n","Epoch: 1, Loss: 0.6446760296821594\n","Epoch: 1, Loss: 0.6995400786399841\n","Epoch: 1, Loss: 0.6716576218605042\n","Epoch: 1, Loss: 0.7158167362213135\n","Epoch: 1, Loss: 0.7028106451034546\n","Epoch: 1, Loss: 0.7110881805419922\n","Epoch: 1, Loss: 0.7231975793838501\n","Epoch: 1, Loss: 0.7506007552146912\n","Epoch: 1, Loss: 0.7367181777954102\n","Epoch: 1, Loss: 0.7917618751525879\n","Epoch: 1, Loss: 0.6049607396125793\n","Epoch: 1, Loss: 0.671380341053009\n","Epoch: 1, Loss: 0.6268066167831421\n","Epoch: 1, Loss: 0.7182980179786682\n","Epoch: 1, Loss: 0.6850626468658447\n","Epoch: 1, Loss: 0.6894840598106384\n","Epoch: 1, Loss: 0.6643393039703369\n","Epoch: 1, Loss: 0.7045583724975586\n","Epoch: 1, Loss: 0.6674882173538208\n","Epoch: 1, Loss: 0.6594869494438171\n","Epoch: 1, Loss: 0.7940355539321899\n","Epoch: 1, Loss: 0.7240694165229797\n","Epoch: 1, Loss: 0.7288762331008911\n","Epoch: 1, Loss: 0.7026769518852234\n","Epoch: 1, Loss: 0.7231650352478027\n","Epoch: 1, Loss: 0.6919219493865967\n","Epoch: 1, Loss: 0.6671854853630066\n","Epoch: 1, Loss: 0.732465922832489\n","Epoch: 1, Loss: 0.6278566122055054\n","Epoch: 1, Loss: 0.7026018500328064\n","Epoch: 1, Loss: 0.7322225570678711\n","Epoch: 1, Loss: 0.6536265015602112\n","Epoch: 1, Loss: 0.6829832792282104\n","Epoch: 1, Loss: 0.6613809466362\n","Epoch: 1, Loss: 0.7290337085723877\n","Epoch: 1, Loss: 0.7490091323852539\n","Epoch: 1, Loss: 0.7230024337768555\n","Epoch: 1, Loss: 0.675920844078064\n","Epoch: 1, Loss: 0.735847532749176\n","Epoch: 1, Loss: 0.7321696281433105\n","Epoch: 1, Loss: 0.7277120351791382\n","Epoch: 1, Loss: 0.6956869959831238\n","Epoch: 1, Loss: 0.6165999174118042\n","Epoch: 1, Loss: 0.6768301725387573\n","Epoch: 1, Loss: 0.7609297633171082\n","Epoch: 1, Loss: 0.7844786047935486\n","Epoch: 1, Loss: 0.6705291271209717\n","Epoch: 1, Loss: 0.7133838534355164\n","Epoch: 1, Loss: 0.6898484230041504\n","Epoch: 1, Loss: 0.725006103515625\n","Epoch: 1, Loss: 0.6541277766227722\n","Epoch: 1, Loss: 0.6608496308326721\n","Epoch: 1, Loss: 0.7149627804756165\n","Epoch: 1, Loss: 0.6406099200248718\n","Epoch: 1, Loss: 0.6870372891426086\n","Epoch: 1, Loss: 0.6031745672225952\n","Epoch: 1, Loss: 0.6418778896331787\n","Epoch: 1, Loss: 0.6414076089859009\n","Epoch: 1, Loss: 0.6576899886131287\n","Epoch: 1, Loss: 0.6938859224319458\n","Epoch: 1, Loss: 0.7089230418205261\n","Epoch: 1, Loss: 0.7255105972290039\n","Epoch: 1, Loss: 0.710430383682251\n","Epoch: 1, Loss: 0.751866340637207\n","Epoch: 1, Loss: 0.7044559717178345\n","Epoch: 1, Loss: 0.7056959867477417\n","Epoch: 1, Loss: 0.6909655332565308\n","Epoch: 1, Loss: 0.6885218620300293\n","Epoch: 1, Loss: 0.7384689450263977\n","Epoch: 1, Loss: 0.6608738899230957\n","Epoch: 1, Loss: 0.6738221645355225\n","Epoch: 1, Loss: 0.6571363806724548\n","Epoch: 1, Loss: 0.681195855140686\n","Epoch: 1, Loss: 0.7166588306427002\n","Epoch: 1, Loss: 0.653628408908844\n","Epoch: 1, Loss: 0.7350935935974121\n","Epoch: 1, Loss: 0.7454269528388977\n","Epoch: 1, Loss: 0.6550710201263428\n","Epoch: 1, Loss: 0.785040020942688\n","Epoch: 1, Loss: 0.7109612226486206\n","Epoch: 1, Loss: 0.6685681939125061\n","Epoch: 1, Loss: 0.6792052984237671\n","Epoch: 1, Loss: 0.7397628426551819\n","Epoch: 1, Loss: 0.652341365814209\n","Epoch: 1, Loss: 0.7597130537033081\n","Epoch: 1, Loss: 0.7060387134552002\n","Epoch: 1, Loss: 0.7301266193389893\n","Epoch: 1, Loss: 0.7468098998069763\n","Epoch: 1, Loss: 0.677588939666748\n","Epoch: 1, Loss: 0.6910150051116943\n","Epoch: 1, Loss: 0.7061434984207153\n","Epoch: 1, Loss: 0.774497926235199\n","Epoch: 1, Loss: 0.7107744216918945\n","Epoch: 1, Loss: 0.7367660403251648\n","Epoch: 1, Loss: 0.6889537572860718\n","Epoch: 1, Loss: 0.6376887559890747\n","Epoch: 1, Loss: 0.7524318695068359\n","Epoch: 1, Loss: 0.7135096788406372\n","Epoch: 1, Loss: 0.621661901473999\n","Epoch: 1, Loss: 0.754595160484314\n","Epoch: 1, Loss: 0.7207769155502319\n","Epoch: 1, Loss: 0.7116437554359436\n","Epoch: 1, Loss: 0.721077024936676\n","Epoch: 1, Loss: 0.680870771408081\n","Epoch: 1, Loss: 0.6579763889312744\n","Epoch: 1, Loss: 0.7251509428024292\n","Epoch: 1, Loss: 0.6726751923561096\n","Epoch: 1, Loss: 0.6654899716377258\n","Epoch: 1, Loss: 0.6939636468887329\n","Epoch: 1, Loss: 0.6835469007492065\n","Epoch: 1, Loss: 0.7051895260810852\n","Epoch: 1, Loss: 0.7007203102111816\n","Epoch: 1, Loss: 0.7027839422225952\n","Epoch: 1, Loss: 0.7303085923194885\n","Epoch: 1, Loss: 0.6954777836799622\n","Epoch: 1, Loss: 0.6805034875869751\n","Epoch: 1, Loss: 0.649591863155365\n","Epoch: 1, Loss: 0.6900767683982849\n","Epoch: 1, Loss: 0.6523869037628174\n","Epoch: 1, Loss: 0.6684952974319458\n","Epoch: 1, Loss: 0.6938867568969727\n","Epoch: 1, Loss: 0.7131869196891785\n","Epoch: 1, Loss: 0.7169919013977051\n","Epoch: 1, Loss: 0.7404337525367737\n","Epoch: 1, Loss: 0.7046001553535461\n","Epoch: 1, Loss: 0.7034038305282593\n","Epoch: 1, Loss: 0.7219206690788269\n","Epoch: 1, Loss: 0.7886309027671814\n","Epoch: 1, Loss: 0.6787528395652771\n","Epoch: 1, Loss: 0.6744610071182251\n","Epoch: 1, Loss: 0.7324315905570984\n","Epoch: 1, Loss: 0.7306898832321167\n","Epoch: 1, Loss: 0.7259395122528076\n","Epoch: 1, Loss: 0.7138370275497437\n","Epoch: 1, Loss: 0.7134228944778442\n","Epoch: 1, Loss: 0.7128365635871887\n","Epoch: 1, Loss: 0.7093346118927002\n","Epoch: 1, Loss: 0.7213891744613647\n","Epoch: 1, Loss: 0.7189552187919617\n","Epoch: 1, Loss: 0.7353814244270325\n","Epoch: 1, Loss: 0.6638373136520386\n","Epoch: 1, Loss: 0.6969172358512878\n","Epoch: 1, Loss: 0.7040538191795349\n","Epoch: 1, Loss: 0.6715952157974243\n","Epoch: 1, Loss: 0.6805793642997742\n","Epoch: 1, Loss: 0.7805783748626709\n","Epoch: 1, Loss: 0.759721040725708\n","Epoch: 1, Loss: 0.6885848641395569\n","Epoch: 1, Loss: 0.7359659671783447\n","Epoch: 1, Loss: 0.6759262084960938\n","Epoch: 1, Loss: 0.6534580588340759\n","Epoch: 1, Loss: 0.6935736536979675\n","Epoch: 1, Loss: 0.7501835227012634\n","Epoch: 1, Loss: 0.7141299843788147\n","Epoch: 1, Loss: 0.6635697484016418\n","Epoch: 1, Loss: 0.6925143599510193\n","Epoch: 1, Loss: 0.6834459900856018\n","Epoch: 1, Loss: 0.7233794927597046\n","Epoch: 1, Loss: 0.653833270072937\n","Epoch: 1, Loss: 0.7038803696632385\n","Epoch: 1, Loss: 0.716536819934845\n","Epoch: 1, Loss: 0.706584095954895\n","Epoch: 1, Loss: 0.6832916736602783\n","Epoch: 1, Loss: 0.683108925819397\n","Epoch: 1, Loss: 0.7009613513946533\n","Epoch: 1, Loss: 0.763526439666748\n","Epoch: 1, Loss: 0.6971972584724426\n","Epoch: 1, Loss: 0.7299440503120422\n","Epoch: 1, Loss: 0.6108769178390503\n","Epoch: 1, Loss: 0.6873548030853271\n","Epoch: 1, Loss: 0.7052994966506958\n","Epoch: 1, Loss: 0.7266669869422913\n","Epoch: 1, Loss: 0.6924208402633667\n","Epoch: 1, Loss: 0.6861904859542847\n","Epoch: 1, Loss: 0.7117035388946533\n","Epoch: 1, Loss: 0.7007291913032532\n","Epoch: 1, Loss: 0.6808711290359497\n","Epoch: 1, Loss: 0.6432967782020569\n","Epoch: 1, Loss: 0.6430042386054993\n","Epoch: 1, Loss: 0.7305499911308289\n","Epoch: 1, Loss: 0.6772705912590027\n","Epoch: 1, Loss: 0.6435688734054565\n","Epoch: 1, Loss: 0.7494912147521973\n","Epoch: 1, Loss: 0.799224853515625\n","Epoch: 1, Loss: 0.7660916447639465\n","Epoch: 1, Loss: 0.7691177725791931\n","Epoch: 1, Loss: 0.6378059387207031\n","Epoch: 1, Loss: 0.6745092272758484\n","Epoch: 1, Loss: 0.7318421602249146\n","Epoch: 1, Loss: 0.6240596771240234\n","Epoch: 1, Loss: 0.7046159505844116\n","Epoch: 1, Loss: 0.6778438091278076\n","Epoch: 1, Loss: 0.6653863787651062\n","Epoch: 1, Loss: 0.6467981338500977\n","Epoch: 1, Loss: 0.719480574131012\n","Epoch: 1, Loss: 0.6876941323280334\n","Epoch: 1, Loss: 0.7117718458175659\n","Epoch: 1, Loss: 0.6915115118026733\n","Epoch: 1, Loss: 0.7464465498924255\n","Epoch: 1, Loss: 0.7082184553146362\n","Epoch: 1, Loss: 0.6846740245819092\n","Epoch: 1, Loss: 0.7576866149902344\n","Epoch: 1, Loss: 0.6874049305915833\n","Epoch: 1, Loss: 0.7037419080734253\n","Epoch: 1, Loss: 0.6684931516647339\n","Epoch: 1, Loss: 0.6705986857414246\n","Epoch: 1, Loss: 0.7229950428009033\n","Epoch: 1, Loss: 0.7420288920402527\n","Epoch: 1, Loss: 0.6899904012680054\n","Epoch: 1, Loss: 0.6739040613174438\n","Epoch: 1, Loss: 0.8150566220283508\n","Epoch: 1, Loss: 0.7368491291999817\n","Epoch: 1, Loss: 0.7100244760513306\n","Epoch: 1, Loss: 0.6354701519012451\n","Epoch: 1, Loss: 0.7270708084106445\n","Epoch: 1, Loss: 0.7495569586753845\n","Epoch: 1, Loss: 0.7163735032081604\n","Epoch: 1, Loss: 0.6635264754295349\n","Epoch: 1, Loss: 0.7607204914093018\n","Epoch: 1, Loss: 0.7106996178627014\n","Epoch: 1, Loss: 0.6724395751953125\n","Epoch: 1, Loss: 0.6824207305908203\n","Epoch: 1, Loss: 0.6335709095001221\n","Epoch: 1, Loss: 0.6845496296882629\n","Epoch: 1, Loss: 0.6515442132949829\n","Epoch: 1, Loss: 0.7174617648124695\n","Epoch: 1, Loss: 0.7297186255455017\n","Epoch: 1, Loss: 0.7727528214454651\n","Epoch: 1, Loss: 0.6647884845733643\n","Epoch: 1, Loss: 0.6971685290336609\n","Epoch: 1, Loss: 0.6494920253753662\n","Epoch: 1, Loss: 0.8035246729850769\n","Epoch: 1, Loss: 0.6545678377151489\n","Epoch: 1, Loss: 0.6499516367912292\n","Epoch: 1, Loss: 0.7386391162872314\n","Epoch: 1, Loss: 0.6821090579032898\n","Epoch: 1, Loss: 0.7299262881278992\n","Epoch: 1, Loss: 0.7430057525634766\n","Epoch: 1, Loss: 0.6594988107681274\n","Epoch: 1, Loss: 0.6587197780609131\n","Epoch: 1, Loss: 0.7125939130783081\n","Epoch: 1, Loss: 0.7409065365791321\n","Epoch: 1, Loss: 0.6973715424537659\n","Epoch: 1, Loss: 0.7352932095527649\n","Epoch: 1, Loss: 0.7727850675582886\n","Epoch: 1, Loss: 0.6732329726219177\n","Epoch: 1, Loss: 0.694542646408081\n","Epoch: 1, Loss: 0.7509862184524536\n","Epoch: 1, Loss: 0.6480028629302979\n","Epoch: 1, Loss: 0.7198370695114136\n","Epoch: 1, Loss: 0.6822829246520996\n","Epoch: 1, Loss: 0.6357486248016357\n","Epoch: 1, Loss: 0.6540873050689697\n","Epoch: 1, Loss: 0.7210740447044373\n","Epoch: 1, Loss: 0.7236083149909973\n","Epoch: 1, Loss: 0.6667879223823547\n","Epoch: 1, Loss: 0.6814291477203369\n","Epoch: 1, Loss: 0.7076210379600525\n","Epoch: 1, Loss: 0.6695868372917175\n","Epoch: 1, Loss: 0.7048552632331848\n","Epoch: 1, Loss: 0.6795008182525635\n","Epoch: 1, Loss: 0.6451481580734253\n","Epoch: 1, Loss: 0.6734225749969482\n","Epoch: 1, Loss: 0.6987324953079224\n","Epoch: 1, Loss: 0.7301572561264038\n","Epoch: 1, Loss: 0.6978628635406494\n","Epoch: 1, Loss: 0.6733915209770203\n","Epoch: 1, Loss: 0.7223019599914551\n","Epoch: 1, Loss: 0.6730207204818726\n","Epoch: 1, Loss: 0.6776202321052551\n","Epoch: 1, Loss: 0.7099198698997498\n","Epoch: 1, Loss: 0.669215202331543\n","Epoch: 1, Loss: 0.6975202560424805\n","Epoch: 1, Loss: 0.7536939382553101\n","Epoch: 1, Loss: 0.7650227546691895\n","Epoch: 1, Loss: 0.7371677160263062\n","Epoch: 1, Loss: 0.6448417901992798\n","Epoch: 1, Loss: 0.7101204991340637\n","Epoch: 1, Loss: 0.6607916355133057\n","Epoch: 1, Loss: 0.6617577075958252\n","Epoch: 1, Loss: 0.7597129344940186\n","Epoch: 1, Loss: 0.732403576374054\n","Epoch: 1, Loss: 0.692806601524353\n","Epoch: 1, Loss: 0.6899402141571045\n","Epoch: 1, Loss: 0.7704497575759888\n","Epoch: 1, Loss: 0.6439971923828125\n","Epoch: 1, Loss: 0.665859043598175\n","Epoch: 1, Loss: 0.6982618570327759\n","Epoch: 1, Loss: 0.6507161855697632\n","Epoch: 1, Loss: 0.7354257106781006\n","Epoch: 1, Loss: 0.6465737223625183\n","Epoch: 1, Loss: 0.7639269828796387\n","Epoch: 1, Loss: 0.699678361415863\n","Epoch: 1, Loss: 0.6801140308380127\n","Epoch: 1, Loss: 0.745204746723175\n","Epoch: 1, Loss: 0.6732897162437439\n","Epoch: 1, Loss: 0.6925768852233887\n","Epoch: 1, Loss: 0.73161381483078\n","Epoch: 1, Loss: 0.7072499990463257\n","Epoch: 1, Loss: 0.6833386421203613\n","Epoch: 1, Loss: 0.6349685788154602\n","Epoch: 1, Loss: 0.7184023857116699\n","Epoch: 1, Loss: 0.6827592849731445\n","Epoch: 1, Loss: 0.7251490354537964\n","Epoch: 1, Loss: 0.7243936657905579\n","Epoch: 1, Loss: 0.724381685256958\n","Epoch: 1, Loss: 0.7369481325149536\n","Epoch: 1, Loss: 0.6942689418792725\n","Epoch: 1, Loss: 0.6759192943572998\n","Epoch: 1, Loss: 0.6880759000778198\n","Epoch: 1, Loss: 0.7262982726097107\n","Epoch: 1, Loss: 0.6714386940002441\n","Epoch: 1, Loss: 0.638691782951355\n","Epoch: 1, Loss: 0.6753832101821899\n","Epoch: 1, Loss: 0.7701479196548462\n","Epoch: 1, Loss: 0.7323802709579468\n","Epoch: 1, Loss: 0.7478317022323608\n","Epoch: 1, Loss: 0.7161946296691895\n","Epoch: 1, Loss: 0.6781567335128784\n","Epoch: 1, Loss: 0.718661904335022\n","Epoch: 1, Loss: 0.6485541462898254\n","Epoch: 1, Loss: 0.754401683807373\n","Epoch: 1, Loss: 0.7647072672843933\n","Epoch: 1, Loss: 0.5931089520454407\n","Epoch: 1, Loss: 0.7223700881004333\n","Epoch: 1, Loss: 0.7342568635940552\n","Epoch: 1, Loss: 0.722392201423645\n","Epoch: 1, Loss: 0.7677427530288696\n","Epoch: 1, Loss: 0.7024132609367371\n","Epoch: 1, Loss: 0.6543329954147339\n","Epoch: 1, Loss: 0.635610044002533\n","Epoch: 1, Loss: 0.6569666266441345\n","Epoch: 1, Loss: 0.7265944480895996\n","Epoch: 1, Loss: 0.6944934129714966\n","Epoch: 1, Loss: 0.6492001414299011\n","Epoch: 1, Loss: 0.6920051574707031\n","Epoch: 1, Loss: 0.6996435523033142\n","Epoch: 1, Loss: 0.6936599016189575\n","Epoch: 1, Loss: 0.7052366733551025\n","Epoch: 1, Loss: 0.6910908222198486\n","Epoch: 1, Loss: 0.6429468989372253\n","Epoch: 1, Loss: 0.656075656414032\n","Epoch: 1, Loss: 0.6821544766426086\n","Epoch: 1, Loss: 0.7147525548934937\n","Epoch: 1, Loss: 0.7064599990844727\n","Epoch: 1, Loss: 0.7018502950668335\n","Epoch: 1, Loss: 0.7387502193450928\n","Epoch: 1, Loss: 0.6755789518356323\n","Epoch: 1, Loss: 0.738713264465332\n","Epoch: 1, Loss: 0.6584570407867432\n","Epoch: 1, Loss: 0.7129466533660889\n","Epoch: 1, Loss: 0.768302857875824\n","Epoch: 1, Loss: 0.6554878950119019\n","Epoch: 1, Loss: 0.7666105031967163\n","Epoch: 1, Loss: 0.5924249291419983\n","Epoch: 1, Loss: 0.7239028811454773\n","Epoch: 1, Loss: 0.6680589914321899\n","Epoch: 1, Loss: 0.7024373412132263\n","Epoch: 1, Loss: 0.6955724954605103\n","Epoch: 1, Loss: 0.6833995580673218\n","Epoch: 1, Loss: 0.7151939868927002\n","Epoch: 1, Loss: 0.7019476294517517\n","Epoch: 1, Loss: 0.6899117827415466\n","Epoch: 1, Loss: 0.7880395650863647\n","Epoch: 1, Loss: 0.6537562608718872\n","Epoch: 1, Loss: 0.7061058282852173\n","Epoch: 1, Loss: 0.7146227359771729\n","Epoch: 1, Loss: 0.7058550715446472\n","Epoch: 1, Loss: 0.6392388343811035\n","Epoch: 1, Loss: 0.6807605028152466\n","Epoch: 1, Loss: 0.7363156080245972\n","Epoch: 1, Loss: 0.7604529857635498\n","Epoch: 1, Loss: 0.6565365195274353\n","Epoch: 1, Loss: 0.6852757930755615\n","Epoch: 1, Loss: 0.7922858595848083\n","Epoch: 1, Loss: 0.615363359451294\n","Epoch: 1, Loss: 0.7849575877189636\n","Epoch: 1, Loss: 0.7273932695388794\n","Epoch: 1, Loss: 0.7596698999404907\n","Epoch: 1, Loss: 0.6507934331893921\n","Epoch: 1, Loss: 0.7028350234031677\n","Epoch: 1, Loss: 0.7652365565299988\n","Epoch: 1, Loss: 0.7034872174263\n","Epoch: 1, Loss: 0.7184457182884216\n","Epoch: 1, Loss: 0.7269914150238037\n","Epoch: 1, Loss: 0.7499420046806335\n","Epoch: 1, Loss: 0.6642847657203674\n","Epoch: 1, Loss: 0.7040809392929077\n","Epoch: 1, Loss: 0.6779505014419556\n","Epoch: 1, Loss: 0.7350435853004456\n","Epoch: 1, Loss: 0.7204331159591675\n","Epoch: 1, Loss: 0.6927235722541809\n","Epoch: 1, Loss: 0.7213644981384277\n","Epoch: 1, Loss: 0.6986984014511108\n","Epoch: 1, Loss: 0.6782481670379639\n","Epoch: 1, Loss: 0.6961289644241333\n","Epoch: 1, Loss: 0.7412190437316895\n","Epoch: 1, Loss: 0.7097474336624146\n","Epoch: 1, Loss: 0.7278562784194946\n","Epoch: 1, Loss: 0.7115180492401123\n","Epoch: 1, Loss: 0.6720569729804993\n","Epoch: 1, Loss: 0.6359869241714478\n","Epoch: 1, Loss: 0.7034239768981934\n","Epoch: 1, Loss: 0.7025471329689026\n","Epoch: 1, Loss: 0.7351435422897339\n","Epoch: 1, Loss: 0.7035223245620728\n","Epoch: 1, Loss: 0.6964625716209412\n","Epoch: 1, Loss: 0.724296510219574\n","Epoch: 1, Loss: 0.6870160698890686\n","Epoch: 1, Loss: 0.6528418064117432\n","Epoch: 1, Loss: 0.7214674353599548\n","Epoch: 1, Loss: 0.7090398073196411\n","Epoch: 1, Loss: 0.7389533519744873\n","Epoch: 1, Loss: 0.6858258247375488\n","Epoch: 1, Loss: 0.7196534872055054\n","Epoch: 1, Loss: 0.6820780038833618\n","Epoch: 1, Loss: 0.7019872665405273\n","Epoch: 1, Loss: 0.7026599645614624\n","Epoch: 1, Loss: 0.664451539516449\n","Epoch: 1, Loss: 0.7274743318557739\n","Epoch: 1, Loss: 0.5427078008651733\n","Epoch: 1, Loss: 0.6872341632843018\n","Epoch: 1, Loss: 0.662842333316803\n","Epoch: 1, Loss: 0.6565212607383728\n","Epoch: 1, Loss: 0.7345472574234009\n","Epoch: 1, Loss: 0.7603224515914917\n","Epoch: 1, Loss: 0.8232409954071045\n","Epoch: 1, Loss: 0.7009730935096741\n","Epoch: 1, Loss: 0.807633638381958\n","Epoch: 1, Loss: 0.7047089338302612\n","Epoch: 1, Loss: 0.7108200788497925\n","Epoch: 1, Loss: 0.6686906814575195\n","Epoch: 1, Loss: 0.6937437057495117\n","Epoch: 1, Loss: 0.6659935712814331\n","Epoch: 1, Loss: 0.6630350351333618\n","Epoch: 1, Loss: 0.8002650141716003\n","Epoch: 1, Loss: 0.5944679379463196\n","Epoch: 1, Loss: 0.6655808687210083\n","Epoch: 1, Loss: 0.7813061475753784\n","Epoch: 1, Loss: 0.7352175116539001\n","Epoch: 1, Loss: 0.7314777970314026\n","Epoch: 1, Loss: 0.6299050450325012\n","Epoch: 1, Loss: 0.6977286338806152\n","Epoch: 1, Loss: 0.7391117811203003\n","Epoch: 1, Loss: 0.6842708587646484\n","Epoch: 1, Loss: 0.7149860858917236\n","Epoch: 1, Loss: 0.6760824918746948\n","Epoch: 1, Loss: 0.6875020861625671\n","Epoch: 1, Loss: 0.7053977251052856\n","Epoch: 1, Loss: 0.7519675493240356\n","Epoch: 1, Loss: 0.6853762865066528\n","Epoch: 1, Loss: 0.6562039256095886\n","Epoch: 1, Loss: 0.711821973323822\n","Epoch: 1, Loss: 0.6995676159858704\n","Epoch: 1, Loss: 0.7576678991317749\n","Epoch: 1, Loss: 0.7360199093818665\n","Epoch: 1, Loss: 0.7227886915206909\n","Epoch: 1, Loss: 0.7011060118675232\n","Epoch: 1, Loss: 0.7556095123291016\n","Epoch: 1, Loss: 0.7297630310058594\n","Epoch: 1, Loss: 0.7116475105285645\n","Epoch: 1, Loss: 0.6882519125938416\n","Epoch: 1, Loss: 0.6777376532554626\n","Epoch: 1, Loss: 0.6800898909568787\n","Epoch: 1, Loss: 0.6967236399650574\n","Epoch: 1, Loss: 0.7188977599143982\n","Epoch: 1, Loss: 0.6593695878982544\n","Epoch: 1, Loss: 0.7633835673332214\n","Epoch: 1, Loss: 0.7178457379341125\n","Epoch: 1, Loss: 0.6294785737991333\n","Epoch: 1, Loss: 0.6979666352272034\n","Epoch: 1, Loss: 0.6349629163742065\n","Epoch: 1, Loss: 0.6550945043563843\n","Epoch: 1, Loss: 0.7548103332519531\n","Epoch: 1, Loss: 0.7493735551834106\n","Epoch: 1, Loss: 0.7525725364685059\n","Epoch: 1, Loss: 0.7454688549041748\n","Epoch: 1, Loss: 0.8033716082572937\n","Epoch: 1, Loss: 0.6293488144874573\n","Epoch: 1, Loss: 0.6513896584510803\n","Epoch: 1, Loss: 0.7369767427444458\n","Epoch: 1, Loss: 0.8133183121681213\n","Epoch: 1, Loss: 0.8000365495681763\n","Epoch: 1, Loss: 0.748816728591919\n","Epoch: 1, Loss: 0.764739990234375\n","Epoch: 1, Loss: 0.6586739420890808\n","Epoch: 1, Loss: 0.7399729490280151\n","Epoch: 1, Loss: 0.6903453469276428\n","Epoch: 1, Loss: 0.7605648040771484\n","Epoch: 1, Loss: 0.6818198561668396\n","Epoch: 1, Loss: 0.7301805019378662\n","Epoch: 1, Loss: 0.689016580581665\n","Epoch: 1, Loss: 0.6707460284233093\n","Epoch: 1, Loss: 0.7202408909797668\n","Epoch: 1, Loss: 0.7044512629508972\n","Epoch: 1, Loss: 0.7160468697547913\n","Epoch: 1, Loss: 0.7202731966972351\n","Epoch: 1, Loss: 0.7594366669654846\n","Epoch: 1, Loss: 0.7072420120239258\n","Epoch: 1, Loss: 0.6867693662643433\n","Epoch: 1, Loss: 0.7279759049415588\n","Epoch: 1, Loss: 0.7345899343490601\n","Epoch: 1, Loss: 0.6496265530586243\n","Epoch: 1, Loss: 0.6798440217971802\n","Epoch: 1, Loss: 0.6690956354141235\n","Epoch: 1, Loss: 0.6964625120162964\n","Epoch: 1, Loss: 0.7140529751777649\n","Epoch: 1, Loss: 0.6355336904525757\n","Epoch: 1, Loss: 0.6676003336906433\n","Epoch: 1, Loss: 0.8137953281402588\n","Epoch: 1, Loss: 0.7060980796813965\n","Epoch: 1, Loss: 0.7175688147544861\n","Epoch: 1, Loss: 0.6848278045654297\n","Epoch: 1, Loss: 0.7091768980026245\n","Epoch: 1, Loss: 0.6875234246253967\n","Epoch: 1, Loss: 0.7450858950614929\n","Epoch: 1, Loss: 0.7148784399032593\n","Epoch: 1, Loss: 0.6636135578155518\n","Epoch: 1, Loss: 0.6786543130874634\n","Epoch: 1, Loss: 0.71528559923172\n","Epoch: 1, Loss: 0.7404108047485352\n","Epoch: 1, Loss: 0.686815619468689\n","Epoch: 1, Loss: 0.677943766117096\n","Epoch: 1, Loss: 0.7078341245651245\n","Epoch: 1, Loss: 0.6884209513664246\n","Epoch: 1, Loss: 0.6678705811500549\n","Epoch: 1, Loss: 0.647876501083374\n","Epoch: 1, Loss: 0.6932222247123718\n","Epoch: 1, Loss: 0.689730703830719\n","Epoch: 1, Loss: 0.7400366067886353\n","Epoch: 1, Loss: 0.6596707105636597\n","Epoch: 1, Loss: 0.6729695796966553\n","Epoch: 1, Loss: 0.7478044629096985\n","Epoch: 1, Loss: 0.6256882548332214\n","Epoch: 1, Loss: 0.6669836044311523\n","Epoch: 1, Loss: 0.651112973690033\n","Epoch: 1, Loss: 0.671126127243042\n","Epoch: 1, Loss: 0.6641736626625061\n","Epoch: 1, Loss: 0.7164278626441956\n","Epoch: 1, Loss: 0.6759122014045715\n","Epoch: 1, Loss: 0.6579033136367798\n","Epoch: 1, Loss: 0.7285330295562744\n","Epoch: 1, Loss: 0.7222914099693298\n","Epoch: 1, Loss: 0.6577171087265015\n","Epoch: 1, Loss: 0.7150787711143494\n","Epoch: 1, Loss: 0.6588966250419617\n","Epoch: 1, Loss: 0.7167072892189026\n","Epoch: 1, Loss: 0.6882414817810059\n","Epoch: 1, Loss: 0.7119342088699341\n","Epoch: 1, Loss: 0.6415144801139832\n","Epoch: 1, Loss: 0.7202208042144775\n","Epoch: 1, Loss: 0.7655998468399048\n","Epoch: 1, Loss: 0.6852236986160278\n","Epoch: 1, Loss: 0.7356458902359009\n","Epoch: 1, Loss: 0.7310073375701904\n","Epoch: 1, Loss: 0.6874312162399292\n","Epoch: 1, Loss: 0.74305659532547\n","Epoch: 1, Loss: 0.6733089089393616\n","Epoch: 1, Loss: 0.6403026580810547\n","Epoch: 1, Loss: 0.7934781908988953\n","Epoch: 1, Loss: 0.7183009386062622\n","Epoch: 1, Loss: 0.6446564197540283\n","Epoch: 1, Loss: 0.6995053291320801\n","Epoch: 1, Loss: 0.7603431940078735\n","Epoch: 1, Loss: 0.7390831112861633\n","Epoch: 1, Loss: 0.677341878414154\n","Epoch: 1, Loss: 0.7063959240913391\n","Epoch: 1, Loss: 0.6400783658027649\n","Epoch: 1, Loss: 0.65157151222229\n","Epoch: 1, Loss: 0.718632698059082\n","Epoch: 1, Loss: 0.6907921433448792\n","Epoch: 1, Loss: 0.7597202658653259\n","Epoch: 1, Loss: 0.7390680909156799\n","Epoch: 1, Loss: 0.6985353231430054\n","Epoch: 1, Loss: 0.7217880487442017\n","Epoch: 1, Loss: 0.7059255242347717\n","Epoch: 1, Loss: 0.7101677656173706\n","Epoch: 1, Loss: 0.689735472202301\n","Epoch: 1, Loss: 0.6898126602172852\n","Epoch: 1, Loss: 0.6828958988189697\n","Epoch: 1, Loss: 0.6615380048751831\n","Epoch: 1, Loss: 0.7268730401992798\n","Epoch: 1, Loss: 0.7333230376243591\n","Epoch: 1, Loss: 0.7530176043510437\n","Epoch: 1, Loss: 0.7030528783798218\n","Epoch: 1, Loss: 0.7001793384552002\n","Epoch: 1, Loss: 0.7011594772338867\n","Epoch: 1, Loss: 0.7586047053337097\n","Epoch: 1, Loss: 0.6641963124275208\n","Epoch: 1, Loss: 0.7254679203033447\n","Epoch: 1, Loss: 0.7407835125923157\n","Epoch: 1, Loss: 0.6287239193916321\n","Epoch: 1, Loss: 0.6960886716842651\n","Epoch: 1, Loss: 0.7060625553131104\n","Epoch: 1, Loss: 0.772926926612854\n","Epoch: 1, Loss: 0.7152190208435059\n","Epoch: 1, Loss: 0.620345950126648\n","Epoch: 1, Loss: 0.6939530968666077\n","Epoch: 1, Loss: 0.7585810422897339\n","Epoch: 1, Loss: 0.791077196598053\n","Epoch: 1, Loss: 0.7039095163345337\n","Epoch: 1, Loss: 0.771063506603241\n","Epoch: 1, Loss: 0.7297067642211914\n","Epoch: 1, Loss: 0.6379967927932739\n","Epoch: 1, Loss: 0.6924224495887756\n","Epoch: 1, Loss: 0.7604886293411255\n","Epoch: 1, Loss: 0.6950584053993225\n","Epoch: 1, Loss: 0.6847140192985535\n","Epoch: 1, Loss: 0.6967750787734985\n","Epoch: 1, Loss: 0.6791102886199951\n","Epoch: 1, Loss: 0.8243012428283691\n","Epoch: 1, Loss: 0.6470478177070618\n","Epoch: 1, Loss: 0.7410069108009338\n","Epoch: 1, Loss: 0.698372483253479\n","Epoch: 1, Loss: 0.6830979585647583\n","Epoch: 1, Loss: 0.7189548015594482\n","Epoch: 1, Loss: 0.7581112384796143\n","Epoch: 1, Loss: 0.7444047331809998\n","Epoch: 1, Loss: 0.6931828260421753\n","Epoch: 1, Loss: 0.6021748781204224\n","Epoch: 1, Loss: 0.7065719366073608\n","Epoch: 1, Loss: 0.7656577825546265\n","Epoch: 1, Loss: 0.7032665610313416\n","Epoch: 1, Loss: 0.6957119703292847\n","Epoch: 1, Loss: 0.6821069717407227\n","Epoch: 1, Loss: 0.7394682765007019\n","Epoch: 1, Loss: 0.7054257392883301\n","Epoch: 1, Loss: 0.7743101716041565\n","Epoch: 1, Loss: 0.6420643329620361\n","Epoch: 1, Loss: 0.6853653192520142\n","Epoch: 1, Loss: 0.7331405878067017\n","Epoch: 1, Loss: 0.6529043912887573\n","Epoch: 1, Loss: 0.6847763657569885\n","Epoch: 1, Loss: 0.6683753132820129\n","Epoch: 1, Loss: 0.6708096265792847\n","Epoch: 1, Loss: 0.7795418500900269\n","Epoch: 1, Loss: 0.7243316769599915\n","Epoch: 1, Loss: 0.7895505428314209\n","Epoch: 1, Loss: 0.7538180351257324\n","Epoch: 1, Loss: 0.6536793112754822\n","Epoch: 1, Loss: 0.7493813037872314\n","Epoch: 1, Loss: 0.6847285628318787\n","Epoch: 1, Loss: 0.7317345142364502\n","Epoch: 1, Loss: 0.6935999393463135\n","Epoch: 1, Loss: 0.7413055300712585\n","Epoch: 1, Loss: 0.6891217231750488\n","Epoch: 1, Loss: 0.6645103693008423\n","Epoch: 1, Loss: 0.6667909622192383\n","Epoch: 1, Loss: 0.6903525590896606\n","Epoch: 1, Loss: 0.7148674726486206\n","Epoch: 1, Loss: 0.6095899343490601\n","Epoch: 1, Loss: 0.6578208208084106\n","Epoch: 1, Loss: 0.696306586265564\n","Epoch: 1, Loss: 0.793732762336731\n","Epoch: 1, Loss: 0.7442911267280579\n","Epoch: 1, Loss: 0.7400754690170288\n","Epoch: 1, Loss: 0.7475701570510864\n","Epoch: 1, Loss: 0.7482540607452393\n","Epoch: 1, Loss: 0.7844247817993164\n","Epoch: 1, Loss: 0.7048003077507019\n","Epoch: 1, Loss: 0.6731843948364258\n","Epoch: 1, Loss: 0.750924825668335\n","Epoch: 1, Loss: 0.7322983145713806\n","Epoch: 1, Loss: 0.7190693616867065\n","Epoch: 1, Loss: 0.7419723272323608\n","Epoch: 1, Loss: 0.710159420967102\n","Epoch: 1, Loss: 0.6900060176849365\n","Epoch: 1, Loss: 0.7144299745559692\n","Epoch: 1, Loss: 0.7322719097137451\n","Epoch: 1, Loss: 0.7137939929962158\n","Epoch: 1, Loss: 0.6412943601608276\n","Epoch: 1, Loss: 0.6634050011634827\n","Epoch: 1, Loss: 0.7205868363380432\n","Epoch: 1, Loss: 0.7156823873519897\n","Epoch: 1, Loss: 0.7349892854690552\n","Epoch: 1, Loss: 0.6125006675720215\n","Epoch: 1, Loss: 0.6969514489173889\n","Epoch: 1, Loss: 0.7489063739776611\n","Epoch: 1, Loss: 0.6916306018829346\n","Epoch: 1, Loss: 0.7007320523262024\n","Epoch: 1, Loss: 0.6637758016586304\n","Epoch: 1, Loss: 0.7018272280693054\n","Epoch: 1, Loss: 0.6726935505867004\n","Epoch: 1, Loss: 0.6926963925361633\n","Epoch: 1, Loss: 0.6070027947425842\n","Epoch: 1, Loss: 0.7126166224479675\n","Epoch: 1, Loss: 0.743922233581543\n","Epoch: 1, Loss: 0.6210801005363464\n","Epoch: 2, Loss: 0.701972484588623\n","Epoch: 2, Loss: 0.7221314311027527\n","Epoch: 2, Loss: 0.668821394443512\n","Epoch: 2, Loss: 0.7316019535064697\n","Epoch: 2, Loss: 0.6984853148460388\n","Epoch: 2, Loss: 0.8470280170440674\n","Epoch: 2, Loss: 0.797669529914856\n","Epoch: 2, Loss: 0.6549876928329468\n","Epoch: 2, Loss: 0.6881852746009827\n","Epoch: 2, Loss: 0.6643918752670288\n","Epoch: 2, Loss: 0.677359402179718\n","Epoch: 2, Loss: 0.7334188222885132\n","Epoch: 2, Loss: 0.7313864231109619\n","Epoch: 2, Loss: 0.7510481476783752\n","Epoch: 2, Loss: 0.8331197500228882\n","Epoch: 2, Loss: 0.650735080242157\n","Epoch: 2, Loss: 0.727084755897522\n","Epoch: 2, Loss: 0.6672910451889038\n","Epoch: 2, Loss: 0.7069815397262573\n","Epoch: 2, Loss: 0.759307861328125\n","Epoch: 2, Loss: 0.6631794571876526\n","Epoch: 2, Loss: 0.7526584267616272\n","Epoch: 2, Loss: 0.7399084568023682\n","Epoch: 2, Loss: 0.7415534257888794\n","Epoch: 2, Loss: 0.8149897456169128\n","Epoch: 2, Loss: 0.6531301736831665\n","Epoch: 2, Loss: 0.7550537586212158\n","Epoch: 2, Loss: 0.6640544533729553\n","Epoch: 2, Loss: 0.7238383293151855\n","Epoch: 2, Loss: 0.6944462060928345\n","Epoch: 2, Loss: 0.8112154006958008\n","Epoch: 2, Loss: 0.7071925401687622\n","Epoch: 2, Loss: 0.6825292706489563\n","Epoch: 2, Loss: 0.7312295436859131\n","Epoch: 2, Loss: 0.7092656493186951\n","Epoch: 2, Loss: 0.6554434895515442\n","Epoch: 2, Loss: 0.6682945489883423\n","Epoch: 2, Loss: 0.683303713798523\n","Epoch: 2, Loss: 0.7370287179946899\n","Epoch: 2, Loss: 0.7223186492919922\n","Epoch: 2, Loss: 0.6920771598815918\n","Epoch: 2, Loss: 0.6977381706237793\n","Epoch: 2, Loss: 0.6848912239074707\n","Epoch: 2, Loss: 0.7091143727302551\n","Epoch: 2, Loss: 0.7195653319358826\n","Epoch: 2, Loss: 0.7576062083244324\n","Epoch: 2, Loss: 0.6699530482292175\n","Epoch: 2, Loss: 0.675766110420227\n","Epoch: 2, Loss: 0.7221313714981079\n","Epoch: 2, Loss: 0.63038170337677\n","Epoch: 2, Loss: 0.7125504016876221\n","Epoch: 2, Loss: 0.7106538414955139\n","Epoch: 2, Loss: 0.6724388599395752\n","Epoch: 2, Loss: 0.7355322241783142\n","Epoch: 2, Loss: 0.712067723274231\n","Epoch: 2, Loss: 0.661686897277832\n","Epoch: 2, Loss: 0.7033029794692993\n","Epoch: 2, Loss: 0.7821882963180542\n","Epoch: 2, Loss: 0.6644982695579529\n","Epoch: 2, Loss: 0.6852376461029053\n","Epoch: 2, Loss: 0.673015296459198\n","Epoch: 2, Loss: 0.6738163232803345\n","Epoch: 2, Loss: 0.7096444964408875\n","Epoch: 2, Loss: 0.7563809156417847\n","Epoch: 2, Loss: 0.7105359435081482\n","Epoch: 2, Loss: 0.649023175239563\n","Epoch: 2, Loss: 0.6906374096870422\n","Epoch: 2, Loss: 0.6809821128845215\n","Epoch: 2, Loss: 0.6667013168334961\n","Epoch: 2, Loss: 0.6449517011642456\n","Epoch: 2, Loss: 0.6609681248664856\n","Epoch: 2, Loss: 0.7108176946640015\n","Epoch: 2, Loss: 0.6964605450630188\n","Epoch: 2, Loss: 0.7033525705337524\n","Epoch: 2, Loss: 0.7693049311637878\n","Epoch: 2, Loss: 0.685760498046875\n","Epoch: 2, Loss: 0.7525745034217834\n","Epoch: 2, Loss: 0.6735859513282776\n","Epoch: 2, Loss: 0.6968632340431213\n","Epoch: 2, Loss: 0.7445363402366638\n","Epoch: 2, Loss: 0.7310733795166016\n","Epoch: 2, Loss: 0.6695038676261902\n","Epoch: 2, Loss: 0.7985050082206726\n","Epoch: 2, Loss: 0.6689817905426025\n","Epoch: 2, Loss: 0.6857702136039734\n","Epoch: 2, Loss: 0.739987313747406\n","Epoch: 2, Loss: 0.7318223118782043\n","Epoch: 2, Loss: 0.7429121732711792\n","Epoch: 2, Loss: 0.7102577090263367\n","Epoch: 2, Loss: 0.7036272883415222\n","Epoch: 2, Loss: 0.7475611567497253\n","Epoch: 2, Loss: 0.7190465331077576\n","Epoch: 2, Loss: 0.7507767677307129\n","Epoch: 2, Loss: 0.6292361617088318\n","Epoch: 2, Loss: 0.6399589776992798\n","Epoch: 2, Loss: 0.6833950877189636\n","Epoch: 2, Loss: 0.6921379566192627\n","Epoch: 2, Loss: 0.749566376209259\n","Epoch: 2, Loss: 0.7146050333976746\n","Epoch: 2, Loss: 0.794002890586853\n","Epoch: 2, Loss: 0.6342403888702393\n","Epoch: 2, Loss: 0.6694598197937012\n","Epoch: 2, Loss: 0.6508104205131531\n","Epoch: 2, Loss: 0.7444258332252502\n","Epoch: 2, Loss: 0.695878267288208\n","Epoch: 2, Loss: 0.7111226916313171\n","Epoch: 2, Loss: 0.7534215450286865\n","Epoch: 2, Loss: 0.7209637761116028\n","Epoch: 2, Loss: 0.7357316613197327\n","Epoch: 2, Loss: 0.6924235224723816\n","Epoch: 2, Loss: 0.7138223648071289\n","Epoch: 2, Loss: 0.6639826893806458\n","Epoch: 2, Loss: 0.7204928398132324\n","Epoch: 2, Loss: 0.7017986178398132\n","Epoch: 2, Loss: 0.6446937322616577\n","Epoch: 2, Loss: 0.6045910120010376\n","Epoch: 2, Loss: 0.7357648611068726\n","Epoch: 2, Loss: 0.7182679176330566\n","Epoch: 2, Loss: 0.6902692914009094\n","Epoch: 2, Loss: 0.6038740277290344\n","Epoch: 2, Loss: 0.7249339818954468\n","Epoch: 2, Loss: 0.6615689396858215\n","Epoch: 2, Loss: 0.7224775552749634\n","Epoch: 2, Loss: 0.6254315972328186\n","Epoch: 2, Loss: 0.7126204371452332\n","Epoch: 2, Loss: 0.5953327417373657\n","Epoch: 2, Loss: 0.8187868595123291\n","Epoch: 2, Loss: 0.7195141911506653\n","Epoch: 2, Loss: 0.6769038438796997\n","Epoch: 2, Loss: 0.8489362597465515\n","Epoch: 2, Loss: 0.6240871548652649\n","Epoch: 2, Loss: 0.8977253437042236\n","Epoch: 2, Loss: 0.6864938139915466\n","Epoch: 2, Loss: 0.7560300230979919\n","Epoch: 2, Loss: 0.7345331311225891\n","Epoch: 2, Loss: 0.7939438819885254\n","Epoch: 2, Loss: 0.649588942527771\n","Epoch: 2, Loss: 0.721429705619812\n","Epoch: 2, Loss: 0.6675814986228943\n","Epoch: 2, Loss: 0.6993301510810852\n","Epoch: 2, Loss: 0.6530133485794067\n","Epoch: 2, Loss: 0.70521080493927\n","Epoch: 2, Loss: 0.7167597413063049\n","Epoch: 2, Loss: 0.7340784072875977\n","Epoch: 2, Loss: 0.7216421961784363\n","Epoch: 2, Loss: 0.6669806838035583\n","Epoch: 2, Loss: 0.5849955677986145\n","Epoch: 2, Loss: 0.648937463760376\n","Epoch: 2, Loss: 0.6646404266357422\n","Epoch: 2, Loss: 0.7336118817329407\n","Epoch: 2, Loss: 0.7128250598907471\n","Epoch: 2, Loss: 0.7120199203491211\n","Epoch: 2, Loss: 0.7221715450286865\n","Epoch: 2, Loss: 0.6546964049339294\n","Epoch: 2, Loss: 0.7381688356399536\n","Epoch: 2, Loss: 0.568105161190033\n","Epoch: 2, Loss: 0.7927318811416626\n","Epoch: 2, Loss: 0.6635938882827759\n","Epoch: 2, Loss: 0.6986298561096191\n","Epoch: 2, Loss: 0.7392545342445374\n","Epoch: 2, Loss: 0.7479295134544373\n","Epoch: 2, Loss: 0.7227766513824463\n","Epoch: 2, Loss: 0.5754861831665039\n","Epoch: 2, Loss: 0.6635763049125671\n","Epoch: 2, Loss: 0.6700701117515564\n","Epoch: 2, Loss: 0.7211917042732239\n","Epoch: 2, Loss: 0.7309689521789551\n","Epoch: 2, Loss: 0.7454565763473511\n","Epoch: 2, Loss: 0.6983157396316528\n","Epoch: 2, Loss: 0.7423670887947083\n","Epoch: 2, Loss: 0.660987138748169\n","Epoch: 2, Loss: 0.6745632886886597\n","Epoch: 2, Loss: 0.7125191688537598\n","Epoch: 2, Loss: 0.722301721572876\n","Epoch: 2, Loss: 0.7024705410003662\n","Epoch: 2, Loss: 0.619340181350708\n","Epoch: 2, Loss: 0.7356100082397461\n","Epoch: 2, Loss: 0.7079409956932068\n","Epoch: 2, Loss: 0.7361721992492676\n","Epoch: 2, Loss: 0.6673900485038757\n","Epoch: 2, Loss: 0.7676571011543274\n","Epoch: 2, Loss: 0.6680296659469604\n","Epoch: 2, Loss: 0.6879113912582397\n","Epoch: 2, Loss: 0.668225884437561\n","Epoch: 2, Loss: 0.6722303032875061\n","Epoch: 2, Loss: 0.6818671822547913\n","Epoch: 2, Loss: 0.6831119656562805\n","Epoch: 2, Loss: 0.7163075804710388\n","Epoch: 2, Loss: 0.7880070805549622\n","Epoch: 2, Loss: 0.6852777600288391\n","Epoch: 2, Loss: 0.689538300037384\n","Epoch: 2, Loss: 0.7145965695381165\n","Epoch: 2, Loss: 0.7242441177368164\n","Epoch: 2, Loss: 0.6607264280319214\n","Epoch: 2, Loss: 0.7425772547721863\n","Epoch: 2, Loss: 0.6377671957015991\n","Epoch: 2, Loss: 0.6806450486183167\n","Epoch: 2, Loss: 0.7069558501243591\n","Epoch: 2, Loss: 0.7411850094795227\n","Epoch: 2, Loss: 0.6642030477523804\n","Epoch: 2, Loss: 0.7403287887573242\n","Epoch: 2, Loss: 0.6511852741241455\n","Epoch: 2, Loss: 0.6609074473381042\n","Epoch: 2, Loss: 0.6510179042816162\n","Epoch: 2, Loss: 0.7859759330749512\n","Epoch: 2, Loss: 0.6801893711090088\n","Epoch: 2, Loss: 0.6885445713996887\n","Epoch: 2, Loss: 0.6512839794158936\n","Epoch: 2, Loss: 0.6671091914176941\n","Epoch: 2, Loss: 0.6568435430526733\n","Epoch: 2, Loss: 0.681043803691864\n","Epoch: 2, Loss: 0.7058151364326477\n","Epoch: 2, Loss: 0.7060818672180176\n","Epoch: 2, Loss: 0.7264343500137329\n","Epoch: 2, Loss: 0.671205461025238\n","Epoch: 2, Loss: 0.662581205368042\n","Epoch: 2, Loss: 0.7339725494384766\n","Epoch: 2, Loss: 0.6784164905548096\n","Epoch: 2, Loss: 0.6243515610694885\n","Epoch: 2, Loss: 0.6931699514389038\n","Epoch: 2, Loss: 0.7246847748756409\n","Epoch: 2, Loss: 0.7813560962677002\n","Epoch: 2, Loss: 0.6924446225166321\n","Epoch: 2, Loss: 0.6788250803947449\n","Epoch: 2, Loss: 0.6863840222358704\n","Epoch: 2, Loss: 0.7328187227249146\n","Epoch: 2, Loss: 0.6619607210159302\n","Epoch: 2, Loss: 0.7100269198417664\n","Epoch: 2, Loss: 0.6622777581214905\n","Epoch: 2, Loss: 0.745361864566803\n","Epoch: 2, Loss: 0.7172822952270508\n","Epoch: 2, Loss: 0.6422669887542725\n","Epoch: 2, Loss: 0.7580060958862305\n","Epoch: 2, Loss: 0.7033183574676514\n","Epoch: 2, Loss: 0.6866441369056702\n","Epoch: 2, Loss: 0.6787189245223999\n","Epoch: 2, Loss: 0.7278400659561157\n","Epoch: 2, Loss: 0.7073574662208557\n","Epoch: 2, Loss: 0.6437830924987793\n","Epoch: 2, Loss: 0.7241859436035156\n","Epoch: 2, Loss: 0.6879766583442688\n","Epoch: 2, Loss: 0.6877955198287964\n","Epoch: 2, Loss: 0.6635683178901672\n","Epoch: 2, Loss: 0.6667160391807556\n","Epoch: 2, Loss: 0.7139056921005249\n","Epoch: 2, Loss: 0.6980512142181396\n","Epoch: 2, Loss: 0.6362184882164001\n","Epoch: 2, Loss: 0.801129937171936\n","Epoch: 2, Loss: 0.7104292511940002\n","Epoch: 2, Loss: 0.7859768867492676\n","Epoch: 2, Loss: 0.7209712266921997\n","Epoch: 2, Loss: 0.602199375629425\n","Epoch: 2, Loss: 0.6899934411048889\n","Epoch: 2, Loss: 0.6620306968688965\n","Epoch: 2, Loss: 0.6605350375175476\n","Epoch: 2, Loss: 0.722275972366333\n","Epoch: 2, Loss: 0.7386156320571899\n","Epoch: 2, Loss: 0.6339569687843323\n","Epoch: 2, Loss: 0.7277716398239136\n","Epoch: 2, Loss: 0.7082332968711853\n","Epoch: 2, Loss: 0.6129711270332336\n","Epoch: 2, Loss: 0.737352728843689\n","Epoch: 2, Loss: 0.6793978214263916\n","Epoch: 2, Loss: 0.7084841728210449\n","Epoch: 2, Loss: 0.7300844788551331\n","Epoch: 2, Loss: 0.8236620426177979\n","Epoch: 2, Loss: 0.6566895842552185\n","Epoch: 2, Loss: 0.6994031667709351\n","Epoch: 2, Loss: 0.6231666803359985\n","Epoch: 2, Loss: 0.7225643396377563\n","Epoch: 2, Loss: 0.7476682662963867\n","Epoch: 2, Loss: 0.6329546570777893\n","Epoch: 2, Loss: 0.6579728126525879\n","Epoch: 2, Loss: 0.6904419660568237\n","Epoch: 2, Loss: 0.7713078260421753\n","Epoch: 2, Loss: 0.6442257761955261\n","Epoch: 2, Loss: 0.6971051096916199\n","Epoch: 2, Loss: 0.7357336282730103\n","Epoch: 2, Loss: 0.6989073157310486\n","Epoch: 2, Loss: 0.6741706132888794\n","Epoch: 2, Loss: 0.6217089891433716\n","Epoch: 2, Loss: 0.6966491937637329\n","Epoch: 2, Loss: 0.6653856039047241\n","Epoch: 2, Loss: 0.723082423210144\n","Epoch: 2, Loss: 0.7167577147483826\n","Epoch: 2, Loss: 0.6863725185394287\n","Epoch: 2, Loss: 0.7160348892211914\n","Epoch: 2, Loss: 0.7384994626045227\n","Epoch: 2, Loss: 0.7368239760398865\n","Epoch: 2, Loss: 0.6066006422042847\n","Epoch: 2, Loss: 0.6636843085289001\n","Epoch: 2, Loss: 0.6642217040061951\n","Epoch: 2, Loss: 0.7515245676040649\n","Epoch: 2, Loss: 0.7682089805603027\n","Epoch: 2, Loss: 0.8174790740013123\n","Epoch: 2, Loss: 0.6788527965545654\n","Epoch: 2, Loss: 0.6745983362197876\n","Epoch: 2, Loss: 0.6508596539497375\n","Epoch: 2, Loss: 0.7619470357894897\n","Epoch: 2, Loss: 0.6493541598320007\n","Epoch: 2, Loss: 0.7210646271705627\n","Epoch: 2, Loss: 0.8128278255462646\n","Epoch: 2, Loss: 0.5979883670806885\n","Epoch: 2, Loss: 0.7020230293273926\n","Epoch: 2, Loss: 0.8209445476531982\n","Epoch: 2, Loss: 0.6912434101104736\n","Epoch: 2, Loss: 0.6973220705986023\n","Epoch: 2, Loss: 0.6992356181144714\n","Epoch: 2, Loss: 0.7036168575286865\n","Epoch: 2, Loss: 0.697292685508728\n","Epoch: 2, Loss: 0.7696502208709717\n","Epoch: 2, Loss: 0.6212930679321289\n","Epoch: 2, Loss: 0.7462560534477234\n","Epoch: 2, Loss: 0.6833505034446716\n","Epoch: 2, Loss: 0.6959363222122192\n","Epoch: 2, Loss: 0.7019391655921936\n","Epoch: 2, Loss: 0.7892487645149231\n","Epoch: 2, Loss: 0.7262584567070007\n","Epoch: 2, Loss: 0.6848122477531433\n","Epoch: 2, Loss: 0.7328170537948608\n","Epoch: 2, Loss: 0.7320584058761597\n","Epoch: 2, Loss: 0.7534939646720886\n","Epoch: 2, Loss: 0.6967346668243408\n","Epoch: 2, Loss: 0.7228344678878784\n","Epoch: 2, Loss: 0.7443439364433289\n","Epoch: 2, Loss: 0.6852668523788452\n","Epoch: 2, Loss: 0.7300167083740234\n","Epoch: 2, Loss: 0.6481763124465942\n","Epoch: 2, Loss: 0.7798876762390137\n","Epoch: 2, Loss: 0.7209816575050354\n","Epoch: 2, Loss: 0.8010976910591125\n","Epoch: 2, Loss: 0.6900880336761475\n","Epoch: 2, Loss: 0.7461815476417542\n","Epoch: 2, Loss: 0.7356717586517334\n","Epoch: 2, Loss: 0.6892871260643005\n","Epoch: 2, Loss: 0.7560829520225525\n","Epoch: 2, Loss: 0.6678152084350586\n","Epoch: 2, Loss: 0.6954547166824341\n","Epoch: 2, Loss: 0.6886467933654785\n","Epoch: 2, Loss: 0.7392994165420532\n","Epoch: 2, Loss: 0.7827000617980957\n","Epoch: 2, Loss: 0.6406762003898621\n","Epoch: 2, Loss: 0.6482119560241699\n","Epoch: 2, Loss: 0.6999176144599915\n","Epoch: 2, Loss: 0.8063182830810547\n","Epoch: 2, Loss: 0.6338675618171692\n","Epoch: 2, Loss: 0.7014247179031372\n","Epoch: 2, Loss: 0.7390674352645874\n","Epoch: 2, Loss: 0.6883992552757263\n","Epoch: 2, Loss: 0.6749862432479858\n","Epoch: 2, Loss: 0.666022539138794\n","Epoch: 2, Loss: 0.673412561416626\n","Epoch: 2, Loss: 0.735275149345398\n","Epoch: 2, Loss: 0.6960219740867615\n","Epoch: 2, Loss: 0.6406446099281311\n","Epoch: 2, Loss: 0.6799532175064087\n","Epoch: 2, Loss: 0.7390155792236328\n","Epoch: 2, Loss: 0.6882755160331726\n","Epoch: 2, Loss: 0.6729460954666138\n","Epoch: 2, Loss: 0.6560599207878113\n","Epoch: 2, Loss: 0.6188933849334717\n","Epoch: 2, Loss: 0.6464463472366333\n","Epoch: 2, Loss: 0.6805092096328735\n","Epoch: 2, Loss: 0.7179517149925232\n","Epoch: 2, Loss: 0.6902024745941162\n","Epoch: 2, Loss: 0.7626674771308899\n","Epoch: 2, Loss: 0.639234721660614\n","Epoch: 2, Loss: 0.7333728671073914\n","Epoch: 2, Loss: 0.6894864439964294\n","Epoch: 2, Loss: 0.7353795766830444\n","Epoch: 2, Loss: 0.7133699655532837\n","Epoch: 2, Loss: 0.7333588004112244\n","Epoch: 2, Loss: 0.6459984183311462\n","Epoch: 2, Loss: 0.7218804359436035\n","Epoch: 2, Loss: 0.6599016189575195\n","Epoch: 2, Loss: 0.7319473028182983\n","Epoch: 2, Loss: 0.6829237937927246\n","Epoch: 2, Loss: 0.7189749479293823\n","Epoch: 2, Loss: 0.7487972974777222\n","Epoch: 2, Loss: 0.7183732986450195\n","Epoch: 2, Loss: 0.6689486503601074\n","Epoch: 2, Loss: 0.7178283929824829\n","Epoch: 2, Loss: 0.6727676391601562\n","Epoch: 2, Loss: 0.7347162961959839\n","Epoch: 2, Loss: 0.7030046582221985\n","Epoch: 2, Loss: 0.7000536918640137\n","Epoch: 2, Loss: 0.74367356300354\n","Epoch: 2, Loss: 0.7197179198265076\n","Epoch: 2, Loss: 0.7423525452613831\n","Epoch: 2, Loss: 0.6253116130828857\n","Epoch: 2, Loss: 0.6931367516517639\n","Epoch: 2, Loss: 0.7488128542900085\n","Epoch: 2, Loss: 0.7244179248809814\n","Epoch: 2, Loss: 0.625991940498352\n","Epoch: 2, Loss: 0.726445734500885\n","Epoch: 2, Loss: 0.7152892351150513\n","Epoch: 2, Loss: 0.7313041687011719\n","Epoch: 2, Loss: 0.8015502691268921\n","Epoch: 2, Loss: 0.7085554003715515\n","Epoch: 2, Loss: 0.6613479852676392\n","Epoch: 2, Loss: 0.7054804563522339\n","Epoch: 2, Loss: 0.6983975172042847\n","Epoch: 2, Loss: 0.6930467486381531\n","Epoch: 2, Loss: 0.701120138168335\n","Epoch: 2, Loss: 0.6530322432518005\n","Epoch: 2, Loss: 0.7055582404136658\n","Epoch: 2, Loss: 0.7190070152282715\n","Epoch: 2, Loss: 0.6870166659355164\n","Epoch: 2, Loss: 0.6530106663703918\n","Epoch: 2, Loss: 0.6694774031639099\n","Epoch: 2, Loss: 0.6628751158714294\n","Epoch: 2, Loss: 0.6534844040870667\n","Epoch: 2, Loss: 0.6464879512786865\n","Epoch: 2, Loss: 0.7033605575561523\n","Epoch: 2, Loss: 0.6841819286346436\n","Epoch: 2, Loss: 0.670644998550415\n","Epoch: 2, Loss: 0.7108580470085144\n","Epoch: 2, Loss: 0.6892420053482056\n","Epoch: 2, Loss: 0.6612964272499084\n","Epoch: 2, Loss: 0.7347157001495361\n","Epoch: 2, Loss: 0.7454472780227661\n","Epoch: 2, Loss: 0.7333322763442993\n","Epoch: 2, Loss: 0.7218372225761414\n","Epoch: 2, Loss: 0.6621323823928833\n","Epoch: 2, Loss: 0.7419906258583069\n","Epoch: 2, Loss: 0.7304089069366455\n","Epoch: 2, Loss: 0.7810375690460205\n","Epoch: 2, Loss: 0.6510568857192993\n","Epoch: 2, Loss: 0.712099552154541\n","Epoch: 2, Loss: 0.731401264667511\n","Epoch: 2, Loss: 0.6865785121917725\n","Epoch: 2, Loss: 0.7193071842193604\n","Epoch: 2, Loss: 0.6939442753791809\n","Epoch: 2, Loss: 0.6734393835067749\n","Epoch: 2, Loss: 0.6805977821350098\n","Epoch: 2, Loss: 0.6637960076332092\n","Epoch: 2, Loss: 0.706101655960083\n","Epoch: 2, Loss: 0.7268486618995667\n","Epoch: 2, Loss: 0.7009540796279907\n","Epoch: 2, Loss: 0.7124144434928894\n","Epoch: 2, Loss: 0.7143679857254028\n","Epoch: 2, Loss: 0.6484081149101257\n","Epoch: 2, Loss: 0.7183145880699158\n","Epoch: 2, Loss: 0.7204366326332092\n","Epoch: 2, Loss: 0.7372840046882629\n","Epoch: 2, Loss: 0.6711814403533936\n","Epoch: 2, Loss: 0.7876607775688171\n","Epoch: 2, Loss: 0.6436412930488586\n","Epoch: 2, Loss: 0.6848993897438049\n","Epoch: 2, Loss: 0.7297285795211792\n","Epoch: 2, Loss: 0.6863220930099487\n","Epoch: 2, Loss: 0.70548015832901\n","Epoch: 2, Loss: 0.700543999671936\n","Epoch: 2, Loss: 0.7582296133041382\n","Epoch: 2, Loss: 0.8125844597816467\n","Epoch: 2, Loss: 0.7450914978981018\n","Epoch: 2, Loss: 0.6796252131462097\n","Epoch: 2, Loss: 0.6445611715316772\n","Epoch: 2, Loss: 0.7511106133460999\n","Epoch: 2, Loss: 0.6892790198326111\n","Epoch: 2, Loss: 0.6594507694244385\n","Epoch: 2, Loss: 0.7003331780433655\n","Epoch: 2, Loss: 0.6819871664047241\n","Epoch: 2, Loss: 0.671784520149231\n","Epoch: 2, Loss: 0.6713008284568787\n","Epoch: 2, Loss: 0.678196370601654\n","Epoch: 2, Loss: 0.6452532410621643\n","Epoch: 2, Loss: 0.6762498617172241\n","Epoch: 2, Loss: 0.6347211599349976\n","Epoch: 2, Loss: 0.6596705317497253\n","Epoch: 2, Loss: 0.7055665254592896\n","Epoch: 2, Loss: 0.7347061634063721\n","Epoch: 2, Loss: 0.711500346660614\n","Epoch: 2, Loss: 0.646690845489502\n","Epoch: 2, Loss: 0.71385258436203\n","Epoch: 2, Loss: 0.7171545624732971\n","Epoch: 2, Loss: 0.6753045916557312\n","Epoch: 2, Loss: 0.725676417350769\n","Epoch: 2, Loss: 0.7107247114181519\n","Epoch: 2, Loss: 0.6635230779647827\n","Epoch: 2, Loss: 0.6983544230461121\n","Epoch: 2, Loss: 0.646446168422699\n","Epoch: 2, Loss: 0.6817833781242371\n","Epoch: 2, Loss: 0.700973391532898\n","Epoch: 2, Loss: 0.7607182860374451\n","Epoch: 2, Loss: 0.764642596244812\n","Epoch: 2, Loss: 0.7659822702407837\n","Epoch: 2, Loss: 0.6973759531974792\n","Epoch: 2, Loss: 0.6947315335273743\n","Epoch: 2, Loss: 0.6294847130775452\n","Epoch: 2, Loss: 0.6878268718719482\n","Epoch: 2, Loss: 0.680276095867157\n","Epoch: 2, Loss: 0.6321722269058228\n","Epoch: 2, Loss: 0.6969738602638245\n","Epoch: 2, Loss: 0.6556469202041626\n","Epoch: 2, Loss: 0.7065240740776062\n","Epoch: 2, Loss: 0.7895301580429077\n","Epoch: 2, Loss: 0.6479385495185852\n","Epoch: 2, Loss: 0.7065040469169617\n","Epoch: 2, Loss: 0.6563571691513062\n","Epoch: 2, Loss: 0.6791704893112183\n","Epoch: 2, Loss: 0.6553358435630798\n","Epoch: 2, Loss: 0.7061170935630798\n","Epoch: 2, Loss: 0.7205424904823303\n","Epoch: 2, Loss: 0.7943719625473022\n","Epoch: 2, Loss: 0.7310193777084351\n","Epoch: 2, Loss: 0.6988382935523987\n","Epoch: 2, Loss: 0.6876435875892639\n","Epoch: 2, Loss: 0.6563102006912231\n","Epoch: 2, Loss: 0.7919461727142334\n","Epoch: 2, Loss: 0.7893714904785156\n","Epoch: 2, Loss: 0.7039031982421875\n","Epoch: 2, Loss: 0.6612141132354736\n","Epoch: 2, Loss: 0.7254992723464966\n","Epoch: 2, Loss: 0.7402098774909973\n","Epoch: 2, Loss: 0.6529425978660583\n","Epoch: 2, Loss: 0.6799622178077698\n","Epoch: 2, Loss: 0.6613669991493225\n","Epoch: 2, Loss: 0.7572652101516724\n","Epoch: 2, Loss: 0.6512712240219116\n","Epoch: 2, Loss: 0.7309492826461792\n","Epoch: 2, Loss: 0.6953264474868774\n","Epoch: 2, Loss: 0.7194219827651978\n","Epoch: 2, Loss: 0.6610773205757141\n","Epoch: 2, Loss: 0.6838270425796509\n","Epoch: 2, Loss: 0.6718683242797852\n","Epoch: 2, Loss: 0.6624467372894287\n","Epoch: 2, Loss: 0.7039986848831177\n","Epoch: 2, Loss: 0.7047170400619507\n","Epoch: 2, Loss: 0.7541313767433167\n","Epoch: 2, Loss: 0.6747979521751404\n","Epoch: 2, Loss: 0.7403887510299683\n","Epoch: 2, Loss: 0.6634294986724854\n","Epoch: 2, Loss: 0.6470588445663452\n","Epoch: 2, Loss: 0.6588078141212463\n","Epoch: 2, Loss: 0.7075402736663818\n","Epoch: 2, Loss: 0.7868632674217224\n","Epoch: 2, Loss: 0.6678662896156311\n","Epoch: 2, Loss: 0.7441627383232117\n","Epoch: 2, Loss: 0.6891210675239563\n","Epoch: 2, Loss: 0.8186997771263123\n","Epoch: 2, Loss: 0.7374782562255859\n","Epoch: 2, Loss: 0.7382901310920715\n","Epoch: 2, Loss: 0.7124901413917542\n","Epoch: 2, Loss: 0.6964590549468994\n","Epoch: 2, Loss: 0.6820319890975952\n","Epoch: 2, Loss: 0.6985178589820862\n","Epoch: 2, Loss: 0.7591543197631836\n","Epoch: 2, Loss: 0.7399327754974365\n","Epoch: 2, Loss: 0.7158089280128479\n","Epoch: 2, Loss: 0.7228107452392578\n","Epoch: 2, Loss: 0.7121933102607727\n","Epoch: 2, Loss: 0.687842845916748\n","Epoch: 2, Loss: 0.7444149255752563\n","Epoch: 2, Loss: 0.746677815914154\n","Epoch: 2, Loss: 0.6924501657485962\n","Epoch: 2, Loss: 0.6714911460876465\n","Epoch: 2, Loss: 0.7166832685470581\n","Epoch: 2, Loss: 0.673176646232605\n","Epoch: 2, Loss: 0.6890550255775452\n","Epoch: 2, Loss: 0.6990269422531128\n","Epoch: 2, Loss: 0.7279486656188965\n","Epoch: 2, Loss: 0.708977460861206\n","Epoch: 2, Loss: 0.7037463784217834\n","Epoch: 2, Loss: 0.7533448338508606\n","Epoch: 2, Loss: 0.7078059911727905\n","Epoch: 2, Loss: 0.7348659038543701\n","Epoch: 2, Loss: 0.7157784700393677\n","Epoch: 2, Loss: 0.7033374309539795\n","Epoch: 2, Loss: 0.6531690359115601\n","Epoch: 2, Loss: 0.718036949634552\n","Epoch: 2, Loss: 0.6255353093147278\n","Epoch: 2, Loss: 0.7354146242141724\n","Epoch: 2, Loss: 0.6965856552124023\n","Epoch: 2, Loss: 0.6941865682601929\n","Epoch: 2, Loss: 0.6903619766235352\n","Epoch: 2, Loss: 0.6861443519592285\n","Epoch: 2, Loss: 0.7812759280204773\n","Epoch: 2, Loss: 0.7275272011756897\n","Epoch: 2, Loss: 0.7872004508972168\n","Epoch: 2, Loss: 0.6743442416191101\n","Epoch: 2, Loss: 0.7302601933479309\n","Epoch: 2, Loss: 0.692272424697876\n","Epoch: 2, Loss: 0.6333052515983582\n","Epoch: 2, Loss: 0.658149778842926\n","Epoch: 2, Loss: 0.7013080716133118\n","Epoch: 2, Loss: 0.709266722202301\n","Epoch: 2, Loss: 0.7171750068664551\n","Epoch: 2, Loss: 0.6779459714889526\n","Epoch: 2, Loss: 0.6556220054626465\n","Epoch: 2, Loss: 0.6241778135299683\n","Epoch: 2, Loss: 0.7212444543838501\n","Epoch: 2, Loss: 0.7429724931716919\n","Epoch: 2, Loss: 0.7455113530158997\n","Epoch: 2, Loss: 0.6604229807853699\n","Epoch: 2, Loss: 0.7353159785270691\n","Epoch: 2, Loss: 0.7095275521278381\n","Epoch: 2, Loss: 0.6595646739006042\n","Epoch: 2, Loss: 0.6338990926742554\n","Epoch: 2, Loss: 0.6706613302230835\n","Epoch: 2, Loss: 0.6487939953804016\n","Epoch: 2, Loss: 0.7276551127433777\n","Epoch: 2, Loss: 0.6601418256759644\n","Epoch: 2, Loss: 0.7192062139511108\n","Epoch: 2, Loss: 0.691845178604126\n","Epoch: 2, Loss: 0.6763811111450195\n","Epoch: 2, Loss: 0.697053074836731\n","Epoch: 2, Loss: 0.7573462128639221\n","Epoch: 2, Loss: 0.7488272190093994\n","Epoch: 2, Loss: 0.6252845525741577\n","Epoch: 2, Loss: 0.6945835947990417\n","Epoch: 2, Loss: 0.7524517774581909\n","Epoch: 2, Loss: 0.6486819982528687\n","Epoch: 2, Loss: 0.7647489905357361\n","Epoch: 2, Loss: 0.6703260540962219\n","Epoch: 2, Loss: 0.6592323780059814\n","Epoch: 2, Loss: 0.681450366973877\n","Epoch: 2, Loss: 0.6657379865646362\n","Epoch: 2, Loss: 0.7033876776695251\n","Epoch: 2, Loss: 0.7342528104782104\n","Epoch: 2, Loss: 0.7456473112106323\n","Epoch: 2, Loss: 0.6562720537185669\n","Epoch: 2, Loss: 0.7106872797012329\n","Epoch: 2, Loss: 0.6523851156234741\n","Epoch: 2, Loss: 0.6949864625930786\n","Epoch: 2, Loss: 0.6884676218032837\n","Epoch: 2, Loss: 0.7259377837181091\n","Epoch: 2, Loss: 0.7058248519897461\n","Epoch: 2, Loss: 0.7079164385795593\n","Epoch: 2, Loss: 0.7900314331054688\n","Epoch: 2, Loss: 0.659887433052063\n","Epoch: 2, Loss: 0.7680585384368896\n","Epoch: 2, Loss: 0.7358860373497009\n","Epoch: 2, Loss: 0.7897679805755615\n","Epoch: 2, Loss: 0.7048986554145813\n","Epoch: 2, Loss: 0.7429878115653992\n","Epoch: 2, Loss: 0.6614352464675903\n","Epoch: 2, Loss: 0.7477335333824158\n","Epoch: 2, Loss: 0.7220064401626587\n","Epoch: 2, Loss: 0.6500624418258667\n","Epoch: 2, Loss: 0.6640796661376953\n","Epoch: 2, Loss: 0.7399262189865112\n","Epoch: 2, Loss: 0.7053472399711609\n","Epoch: 2, Loss: 0.6506792902946472\n","Epoch: 2, Loss: 0.6854676008224487\n","Epoch: 2, Loss: 0.7153222560882568\n","Epoch: 2, Loss: 0.6863628625869751\n","Epoch: 2, Loss: 0.6971563100814819\n","Epoch: 2, Loss: 0.685336709022522\n","Epoch: 2, Loss: 0.713929295539856\n","Epoch: 2, Loss: 0.7173132300376892\n","Epoch: 2, Loss: 0.6992146968841553\n","Epoch: 2, Loss: 0.6323838829994202\n","Epoch: 2, Loss: 0.6623872518539429\n","Epoch: 2, Loss: 0.7105511426925659\n","Epoch: 2, Loss: 0.6804549098014832\n","Epoch: 2, Loss: 0.7319297194480896\n","Epoch: 2, Loss: 0.6426533460617065\n","Epoch: 2, Loss: 0.7290428876876831\n","Epoch: 2, Loss: 0.731059730052948\n","Epoch: 2, Loss: 0.6763077974319458\n","Epoch: 2, Loss: 0.6735662817955017\n","Epoch: 2, Loss: 0.7059641480445862\n","Epoch: 2, Loss: 0.6542125940322876\n","Epoch: 2, Loss: 0.7405466437339783\n","Epoch: 2, Loss: 0.794346809387207\n","Epoch: 2, Loss: 0.6754883527755737\n","Epoch: 2, Loss: 0.7404470443725586\n","Epoch: 2, Loss: 0.6863632798194885\n","Epoch: 2, Loss: 0.7001962661743164\n","Epoch: 2, Loss: 0.6774821281433105\n","Epoch: 2, Loss: 0.6819722652435303\n","Epoch: 2, Loss: 0.6812843680381775\n","Epoch: 2, Loss: 0.683853268623352\n","Epoch: 2, Loss: 0.6667764782905579\n","Epoch: 2, Loss: 0.6443305015563965\n","Epoch: 2, Loss: 0.7803733348846436\n","Epoch: 2, Loss: 0.7259603142738342\n","Epoch: 2, Loss: 0.7400833368301392\n","Epoch: 2, Loss: 0.6726014018058777\n","Epoch: 2, Loss: 0.7049981355667114\n","Epoch: 2, Loss: 0.6793226599693298\n","Epoch: 2, Loss: 0.712660551071167\n","Epoch: 2, Loss: 0.7225794196128845\n","Epoch: 2, Loss: 0.7110267281532288\n","Epoch: 2, Loss: 0.6626614928245544\n","Epoch: 2, Loss: 0.6967779397964478\n","Epoch: 2, Loss: 0.7217029333114624\n","Epoch: 2, Loss: 0.7185830473899841\n","Epoch: 2, Loss: 0.7351802587509155\n","Epoch: 2, Loss: 0.69329434633255\n","Epoch: 2, Loss: 0.5834166407585144\n","Epoch: 2, Loss: 0.6808062195777893\n","Epoch: 2, Loss: 0.6247402429580688\n","Epoch: 2, Loss: 0.6631470918655396\n","Epoch: 2, Loss: 0.7331236004829407\n","Epoch: 2, Loss: 0.7506531476974487\n","Epoch: 2, Loss: 0.7149026393890381\n","Epoch: 2, Loss: 0.6549825668334961\n","Epoch: 2, Loss: 0.6473338007926941\n","Epoch: 2, Loss: 0.7285048365592957\n","Epoch: 2, Loss: 0.6427779793739319\n","Epoch: 2, Loss: 0.7772151231765747\n","Epoch: 2, Loss: 0.7171626091003418\n","Epoch: 2, Loss: 0.7100754380226135\n","Epoch: 2, Loss: 0.6734474301338196\n","Epoch: 2, Loss: 0.7144743800163269\n","Epoch: 2, Loss: 0.7280921936035156\n","Epoch: 2, Loss: 0.6434884071350098\n","Epoch: 2, Loss: 0.7156741619110107\n","Epoch: 2, Loss: 0.7027062773704529\n","Epoch: 2, Loss: 0.6805880069732666\n","Epoch: 2, Loss: 0.663299560546875\n","Epoch: 2, Loss: 0.70115727186203\n","Epoch: 2, Loss: 0.6872508525848389\n","Epoch: 2, Loss: 0.6919984817504883\n","Epoch: 2, Loss: 0.6892338991165161\n","Epoch: 2, Loss: 0.6990625858306885\n","Epoch: 2, Loss: 0.7130427360534668\n","Epoch: 2, Loss: 0.7133501768112183\n","Epoch: 2, Loss: 0.6958675384521484\n","Epoch: 2, Loss: 0.6816486120223999\n","Epoch: 2, Loss: 0.692180871963501\n","Epoch: 2, Loss: 0.6989017128944397\n","Epoch: 2, Loss: 0.6956868171691895\n","Epoch: 2, Loss: 0.7038441300392151\n","Epoch: 2, Loss: 0.6675519943237305\n","Epoch: 2, Loss: 0.6961265206336975\n","Epoch: 2, Loss: 0.619958758354187\n","Epoch: 2, Loss: 0.7056164741516113\n","Epoch: 2, Loss: 0.6576597690582275\n","Epoch: 2, Loss: 0.72373366355896\n","Epoch: 2, Loss: 0.6992307305335999\n","Epoch: 2, Loss: 0.7103819251060486\n","Epoch: 2, Loss: 0.6637680530548096\n","Epoch: 2, Loss: 0.6792736649513245\n","Epoch: 2, Loss: 0.674248218536377\n","Epoch: 2, Loss: 0.6585376262664795\n","Epoch: 2, Loss: 0.6976664066314697\n","Epoch: 2, Loss: 0.6501661539077759\n","Epoch: 2, Loss: 0.7128055691719055\n","Epoch: 2, Loss: 0.6646214127540588\n","Epoch: 2, Loss: 0.7403985857963562\n","Epoch: 2, Loss: 0.6919222474098206\n","Epoch: 2, Loss: 0.7275605201721191\n","Epoch: 2, Loss: 0.7606872320175171\n","Epoch: 2, Loss: 0.6510220170021057\n","Epoch: 2, Loss: 0.7008112072944641\n","Epoch: 2, Loss: 0.7111427783966064\n","Epoch: 2, Loss: 0.6760756969451904\n","Epoch: 2, Loss: 0.7646936178207397\n","Epoch: 2, Loss: 0.7127746343612671\n","Epoch: 2, Loss: 0.7051381468772888\n","Epoch: 2, Loss: 0.7570174932479858\n","Epoch: 2, Loss: 0.6352460384368896\n","Epoch: 2, Loss: 0.6875259280204773\n","Epoch: 2, Loss: 0.7043424248695374\n","Epoch: 2, Loss: 0.6557118892669678\n","Epoch: 2, Loss: 0.6361225843429565\n","Epoch: 2, Loss: 0.6142534613609314\n","Epoch: 2, Loss: 0.7204744219779968\n","Epoch: 2, Loss: 0.6568926572799683\n","Epoch: 2, Loss: 0.7379916906356812\n","Epoch: 2, Loss: 0.7666252851486206\n","Epoch: 2, Loss: 0.7011396884918213\n","Epoch: 2, Loss: 0.7711028456687927\n","Epoch: 2, Loss: 0.7557092308998108\n","Epoch: 2, Loss: 0.6861035227775574\n","Epoch: 2, Loss: 0.7351759672164917\n","Epoch: 2, Loss: 0.6480236649513245\n","Epoch: 2, Loss: 0.6911901235580444\n","Epoch: 2, Loss: 0.7245927453041077\n","Epoch: 2, Loss: 0.6457923054695129\n","Epoch: 2, Loss: 0.6663850545883179\n","Epoch: 2, Loss: 0.649899959564209\n","Epoch: 2, Loss: 0.6586978435516357\n","Epoch: 2, Loss: 0.6872689127922058\n","Epoch: 2, Loss: 0.6805717349052429\n","Epoch: 2, Loss: 0.6161665916442871\n","Epoch: 2, Loss: 0.7572739720344543\n","Epoch: 2, Loss: 0.64256352186203\n","Epoch: 2, Loss: 0.7269363403320312\n","Epoch: 2, Loss: 0.7885796427726746\n","Epoch: 2, Loss: 0.6600056290626526\n","Epoch: 2, Loss: 0.5737897753715515\n","Epoch: 2, Loss: 0.7252843976020813\n","Epoch: 2, Loss: 0.6843000650405884\n","Epoch: 2, Loss: 0.6741836071014404\n","Epoch: 2, Loss: 0.6850525140762329\n","Epoch: 2, Loss: 0.7736832499504089\n","Epoch: 2, Loss: 0.7307130098342896\n","Epoch: 2, Loss: 0.7353842854499817\n","Epoch: 2, Loss: 0.7039530873298645\n","Epoch: 2, Loss: 0.7225289940834045\n","Epoch: 2, Loss: 0.6799848675727844\n","Epoch: 2, Loss: 0.7288391590118408\n","Epoch: 2, Loss: 0.7539640665054321\n","Epoch: 2, Loss: 0.6847221255302429\n","Epoch: 2, Loss: 0.6744057536125183\n","Epoch: 2, Loss: 0.7198110818862915\n","Epoch: 2, Loss: 0.6248137950897217\n","Epoch: 2, Loss: 0.6919588446617126\n","Epoch: 2, Loss: 0.6455590724945068\n","Epoch: 2, Loss: 0.6908121705055237\n","Epoch: 2, Loss: 0.6588786244392395\n","Epoch: 2, Loss: 0.7453218102455139\n","Epoch: 2, Loss: 0.6736608743667603\n","Epoch: 2, Loss: 0.5695999264717102\n","Epoch: 2, Loss: 0.6924123764038086\n","Epoch: 2, Loss: 0.6672196388244629\n","Epoch: 2, Loss: 0.7262450456619263\n","Epoch: 2, Loss: 0.620029628276825\n","Epoch: 2, Loss: 0.6682577133178711\n","Epoch: 2, Loss: 0.6115073561668396\n","Epoch: 2, Loss: 0.6504580974578857\n","Epoch: 2, Loss: 0.9704174995422363\n","Epoch: 2, Loss: 0.733744204044342\n","Epoch: 2, Loss: 0.7759017944335938\n","Epoch: 2, Loss: 0.6430706977844238\n","Epoch: 2, Loss: 0.7359249591827393\n","Epoch: 2, Loss: 0.8297868371009827\n","Epoch: 2, Loss: 0.6000054478645325\n","Epoch: 2, Loss: 0.7460334300994873\n","Epoch: 2, Loss: 0.7130862474441528\n","Epoch: 2, Loss: 0.7594504952430725\n","Epoch: 2, Loss: 0.6483187675476074\n","Epoch: 2, Loss: 0.6627305150032043\n","Epoch: 2, Loss: 0.6918211579322815\n","Epoch: 2, Loss: 0.709942102432251\n","Epoch: 2, Loss: 0.6596804261207581\n","Epoch: 2, Loss: 0.6872836947441101\n","Epoch: 2, Loss: 0.6936137080192566\n","Epoch: 2, Loss: 0.6835020780563354\n","Epoch: 2, Loss: 0.6304492354393005\n","Epoch: 2, Loss: 0.6221771240234375\n","Epoch: 2, Loss: 0.7604848742485046\n","Epoch: 2, Loss: 0.7390865087509155\n","Epoch: 2, Loss: 0.6417827606201172\n","Epoch: 2, Loss: 0.7010294198989868\n","Epoch: 2, Loss: 0.7368232607841492\n","Epoch: 2, Loss: 0.7700039148330688\n","Epoch: 2, Loss: 0.7034292817115784\n","Epoch: 2, Loss: 0.6884505748748779\n","Epoch: 2, Loss: 0.7200349569320679\n","Epoch: 2, Loss: 0.7568431496620178\n","Epoch: 2, Loss: 0.7331200838088989\n","Epoch: 2, Loss: 0.7091693878173828\n","Epoch: 2, Loss: 0.6788989305496216\n","Epoch: 2, Loss: 0.7271670699119568\n","Epoch: 2, Loss: 0.6738172769546509\n","Epoch: 2, Loss: 0.6775779128074646\n","Epoch: 2, Loss: 0.6567081809043884\n","Epoch: 2, Loss: 0.7730709314346313\n","Epoch: 2, Loss: 0.6929070353507996\n","Epoch: 2, Loss: 0.7941733598709106\n","Epoch: 2, Loss: 0.7213229537010193\n","Epoch: 2, Loss: 0.656792402267456\n","Epoch: 2, Loss: 0.7204290628433228\n","Epoch: 2, Loss: 0.6932424902915955\n","Epoch: 2, Loss: 0.6579186320304871\n","Epoch: 2, Loss: 0.7808938026428223\n","Epoch: 2, Loss: 0.675609827041626\n","Epoch: 2, Loss: 0.6904368996620178\n","Epoch: 2, Loss: 0.6516703367233276\n","Epoch: 2, Loss: 0.6675171852111816\n","Epoch: 2, Loss: 0.6907190084457397\n","Epoch: 2, Loss: 0.7120236158370972\n","Epoch: 2, Loss: 0.663594663143158\n","Epoch: 2, Loss: 0.6834839582443237\n","Epoch: 2, Loss: 0.656242311000824\n","Epoch: 2, Loss: 0.7172824740409851\n","Epoch: 2, Loss: 0.6952860355377197\n","Epoch: 2, Loss: 0.6871949434280396\n","Epoch: 2, Loss: 0.698043942451477\n","Epoch: 2, Loss: 0.6699731349945068\n","Epoch: 2, Loss: 0.6051990389823914\n","Epoch: 2, Loss: 0.6412152647972107\n","Epoch: 2, Loss: 0.6436940431594849\n","Epoch: 2, Loss: 0.7083522081375122\n","Epoch: 2, Loss: 0.7197790145874023\n","Epoch: 2, Loss: 0.6602983474731445\n","Epoch: 2, Loss: 0.5989172458648682\n","Epoch: 2, Loss: 0.7548514008522034\n","Epoch: 2, Loss: 0.7021560668945312\n","Epoch: 2, Loss: 0.7115103006362915\n","Epoch: 2, Loss: 0.8430085182189941\n","Epoch: 2, Loss: 0.7580408453941345\n","Epoch: 2, Loss: 0.6906930208206177\n","Epoch: 2, Loss: 0.6460570096969604\n","Epoch: 2, Loss: 0.5819625854492188\n","Epoch: 2, Loss: 0.688434362411499\n","Epoch: 2, Loss: 0.7284194231033325\n","Epoch: 2, Loss: 0.6625128984451294\n","Epoch: 2, Loss: 0.7581906914710999\n","Epoch: 2, Loss: 0.7329387068748474\n","Epoch: 2, Loss: 0.6525741815567017\n","Epoch: 2, Loss: 0.7662832736968994\n","Epoch: 2, Loss: 0.6957001686096191\n","Epoch: 2, Loss: 0.6996094584465027\n","Epoch: 2, Loss: 0.6842116117477417\n","Epoch: 2, Loss: 0.6400883793830872\n","Epoch: 2, Loss: 0.6852254867553711\n","Epoch: 2, Loss: 0.7542835474014282\n","Epoch: 2, Loss: 0.7688347101211548\n","Epoch: 2, Loss: 0.6649429202079773\n","Epoch: 2, Loss: 0.7281802296638489\n","Epoch: 2, Loss: 0.7085717916488647\n","Epoch: 2, Loss: 0.644712507724762\n","Epoch: 2, Loss: 0.7081190347671509\n","Epoch: 2, Loss: 0.6931695938110352\n","Epoch: 2, Loss: 0.6911786794662476\n","Epoch: 2, Loss: 0.6583827137947083\n","Epoch: 2, Loss: 0.735209584236145\n","Epoch: 2, Loss: 0.663788914680481\n","Epoch: 2, Loss: 0.6988625526428223\n","Epoch: 2, Loss: 0.6794895529747009\n","Epoch: 2, Loss: 0.7047217488288879\n","Epoch: 2, Loss: 0.6657539010047913\n","Epoch: 2, Loss: 0.7412438988685608\n","Epoch: 2, Loss: 0.6558980941772461\n","Epoch: 2, Loss: 0.8252106308937073\n","Epoch: 2, Loss: 0.7014280557632446\n","Epoch: 2, Loss: 0.6940717697143555\n","Epoch: 2, Loss: 0.7124211192131042\n","Epoch: 2, Loss: 0.6824522018432617\n","Epoch: 2, Loss: 0.7316731214523315\n","Epoch: 2, Loss: 0.7268994450569153\n","Epoch: 2, Loss: 0.7244889736175537\n","Epoch: 2, Loss: 0.7770941257476807\n","Epoch: 2, Loss: 0.7551811337471008\n","Epoch: 2, Loss: 0.6730195879936218\n","Epoch: 2, Loss: 0.721979022026062\n","Epoch: 2, Loss: 0.6762387752532959\n","Epoch: 2, Loss: 0.6429161429405212\n","Epoch: 2, Loss: 0.6295796632766724\n","Epoch: 2, Loss: 0.7364692687988281\n","Epoch: 2, Loss: 0.6206436157226562\n","Epoch: 2, Loss: 0.7269257307052612\n","Epoch: 2, Loss: 0.7550750970840454\n","Epoch: 2, Loss: 0.7448532581329346\n","Epoch: 2, Loss: 0.7239823937416077\n","Epoch: 2, Loss: 0.7069522142410278\n","Epoch: 2, Loss: 0.7513726949691772\n","Epoch: 2, Loss: 0.7089006900787354\n","Epoch: 2, Loss: 0.6911776065826416\n","Epoch: 2, Loss: 0.6536275744438171\n","Epoch: 2, Loss: 0.681671679019928\n","Epoch: 2, Loss: 0.7073493599891663\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss: 0.7412422895431519\n","Epoch: 0, Loss: 0.9102133512496948\n","Epoch: 0, Loss: 0.6389440894126892\n","Epoch: 0, Loss: 0.6849325895309448\n","Epoch: 0, Loss: 0.7703819274902344\n","Epoch: 0, Loss: 0.7393357753753662\n","Epoch: 0, Loss: 0.7198930978775024\n","Epoch: 0, Loss: 0.71733158826828\n","Epoch: 0, Loss: 0.7702065110206604\n","Epoch: 0, Loss: 0.7557789087295532\n","Epoch: 0, Loss: 0.7466634511947632\n","Epoch: 0, Loss: 0.6430736184120178\n","Epoch: 0, Loss: 0.751858115196228\n","Epoch: 0, Loss: 0.7444820404052734\n","Epoch: 0, Loss: 0.7069908976554871\n","Epoch: 0, Loss: 0.7426291704177856\n","Epoch: 0, Loss: 0.6321664452552795\n","Epoch: 0, Loss: 0.6869156956672668\n","Epoch: 0, Loss: 0.7027770280838013\n","Epoch: 0, Loss: 0.6982196569442749\n","Epoch: 0, Loss: 0.593335747718811\n","Epoch: 0, Loss: 0.8333384394645691\n","Epoch: 0, Loss: 0.6891831755638123\n","Epoch: 0, Loss: 0.6389833688735962\n","Epoch: 0, Loss: 0.5162726044654846\n","Epoch: 0, Loss: 0.6661826968193054\n","Epoch: 0, Loss: 0.7197288870811462\n","Epoch: 0, Loss: 0.6603603363037109\n","Epoch: 0, Loss: 0.6224690675735474\n","Epoch: 0, Loss: 0.8051832914352417\n","Epoch: 0, Loss: 0.7103873491287231\n","Epoch: 0, Loss: 0.7037568688392639\n","Epoch: 0, Loss: 0.7393798232078552\n","Epoch: 0, Loss: 0.7941706776618958\n","Epoch: 0, Loss: 0.7260154485702515\n","Epoch: 0, Loss: 0.6708284020423889\n","Epoch: 0, Loss: 0.7282711267471313\n","Epoch: 0, Loss: 0.6894571781158447\n","Epoch: 0, Loss: 0.8502174019813538\n","Epoch: 0, Loss: 0.7853175401687622\n","Epoch: 0, Loss: 0.8127940893173218\n","Epoch: 0, Loss: 0.715045690536499\n","Epoch: 0, Loss: 0.7318617701530457\n","Epoch: 0, Loss: 0.6612417697906494\n","Epoch: 0, Loss: 0.7151986360549927\n","Epoch: 0, Loss: 0.7659825086593628\n","Epoch: 0, Loss: 0.7206407189369202\n","Epoch: 0, Loss: 0.723135769367218\n","Epoch: 0, Loss: 0.6919800043106079\n","Epoch: 0, Loss: 0.6873154640197754\n","Epoch: 0, Loss: 0.705906331539154\n","Epoch: 0, Loss: 0.7012967467308044\n","Epoch: 0, Loss: 0.7423465251922607\n","Epoch: 0, Loss: 0.702168881893158\n","Epoch: 0, Loss: 0.7500438094139099\n","Epoch: 0, Loss: 0.7515341639518738\n","Epoch: 0, Loss: 0.7041400074958801\n","Epoch: 0, Loss: 0.6544305086135864\n","Epoch: 0, Loss: 0.6548570394515991\n","Epoch: 0, Loss: 0.7737326622009277\n","Epoch: 0, Loss: 0.6961377859115601\n","Epoch: 0, Loss: 0.6486088037490845\n","Epoch: 0, Loss: 0.6896864771842957\n","Epoch: 0, Loss: 0.7064521312713623\n","Epoch: 0, Loss: 0.6440331339836121\n","Epoch: 0, Loss: 0.7446104884147644\n","Epoch: 0, Loss: 0.6901562213897705\n","Epoch: 0, Loss: 0.7211524844169617\n","Epoch: 0, Loss: 0.6766663789749146\n","Epoch: 0, Loss: 0.7017248868942261\n","Epoch: 0, Loss: 0.6160708665847778\n","Epoch: 0, Loss: 0.671396017074585\n","Epoch: 0, Loss: 0.6940714716911316\n","Epoch: 0, Loss: 0.7084770798683167\n","Epoch: 0, Loss: 0.6033295392990112\n","Epoch: 0, Loss: 0.7087973356246948\n","Epoch: 0, Loss: 0.7590031027793884\n","Epoch: 0, Loss: 0.6858147382736206\n","Epoch: 0, Loss: 0.6949264407157898\n","Epoch: 0, Loss: 0.7239305377006531\n","Epoch: 0, Loss: 0.7462093234062195\n","Epoch: 0, Loss: 0.7214522361755371\n","Epoch: 0, Loss: 0.7674381732940674\n","Epoch: 0, Loss: 0.8047416806221008\n","Epoch: 0, Loss: 0.6243137121200562\n","Epoch: 0, Loss: 0.6427344083786011\n","Epoch: 0, Loss: 0.656384289264679\n","Epoch: 0, Loss: 0.7150546312332153\n","Epoch: 0, Loss: 0.7036266922950745\n","Epoch: 0, Loss: 0.8025283217430115\n","Epoch: 0, Loss: 0.6899616122245789\n","Epoch: 0, Loss: 0.7166889309883118\n","Epoch: 0, Loss: 0.7424377202987671\n","Epoch: 0, Loss: 0.7586444616317749\n","Epoch: 0, Loss: 0.6937555074691772\n","Epoch: 0, Loss: 0.606484591960907\n","Epoch: 0, Loss: 0.7405213117599487\n","Epoch: 0, Loss: 0.6872956156730652\n","Epoch: 0, Loss: 0.7562959790229797\n","Epoch: 0, Loss: 0.7829517722129822\n","Epoch: 0, Loss: 0.7651198506355286\n","Epoch: 0, Loss: 0.7065090537071228\n","Epoch: 0, Loss: 0.769188404083252\n","Epoch: 0, Loss: 0.7208956480026245\n","Epoch: 0, Loss: 0.7501583695411682\n","Epoch: 0, Loss: 0.5942283272743225\n","Epoch: 0, Loss: 0.7240138649940491\n","Epoch: 0, Loss: 0.8153842687606812\n","Epoch: 0, Loss: 0.6098438501358032\n","Epoch: 0, Loss: 0.6942152976989746\n","Epoch: 0, Loss: 0.6047408580780029\n","Epoch: 0, Loss: 0.7210348844528198\n","Epoch: 0, Loss: 0.773061990737915\n","Epoch: 0, Loss: 0.6316976547241211\n","Epoch: 0, Loss: 0.7401260137557983\n","Epoch: 0, Loss: 0.7847857475280762\n","Epoch: 0, Loss: 0.6686776280403137\n","Epoch: 0, Loss: 0.7256806492805481\n","Epoch: 0, Loss: 0.6213220357894897\n","Epoch: 0, Loss: 0.7280060648918152\n","Epoch: 0, Loss: 0.7012710571289062\n","Epoch: 0, Loss: 0.7424576878547668\n","Epoch: 0, Loss: 0.6565042734146118\n","Epoch: 0, Loss: 0.7369018793106079\n","Epoch: 0, Loss: 0.6363421678543091\n","Epoch: 0, Loss: 0.7485566139221191\n","Epoch: 0, Loss: 0.6913779377937317\n","Epoch: 0, Loss: 0.7639414668083191\n","Epoch: 0, Loss: 0.6669290661811829\n","Epoch: 0, Loss: 0.7085150480270386\n","Epoch: 0, Loss: 0.7490813732147217\n","Epoch: 0, Loss: 0.7133239507675171\n","Epoch: 0, Loss: 0.7002121210098267\n","Epoch: 0, Loss: 0.6549041271209717\n","Epoch: 0, Loss: 0.7731053829193115\n","Epoch: 0, Loss: 0.6940799355506897\n","Epoch: 0, Loss: 0.6614148616790771\n","Epoch: 0, Loss: 0.6346412301063538\n","Epoch: 0, Loss: 0.7195026874542236\n","Epoch: 0, Loss: 0.6953201293945312\n","Epoch: 0, Loss: 0.6801708340644836\n","Epoch: 0, Loss: 0.589320719242096\n","Epoch: 0, Loss: 0.763292670249939\n","Epoch: 0, Loss: 0.6509553790092468\n","Epoch: 0, Loss: 0.7522055506706238\n","Epoch: 0, Loss: 0.5758078694343567\n","Epoch: 0, Loss: 0.6844019293785095\n","Epoch: 0, Loss: 0.7141723036766052\n","Epoch: 0, Loss: 0.6391386389732361\n","Epoch: 0, Loss: 0.7673733234405518\n","Epoch: 0, Loss: 0.7342903017997742\n","Epoch: 0, Loss: 0.7052710056304932\n","Epoch: 0, Loss: 0.6540190577507019\n","Epoch: 0, Loss: 0.7101873755455017\n","Epoch: 0, Loss: 0.7224860191345215\n","Epoch: 0, Loss: 0.7459681630134583\n","Epoch: 0, Loss: 0.6466743350028992\n","Epoch: 0, Loss: 0.7698549628257751\n","Epoch: 0, Loss: 0.657494843006134\n","Epoch: 0, Loss: 0.7131984829902649\n","Epoch: 0, Loss: 0.6692802309989929\n","Epoch: 0, Loss: 0.6317631006240845\n","Epoch: 0, Loss: 0.7394118905067444\n","Epoch: 0, Loss: 0.6384545564651489\n","Epoch: 0, Loss: 0.7199826240539551\n","Epoch: 0, Loss: 0.727393627166748\n","Epoch: 0, Loss: 0.6485131978988647\n","Epoch: 0, Loss: 0.6076382994651794\n","Epoch: 0, Loss: 0.5819337964057922\n","Epoch: 0, Loss: 0.7638389468193054\n","Epoch: 0, Loss: 0.727256178855896\n","Epoch: 0, Loss: 0.6685823798179626\n","Epoch: 0, Loss: 0.7382599115371704\n","Epoch: 0, Loss: 0.6610609889030457\n","Epoch: 0, Loss: 0.6917988657951355\n","Epoch: 0, Loss: 0.6496928334236145\n","Epoch: 0, Loss: 0.6623270511627197\n","Epoch: 0, Loss: 0.6755059957504272\n","Epoch: 0, Loss: 0.7637167572975159\n","Epoch: 0, Loss: 0.8752785325050354\n","Epoch: 0, Loss: 0.815435528755188\n","Epoch: 0, Loss: 0.6654745936393738\n","Epoch: 0, Loss: 0.6489363312721252\n","Epoch: 0, Loss: 0.5486576557159424\n","Epoch: 0, Loss: 0.8395760655403137\n","Epoch: 0, Loss: 0.5982361435890198\n","Epoch: 0, Loss: 0.7332503795623779\n","Epoch: 0, Loss: 0.7832671403884888\n","Epoch: 0, Loss: 0.7732827663421631\n","Epoch: 0, Loss: 0.8331788182258606\n","Epoch: 0, Loss: 0.6626766920089722\n","Epoch: 0, Loss: 0.850562334060669\n","Epoch: 0, Loss: 0.6567146182060242\n","Epoch: 0, Loss: 0.6755934953689575\n","Epoch: 0, Loss: 0.6305554509162903\n","Epoch: 0, Loss: 0.6325221657752991\n","Epoch: 0, Loss: 0.633421778678894\n","Epoch: 0, Loss: 0.6881541013717651\n","Epoch: 0, Loss: 0.6772131323814392\n","Epoch: 0, Loss: 0.7708407044410706\n","Epoch: 0, Loss: 0.6577048301696777\n","Epoch: 0, Loss: 0.6131651401519775\n","Epoch: 0, Loss: 0.7243444919586182\n","Epoch: 0, Loss: 0.7497414946556091\n","Epoch: 0, Loss: 0.639208197593689\n","Epoch: 0, Loss: 0.637764573097229\n","Epoch: 0, Loss: 0.6384962797164917\n","Epoch: 0, Loss: 0.8247441649436951\n","Epoch: 0, Loss: 0.7215409874916077\n","Epoch: 0, Loss: 0.7415629625320435\n","Epoch: 0, Loss: 0.6857761740684509\n","Epoch: 0, Loss: 0.6391472816467285\n","Epoch: 0, Loss: 0.7334944009780884\n","Epoch: 0, Loss: 0.7432136535644531\n","Epoch: 0, Loss: 0.6790672540664673\n","Epoch: 0, Loss: 0.6901121735572815\n","Epoch: 0, Loss: 0.7443728446960449\n","Epoch: 0, Loss: 0.6973716020584106\n","Epoch: 0, Loss: 0.7329636812210083\n","Epoch: 0, Loss: 0.6485130190849304\n","Epoch: 0, Loss: 0.7331623435020447\n","Epoch: 0, Loss: 0.7117706537246704\n","Epoch: 0, Loss: 0.7424284815788269\n","Epoch: 0, Loss: 0.6483883261680603\n","Epoch: 0, Loss: 0.7596438527107239\n","Epoch: 0, Loss: 0.7363084554672241\n","Epoch: 0, Loss: 0.6604802012443542\n","Epoch: 0, Loss: 0.7206471562385559\n","Epoch: 0, Loss: 0.708362340927124\n","Epoch: 0, Loss: 0.6366555690765381\n","Epoch: 0, Loss: 0.6923075914382935\n","Epoch: 0, Loss: 0.6519798040390015\n","Epoch: 0, Loss: 0.7219422459602356\n","Epoch: 0, Loss: 0.7065946459770203\n","Epoch: 0, Loss: 0.7113553881645203\n","Epoch: 0, Loss: 0.7890045642852783\n","Epoch: 0, Loss: 0.6922496557235718\n","Epoch: 0, Loss: 0.7063475847244263\n","Epoch: 0, Loss: 0.7040327787399292\n","Epoch: 0, Loss: 0.6379721164703369\n","Epoch: 0, Loss: 0.736143946647644\n","Epoch: 0, Loss: 0.6592496633529663\n","Epoch: 0, Loss: 0.6992614269256592\n","Epoch: 0, Loss: 0.7245180606842041\n","Epoch: 0, Loss: 0.7357394695281982\n","Epoch: 0, Loss: 0.7701418995857239\n","Epoch: 0, Loss: 0.7358323335647583\n","Epoch: 0, Loss: 0.6929556131362915\n","Epoch: 0, Loss: 0.7329676151275635\n","Epoch: 0, Loss: 0.7291966676712036\n","Epoch: 0, Loss: 0.6880680322647095\n","Epoch: 0, Loss: 0.6303675770759583\n","Epoch: 0, Loss: 0.6437408328056335\n","Epoch: 0, Loss: 0.6824712753295898\n","Epoch: 0, Loss: 0.6680066585540771\n","Epoch: 0, Loss: 0.7791696190834045\n","Epoch: 0, Loss: 0.8365455865859985\n","Epoch: 0, Loss: 0.6846175193786621\n","Epoch: 0, Loss: 0.6341346502304077\n","Epoch: 0, Loss: 0.8843150734901428\n","Epoch: 0, Loss: 0.6815181374549866\n","Epoch: 0, Loss: 0.7674643993377686\n","Epoch: 0, Loss: 0.7394962310791016\n","Epoch: 0, Loss: 0.7030035257339478\n","Epoch: 0, Loss: 0.68595290184021\n","Epoch: 0, Loss: 0.6897390484809875\n","Epoch: 0, Loss: 0.7386852502822876\n","Epoch: 0, Loss: 0.6440474987030029\n","Epoch: 0, Loss: 0.5941137075424194\n","Epoch: 0, Loss: 0.6416140198707581\n","Epoch: 0, Loss: 0.6914187073707581\n","Epoch: 0, Loss: 0.7361968755722046\n","Epoch: 0, Loss: 0.8299106955528259\n","Epoch: 0, Loss: 0.6713016629219055\n","Epoch: 0, Loss: 0.6966074109077454\n","Epoch: 0, Loss: 0.6731432676315308\n","Epoch: 0, Loss: 0.7669156789779663\n","Epoch: 0, Loss: 0.7292423844337463\n","Epoch: 0, Loss: 0.7106941938400269\n","Epoch: 0, Loss: 0.7080922722816467\n","Epoch: 0, Loss: 0.6485280990600586\n","Epoch: 0, Loss: 0.6663671731948853\n","Epoch: 0, Loss: 0.6820270419120789\n","Epoch: 0, Loss: 0.7211408615112305\n","Epoch: 0, Loss: 0.6750817894935608\n","Epoch: 0, Loss: 0.6836594343185425\n","Epoch: 0, Loss: 0.7044554948806763\n","Epoch: 0, Loss: 0.7611377835273743\n","Epoch: 0, Loss: 0.7904672622680664\n","Epoch: 0, Loss: 0.7207028865814209\n","Epoch: 0, Loss: 0.7575029730796814\n","Epoch: 0, Loss: 0.7320848703384399\n","Epoch: 0, Loss: 0.6822149157524109\n","Epoch: 0, Loss: 0.6885274052619934\n","Epoch: 0, Loss: 0.7072668075561523\n","Epoch: 0, Loss: 0.7256485223770142\n","Epoch: 0, Loss: 0.7548232078552246\n","Epoch: 0, Loss: 0.6505925059318542\n","Epoch: 0, Loss: 0.6106448173522949\n","Epoch: 0, Loss: 0.6934603452682495\n","Epoch: 0, Loss: 0.6817163228988647\n","Epoch: 0, Loss: 0.645270586013794\n","Epoch: 0, Loss: 0.6531299948692322\n","Epoch: 0, Loss: 0.7680824995040894\n","Epoch: 0, Loss: 0.7008959054946899\n","Epoch: 0, Loss: 0.6566891670227051\n","Epoch: 0, Loss: 0.7460673451423645\n","Epoch: 0, Loss: 0.7525378465652466\n","Epoch: 0, Loss: 0.7132591009140015\n","Epoch: 0, Loss: 0.6947065591812134\n","Epoch: 0, Loss: 0.6110218167304993\n","Epoch: 0, Loss: 0.718047022819519\n","Epoch: 0, Loss: 0.7066709995269775\n","Epoch: 0, Loss: 0.6373577117919922\n","Epoch: 0, Loss: 0.681460440158844\n","Epoch: 0, Loss: 0.8569976091384888\n","Epoch: 0, Loss: 0.5945338010787964\n","Epoch: 0, Loss: 0.6314889192581177\n","Epoch: 0, Loss: 0.7755218744277954\n","Epoch: 0, Loss: 0.6690958738327026\n","Epoch: 0, Loss: 0.7470386028289795\n","Epoch: 0, Loss: 0.7412718534469604\n","Epoch: 0, Loss: 0.689613401889801\n","Epoch: 0, Loss: 0.6118065714836121\n","Epoch: 0, Loss: 0.6611306071281433\n","Epoch: 0, Loss: 0.6533784866333008\n","Epoch: 0, Loss: 0.7369529008865356\n","Epoch: 0, Loss: 0.752001166343689\n","Epoch: 0, Loss: 0.6755385994911194\n","Epoch: 0, Loss: 0.5902923345565796\n","Epoch: 0, Loss: 0.7104318737983704\n","Epoch: 0, Loss: 0.7138234376907349\n","Epoch: 0, Loss: 0.7416796684265137\n","Epoch: 0, Loss: 0.6936164498329163\n","Epoch: 0, Loss: 0.6988934278488159\n","Epoch: 0, Loss: 0.6739449501037598\n","Epoch: 0, Loss: 0.7124408483505249\n","Epoch: 0, Loss: 0.7210735082626343\n","Epoch: 0, Loss: 0.6874890923500061\n","Epoch: 0, Loss: 0.7231297492980957\n","Epoch: 0, Loss: 0.7716476321220398\n","Epoch: 0, Loss: 0.7499947547912598\n","Epoch: 0, Loss: 0.7229565978050232\n","Epoch: 0, Loss: 0.7140305042266846\n","Epoch: 0, Loss: 0.7444677352905273\n","Epoch: 0, Loss: 0.6228466033935547\n","Epoch: 0, Loss: 0.6221917867660522\n","Epoch: 0, Loss: 0.7194913029670715\n","Epoch: 0, Loss: 0.7008686065673828\n","Epoch: 0, Loss: 0.7252317667007446\n","Epoch: 0, Loss: 0.7763171195983887\n","Epoch: 0, Loss: 0.5480947494506836\n","Epoch: 0, Loss: 0.7131018042564392\n","Epoch: 0, Loss: 0.8166540861129761\n","Epoch: 0, Loss: 0.7270574569702148\n","Epoch: 0, Loss: 0.8108611106872559\n","Epoch: 0, Loss: 0.7835455536842346\n","Epoch: 0, Loss: 0.6954008340835571\n","Epoch: 0, Loss: 0.7844511866569519\n","Epoch: 0, Loss: 0.757714033126831\n","Epoch: 0, Loss: 0.6546025276184082\n","Epoch: 0, Loss: 0.7582760453224182\n","Epoch: 0, Loss: 0.7402796745300293\n","Epoch: 0, Loss: 0.7519294023513794\n","Epoch: 0, Loss: 0.6656420826911926\n","Epoch: 0, Loss: 0.708315372467041\n","Epoch: 0, Loss: 0.728553831577301\n","Epoch: 0, Loss: 0.6535195112228394\n","Epoch: 0, Loss: 0.6812515258789062\n","Epoch: 0, Loss: 0.6914361119270325\n","Epoch: 0, Loss: 0.6880891919136047\n","Epoch: 0, Loss: 0.6879016160964966\n","Epoch: 0, Loss: 0.6795979738235474\n","Epoch: 0, Loss: 0.7307705283164978\n","Epoch: 0, Loss: 0.6603797078132629\n","Epoch: 0, Loss: 0.7884508371353149\n","Epoch: 0, Loss: 0.6760939359664917\n","Epoch: 0, Loss: 0.6836156845092773\n","Epoch: 0, Loss: 0.7096709609031677\n","Epoch: 0, Loss: 0.7445740103721619\n","Epoch: 0, Loss: 0.770033597946167\n","Epoch: 0, Loss: 0.802951455116272\n","Epoch: 0, Loss: 0.7434731721878052\n","Epoch: 0, Loss: 0.6423832774162292\n","Epoch: 0, Loss: 0.6943506002426147\n","Epoch: 0, Loss: 0.6477581262588501\n","Epoch: 0, Loss: 0.7920291423797607\n","Epoch: 0, Loss: 0.7170705795288086\n","Epoch: 0, Loss: 0.6638618111610413\n","Epoch: 0, Loss: 0.725806474685669\n","Epoch: 0, Loss: 0.6566829085350037\n","Epoch: 0, Loss: 0.7507228851318359\n","Epoch: 0, Loss: 0.7289183735847473\n","Epoch: 0, Loss: 0.7352911233901978\n","Epoch: 0, Loss: 0.7507344484329224\n","Epoch: 0, Loss: 0.683610737323761\n","Epoch: 0, Loss: 0.6641930341720581\n","Epoch: 0, Loss: 0.7100220918655396\n","Epoch: 0, Loss: 0.66877681016922\n","Epoch: 0, Loss: 0.671628475189209\n","Epoch: 0, Loss: 0.65818190574646\n","Epoch: 0, Loss: 0.764358401298523\n","Epoch: 0, Loss: 0.6517527103424072\n","Epoch: 0, Loss: 0.7161740660667419\n","Epoch: 0, Loss: 0.6648527383804321\n","Epoch: 0, Loss: 0.7899494171142578\n","Epoch: 0, Loss: 0.7440713047981262\n","Epoch: 0, Loss: 0.7926650643348694\n","Epoch: 0, Loss: 0.6395848989486694\n","Epoch: 0, Loss: 0.7009859085083008\n","Epoch: 0, Loss: 0.686833381652832\n","Epoch: 0, Loss: 0.7298769950866699\n","Epoch: 0, Loss: 0.6942110061645508\n","Epoch: 0, Loss: 0.7009631991386414\n","Epoch: 0, Loss: 0.674221932888031\n","Epoch: 0, Loss: 0.7373635172843933\n","Epoch: 0, Loss: 0.6931403875350952\n","Epoch: 0, Loss: 0.6695225834846497\n","Epoch: 0, Loss: 0.7153263092041016\n","Epoch: 0, Loss: 0.6620328426361084\n","Epoch: 0, Loss: 0.701004147529602\n","Epoch: 0, Loss: 0.7203667759895325\n","Epoch: 0, Loss: 0.7085909247398376\n","Epoch: 0, Loss: 0.6927899122238159\n","Epoch: 0, Loss: 0.7584760189056396\n","Epoch: 0, Loss: 0.6526131629943848\n","Epoch: 0, Loss: 0.6903079152107239\n","Epoch: 0, Loss: 0.6438935995101929\n","Epoch: 0, Loss: 0.6795694828033447\n","Epoch: 0, Loss: 0.6879453659057617\n","Epoch: 0, Loss: 0.6865244507789612\n","Epoch: 0, Loss: 0.7175948023796082\n","Epoch: 0, Loss: 0.6765741109848022\n","Epoch: 0, Loss: 0.6763114929199219\n","Epoch: 0, Loss: 0.7406293749809265\n","Epoch: 0, Loss: 0.6883344650268555\n","Epoch: 0, Loss: 0.7752848863601685\n","Epoch: 0, Loss: 0.6462664008140564\n","Epoch: 0, Loss: 0.809146523475647\n","Epoch: 0, Loss: 0.7508314847946167\n","Epoch: 0, Loss: 0.7085638642311096\n","Epoch: 0, Loss: 0.6991824507713318\n","Epoch: 0, Loss: 0.6690132021903992\n","Epoch: 0, Loss: 0.7656902074813843\n","Epoch: 0, Loss: 0.6611388325691223\n","Epoch: 0, Loss: 0.7292277216911316\n","Epoch: 0, Loss: 0.8001924753189087\n","Epoch: 0, Loss: 0.8132273554801941\n","Epoch: 0, Loss: 0.7716206908226013\n","Epoch: 0, Loss: 0.8188703656196594\n","Epoch: 0, Loss: 0.6696503162384033\n","Epoch: 0, Loss: 0.6854486465454102\n","Epoch: 0, Loss: 0.7289785146713257\n","Epoch: 0, Loss: 0.6349753737449646\n","Epoch: 0, Loss: 0.7322554588317871\n","Epoch: 0, Loss: 0.671712338924408\n","Epoch: 0, Loss: 0.7262439727783203\n","Epoch: 0, Loss: 0.7374070286750793\n","Epoch: 0, Loss: 0.7210916876792908\n","Epoch: 0, Loss: 0.6469720602035522\n","Epoch: 0, Loss: 0.7234224081039429\n","Epoch: 0, Loss: 0.7419129014015198\n","Epoch: 0, Loss: 0.7022168040275574\n","Epoch: 0, Loss: 0.6799613237380981\n","Epoch: 0, Loss: 0.6777816414833069\n","Epoch: 0, Loss: 0.6765891909599304\n","Epoch: 0, Loss: 0.746517539024353\n","Epoch: 0, Loss: 0.6890660524368286\n","Epoch: 0, Loss: 0.695164680480957\n","Epoch: 0, Loss: 0.7166383862495422\n","Epoch: 0, Loss: 0.8121053576469421\n","Epoch: 0, Loss: 0.7101188898086548\n","Epoch: 0, Loss: 0.6299660801887512\n","Epoch: 0, Loss: 0.7665491700172424\n","Epoch: 0, Loss: 0.707008957862854\n","Epoch: 0, Loss: 0.6459447741508484\n","Epoch: 0, Loss: 0.6711330413818359\n","Epoch: 0, Loss: 0.7658286094665527\n","Epoch: 0, Loss: 0.6363300681114197\n","Epoch: 0, Loss: 0.6278706789016724\n","Epoch: 0, Loss: 0.6912362575531006\n","Epoch: 0, Loss: 0.7746613025665283\n","Epoch: 0, Loss: 0.6996501088142395\n","Epoch: 0, Loss: 0.6633344292640686\n","Epoch: 0, Loss: 0.7176815271377563\n","Epoch: 0, Loss: 0.7091087698936462\n","Epoch: 0, Loss: 0.6160531044006348\n","Epoch: 0, Loss: 0.6942340135574341\n","Epoch: 0, Loss: 0.7439863085746765\n","Epoch: 0, Loss: 0.7113340497016907\n","Epoch: 0, Loss: 0.7744331359863281\n","Epoch: 0, Loss: 0.7072229981422424\n","Epoch: 0, Loss: 0.6774911880493164\n","Epoch: 0, Loss: 0.6173144578933716\n","Epoch: 0, Loss: 0.7383503913879395\n","Epoch: 0, Loss: 0.706371545791626\n","Epoch: 0, Loss: 0.7334804534912109\n","Epoch: 0, Loss: 0.6453487277030945\n","Epoch: 0, Loss: 0.7514834403991699\n","Epoch: 0, Loss: 0.6680190563201904\n","Epoch: 0, Loss: 0.6584898233413696\n","Epoch: 0, Loss: 0.6547240018844604\n","Epoch: 0, Loss: 0.7695754766464233\n","Epoch: 0, Loss: 0.7967672944068909\n","Epoch: 0, Loss: 0.7330759763717651\n","Epoch: 0, Loss: 0.7587875723838806\n","Epoch: 0, Loss: 0.7350726127624512\n","Epoch: 0, Loss: 0.706243097782135\n","Epoch: 0, Loss: 0.7120379209518433\n","Epoch: 0, Loss: 0.717284083366394\n","Epoch: 0, Loss: 0.6103070974349976\n","Epoch: 0, Loss: 0.7394290566444397\n","Epoch: 0, Loss: 0.6617463231086731\n","Epoch: 0, Loss: 0.7328826189041138\n","Epoch: 0, Loss: 0.707672655582428\n","Epoch: 0, Loss: 0.7513900995254517\n","Epoch: 0, Loss: 0.6929872632026672\n","Epoch: 0, Loss: 0.7190576195716858\n","Epoch: 0, Loss: 0.7615459561347961\n","Epoch: 0, Loss: 0.6626067161560059\n","Epoch: 0, Loss: 0.722151517868042\n","Epoch: 0, Loss: 0.6212059259414673\n","Epoch: 0, Loss: 0.7273178100585938\n","Epoch: 0, Loss: 0.7484743595123291\n","Epoch: 0, Loss: 0.7183935642242432\n","Epoch: 0, Loss: 0.7565581202507019\n","Epoch: 0, Loss: 0.7380139231681824\n","Epoch: 0, Loss: 0.7285419702529907\n","Epoch: 0, Loss: 0.7477585673332214\n","Epoch: 0, Loss: 0.7077586054801941\n","Epoch: 0, Loss: 0.6777077317237854\n","Epoch: 0, Loss: 0.6449068784713745\n","Epoch: 0, Loss: 0.8141776323318481\n","Epoch: 0, Loss: 0.6714997887611389\n","Epoch: 0, Loss: 0.6908538341522217\n","Epoch: 0, Loss: 0.6784350872039795\n","Epoch: 0, Loss: 0.6511086225509644\n","Epoch: 0, Loss: 0.7642114758491516\n","Epoch: 0, Loss: 0.7551316618919373\n","Epoch: 0, Loss: 0.6400083303451538\n","Epoch: 0, Loss: 0.7193928956985474\n","Epoch: 0, Loss: 0.6594905257225037\n","Epoch: 0, Loss: 0.7803472280502319\n","Epoch: 0, Loss: 0.7782471179962158\n","Epoch: 0, Loss: 0.6554413437843323\n","Epoch: 0, Loss: 0.6951494812965393\n","Epoch: 0, Loss: 0.7043980956077576\n","Epoch: 0, Loss: 0.6757892370223999\n","Epoch: 0, Loss: 0.7351069450378418\n","Epoch: 0, Loss: 0.6408803462982178\n","Epoch: 0, Loss: 0.7389709949493408\n","Epoch: 0, Loss: 0.7172354459762573\n","Epoch: 0, Loss: 0.6412147283554077\n","Epoch: 0, Loss: 0.6568475961685181\n","Epoch: 0, Loss: 0.70769202709198\n","Epoch: 0, Loss: 0.6833888292312622\n","Epoch: 0, Loss: 0.6888010501861572\n","Epoch: 0, Loss: 0.6585838198661804\n","Epoch: 0, Loss: 0.6689854264259338\n","Epoch: 0, Loss: 0.7422893643379211\n","Epoch: 0, Loss: 0.6739232540130615\n","Epoch: 0, Loss: 0.75273597240448\n","Epoch: 0, Loss: 0.7372265458106995\n","Epoch: 0, Loss: 0.6729696989059448\n","Epoch: 0, Loss: 0.6957712173461914\n","Epoch: 0, Loss: 0.7897730469703674\n","Epoch: 0, Loss: 0.6638946533203125\n","Epoch: 0, Loss: 0.6396484375\n","Epoch: 0, Loss: 0.6744108200073242\n","Epoch: 0, Loss: 0.6496275067329407\n","Epoch: 0, Loss: 0.6596788763999939\n","Epoch: 0, Loss: 0.656460702419281\n","Epoch: 0, Loss: 0.686711311340332\n","Epoch: 0, Loss: 0.7444084882736206\n","Epoch: 0, Loss: 0.6828452348709106\n","Epoch: 0, Loss: 0.8182419538497925\n","Epoch: 0, Loss: 0.680742621421814\n","Epoch: 0, Loss: 0.6550526022911072\n","Epoch: 0, Loss: 0.6782986521720886\n","Epoch: 0, Loss: 0.6690337061882019\n","Epoch: 0, Loss: 0.7871749401092529\n","Epoch: 0, Loss: 0.6930556297302246\n","Epoch: 0, Loss: 0.776593029499054\n","Epoch: 0, Loss: 0.7497496604919434\n","Epoch: 0, Loss: 0.6766583919525146\n","Epoch: 0, Loss: 0.6889779567718506\n","Epoch: 0, Loss: 0.6304353475570679\n","Epoch: 0, Loss: 0.7161299586296082\n","Epoch: 0, Loss: 0.7360423803329468\n","Epoch: 0, Loss: 0.7406629323959351\n","Epoch: 0, Loss: 0.7143303155899048\n","Epoch: 0, Loss: 0.6871649622917175\n","Epoch: 0, Loss: 0.6792373657226562\n","Epoch: 0, Loss: 0.6851077675819397\n","Epoch: 0, Loss: 0.669962465763092\n","Epoch: 0, Loss: 0.7538354992866516\n","Epoch: 0, Loss: 0.6736230254173279\n","Epoch: 0, Loss: 0.726487934589386\n","Epoch: 0, Loss: 0.6880584955215454\n","Epoch: 0, Loss: 0.6793544292449951\n","Epoch: 0, Loss: 0.7374433279037476\n","Epoch: 0, Loss: 0.6272635459899902\n","Epoch: 0, Loss: 0.7170846462249756\n","Epoch: 0, Loss: 0.724629282951355\n","Epoch: 0, Loss: 0.7148115634918213\n","Epoch: 0, Loss: 0.649593710899353\n","Epoch: 0, Loss: 0.6601297855377197\n","Epoch: 0, Loss: 0.7038408517837524\n","Epoch: 0, Loss: 0.7416215538978577\n","Epoch: 0, Loss: 0.701176106929779\n","Epoch: 0, Loss: 0.7331918478012085\n","Epoch: 0, Loss: 0.7894212603569031\n","Epoch: 0, Loss: 0.7026404738426208\n","Epoch: 0, Loss: 0.7092049717903137\n","Epoch: 0, Loss: 0.6693053841590881\n","Epoch: 0, Loss: 0.7078065276145935\n","Epoch: 0, Loss: 0.7440187931060791\n","Epoch: 0, Loss: 0.7346621155738831\n","Epoch: 0, Loss: 0.7540475726127625\n","Epoch: 0, Loss: 0.6564399003982544\n","Epoch: 0, Loss: 0.7659974694252014\n","Epoch: 0, Loss: 0.6870251893997192\n","Epoch: 0, Loss: 0.7428101897239685\n","Epoch: 0, Loss: 0.7450079321861267\n","Epoch: 0, Loss: 0.7570239901542664\n","Epoch: 0, Loss: 0.7115005254745483\n","Epoch: 0, Loss: 0.694150984287262\n","Epoch: 0, Loss: 0.7529988288879395\n","Epoch: 0, Loss: 0.6941471099853516\n","Epoch: 0, Loss: 0.7136411666870117\n","Epoch: 0, Loss: 0.6858119368553162\n","Epoch: 0, Loss: 0.6574332118034363\n","Epoch: 0, Loss: 0.7220350503921509\n","Epoch: 0, Loss: 0.7395910024642944\n","Epoch: 0, Loss: 0.6694111824035645\n","Epoch: 0, Loss: 0.6220424175262451\n","Epoch: 0, Loss: 0.5883058309555054\n","Epoch: 0, Loss: 0.644834578037262\n","Epoch: 0, Loss: 0.6833352446556091\n","Epoch: 0, Loss: 0.6708397269248962\n","Epoch: 0, Loss: 0.6929446458816528\n","Epoch: 0, Loss: 0.6747893691062927\n","Epoch: 0, Loss: 0.7571325302124023\n","Epoch: 0, Loss: 0.7526021003723145\n","Epoch: 0, Loss: 0.6806449890136719\n","Epoch: 0, Loss: 0.677839457988739\n","Epoch: 0, Loss: 0.6890133619308472\n","Epoch: 0, Loss: 0.6842947006225586\n","Epoch: 0, Loss: 0.7092572450637817\n","Epoch: 0, Loss: 0.6005229949951172\n","Epoch: 0, Loss: 0.7644637823104858\n","Epoch: 0, Loss: 0.6782941818237305\n","Epoch: 0, Loss: 0.8127543330192566\n","Epoch: 0, Loss: 0.7092822194099426\n","Epoch: 0, Loss: 0.7556506991386414\n","Epoch: 0, Loss: 0.7348688840866089\n","Epoch: 0, Loss: 0.6775203943252563\n","Epoch: 0, Loss: 0.741496205329895\n","Epoch: 0, Loss: 0.7603923678398132\n","Epoch: 0, Loss: 0.6885080933570862\n","Epoch: 0, Loss: 0.7568637728691101\n","Epoch: 0, Loss: 0.7173724174499512\n","Epoch: 0, Loss: 0.7302321195602417\n","Epoch: 0, Loss: 0.7336265444755554\n","Epoch: 0, Loss: 0.8611590266227722\n","Epoch: 0, Loss: 0.6618780493736267\n","Epoch: 0, Loss: 0.7215131521224976\n","Epoch: 0, Loss: 0.6334304809570312\n","Epoch: 0, Loss: 0.683214545249939\n","Epoch: 0, Loss: 0.6983829736709595\n","Epoch: 0, Loss: 0.7088661193847656\n","Epoch: 0, Loss: 0.7153404355049133\n","Epoch: 0, Loss: 0.7300645112991333\n","Epoch: 0, Loss: 0.6676579713821411\n","Epoch: 0, Loss: 0.6622582674026489\n","Epoch: 0, Loss: 0.6950939893722534\n","Epoch: 0, Loss: 0.820397675037384\n","Epoch: 0, Loss: 0.7057477831840515\n","Epoch: 0, Loss: 0.6686614751815796\n","Epoch: 0, Loss: 0.6758171916007996\n","Epoch: 0, Loss: 0.6632480025291443\n","Epoch: 0, Loss: 0.6007984280586243\n","Epoch: 0, Loss: 0.7675578594207764\n","Epoch: 0, Loss: 0.7384682893753052\n","Epoch: 0, Loss: 0.6700063943862915\n","Epoch: 0, Loss: 0.6473875045776367\n","Epoch: 0, Loss: 0.6349308490753174\n","Epoch: 0, Loss: 0.6918959617614746\n","Epoch: 0, Loss: 0.7252861857414246\n","Epoch: 0, Loss: 0.6845750212669373\n","Epoch: 0, Loss: 0.6867225170135498\n","Epoch: 0, Loss: 0.7560592889785767\n","Epoch: 0, Loss: 0.7009291052818298\n","Epoch: 0, Loss: 0.720460057258606\n","Epoch: 0, Loss: 0.668790876865387\n","Epoch: 0, Loss: 0.7198269963264465\n","Epoch: 0, Loss: 0.6835397481918335\n","Epoch: 0, Loss: 0.6421056985855103\n","Epoch: 0, Loss: 0.6673890948295593\n","Epoch: 0, Loss: 0.6490529179573059\n","Epoch: 0, Loss: 0.6864182353019714\n","Epoch: 0, Loss: 0.7308088541030884\n","Epoch: 0, Loss: 0.705287754535675\n","Epoch: 0, Loss: 0.7298654317855835\n","Epoch: 0, Loss: 0.744866132736206\n","Epoch: 0, Loss: 0.6932401657104492\n","Epoch: 0, Loss: 0.6980094909667969\n","Epoch: 0, Loss: 0.6978889107704163\n","Epoch: 0, Loss: 0.6832906007766724\n","Epoch: 0, Loss: 0.7067005634307861\n","Epoch: 0, Loss: 0.6707326769828796\n","Epoch: 0, Loss: 0.6533042192459106\n","Epoch: 0, Loss: 0.7157344818115234\n","Epoch: 0, Loss: 0.7250683307647705\n","Epoch: 0, Loss: 0.7137569785118103\n","Epoch: 0, Loss: 0.7220423221588135\n","Epoch: 0, Loss: 0.6667738556861877\n","Epoch: 0, Loss: 0.6968506574630737\n","Epoch: 0, Loss: 0.6851168870925903\n","Epoch: 0, Loss: 0.6970036029815674\n","Epoch: 0, Loss: 0.6882529258728027\n","Epoch: 0, Loss: 0.6565916538238525\n","Epoch: 0, Loss: 0.7152297496795654\n","Epoch: 0, Loss: 0.666643500328064\n","Epoch: 0, Loss: 0.6906805634498596\n","Epoch: 0, Loss: 0.7094130516052246\n","Epoch: 0, Loss: 0.6899035573005676\n","Epoch: 0, Loss: 0.6511609554290771\n","Epoch: 0, Loss: 0.6634606719017029\n","Epoch: 0, Loss: 0.6804556846618652\n","Epoch: 0, Loss: 0.7643629312515259\n","Epoch: 0, Loss: 0.6888642311096191\n","Epoch: 0, Loss: 0.7355079650878906\n","Epoch: 0, Loss: 0.7681657671928406\n","Epoch: 0, Loss: 0.647307813167572\n","Epoch: 0, Loss: 0.6957692503929138\n","Epoch: 0, Loss: 0.6767812967300415\n","Epoch: 0, Loss: 0.7085186243057251\n","Epoch: 0, Loss: 0.7300775647163391\n","Epoch: 0, Loss: 0.6894093751907349\n","Epoch: 0, Loss: 0.6857709288597107\n","Epoch: 0, Loss: 0.6852463483810425\n","Epoch: 0, Loss: 0.7299286723136902\n","Epoch: 0, Loss: 0.8302032351493835\n","Epoch: 0, Loss: 0.6023733019828796\n","Epoch: 0, Loss: 0.7379072904586792\n","Epoch: 0, Loss: 0.6896446347236633\n","Epoch: 0, Loss: 0.7603985071182251\n","Epoch: 0, Loss: 0.7389400601387024\n","Epoch: 0, Loss: 0.7036136984825134\n","Epoch: 0, Loss: 0.732665479183197\n","Epoch: 0, Loss: 0.6518794298171997\n","Epoch: 0, Loss: 0.7171014547348022\n","Epoch: 0, Loss: 0.7015354037284851\n","Epoch: 0, Loss: 0.681464672088623\n","Epoch: 0, Loss: 0.6441171169281006\n","Epoch: 0, Loss: 0.6932867765426636\n","Epoch: 0, Loss: 0.66495281457901\n","Epoch: 0, Loss: 0.7602518796920776\n","Epoch: 0, Loss: 0.6387917399406433\n","Epoch: 0, Loss: 0.6801491379737854\n","Epoch: 0, Loss: 0.6917146444320679\n","Epoch: 0, Loss: 0.7075594663619995\n","Epoch: 0, Loss: 0.6800644397735596\n","Epoch: 0, Loss: 0.7820388674736023\n","Epoch: 0, Loss: 0.7389548420906067\n","Epoch: 0, Loss: 0.6781138181686401\n","Epoch: 0, Loss: 0.6292986869812012\n","Epoch: 0, Loss: 0.7956797480583191\n","Epoch: 0, Loss: 0.7091559171676636\n","Epoch: 0, Loss: 0.7629968523979187\n","Epoch: 0, Loss: 0.6048251390457153\n","Epoch: 0, Loss: 0.7939420342445374\n","Epoch: 0, Loss: 0.7069623470306396\n","Epoch: 0, Loss: 0.7177033424377441\n","Epoch: 0, Loss: 0.7527899742126465\n","Epoch: 0, Loss: 0.7179539799690247\n","Epoch: 0, Loss: 0.7820245027542114\n","Epoch: 0, Loss: 0.6614260077476501\n","Epoch: 0, Loss: 0.6363150477409363\n","Epoch: 0, Loss: 0.6956203579902649\n","Epoch: 0, Loss: 0.7623135447502136\n","Epoch: 0, Loss: 0.6927773356437683\n","Epoch: 0, Loss: 0.6456387042999268\n","Epoch: 0, Loss: 0.7156344652175903\n","Epoch: 0, Loss: 0.6940113306045532\n","Epoch: 0, Loss: 0.7169153690338135\n","Epoch: 0, Loss: 0.6585855484008789\n","Epoch: 0, Loss: 0.7067181468009949\n","Epoch: 0, Loss: 0.6779915690422058\n","Epoch: 0, Loss: 0.8057271838188171\n","Epoch: 0, Loss: 0.6818761825561523\n","Epoch: 0, Loss: 0.678381085395813\n","Epoch: 0, Loss: 0.7488627433776855\n","Epoch: 0, Loss: 0.786532998085022\n","Epoch: 0, Loss: 0.729250431060791\n","Epoch: 0, Loss: 0.7321639657020569\n","Epoch: 0, Loss: 0.6374165415763855\n","Epoch: 0, Loss: 0.6523413062095642\n","Epoch: 0, Loss: 0.7231988310813904\n","Epoch: 0, Loss: 0.7404186725616455\n","Epoch: 0, Loss: 0.7536989450454712\n","Epoch: 0, Loss: 0.7525509595870972\n","Epoch: 0, Loss: 0.6341369152069092\n","Epoch: 0, Loss: 0.7219098210334778\n","Epoch: 0, Loss: 0.6354705095291138\n","Epoch: 0, Loss: 0.6922330856323242\n","Epoch: 0, Loss: 0.7379536032676697\n","Epoch: 0, Loss: 0.6741325259208679\n","Epoch: 0, Loss: 0.7472336888313293\n","Epoch: 0, Loss: 0.7450785040855408\n","Epoch: 0, Loss: 0.6331661343574524\n","Epoch: 0, Loss: 0.7282604575157166\n","Epoch: 0, Loss: 0.6831878423690796\n","Epoch: 0, Loss: 0.6576887369155884\n","Epoch: 0, Loss: 0.7512536644935608\n","Epoch: 0, Loss: 0.6741001009941101\n","Epoch: 0, Loss: 0.7233495116233826\n","Epoch: 0, Loss: 0.7119847536087036\n","Epoch: 0, Loss: 0.7012344598770142\n","Epoch: 0, Loss: 0.7500114440917969\n","Epoch: 0, Loss: 0.7720575332641602\n","Epoch: 0, Loss: 0.7089999914169312\n","Epoch: 0, Loss: 0.764552652835846\n","Epoch: 0, Loss: 0.7134031653404236\n","Epoch: 0, Loss: 0.6644872426986694\n","Epoch: 0, Loss: 0.6686816811561584\n","Epoch: 0, Loss: 0.6918270587921143\n","Epoch: 0, Loss: 0.664040744304657\n","Epoch: 0, Loss: 0.6540440320968628\n","Epoch: 0, Loss: 0.7404965758323669\n","Epoch: 0, Loss: 0.7163444757461548\n","Epoch: 0, Loss: 0.7435581684112549\n","Epoch: 0, Loss: 0.6925455927848816\n","Epoch: 0, Loss: 0.7150625586509705\n","Epoch: 0, Loss: 0.6888953447341919\n","Epoch: 0, Loss: 0.7097771763801575\n","Epoch: 0, Loss: 0.6585284471511841\n","Epoch: 0, Loss: 0.6326640248298645\n","Epoch: 0, Loss: 0.6434609889984131\n","Epoch: 0, Loss: 0.6628666520118713\n","Epoch: 0, Loss: 0.6915323734283447\n","Epoch: 0, Loss: 0.6779489517211914\n","Epoch: 0, Loss: 0.6580360531806946\n","Epoch: 0, Loss: 0.6604379415512085\n","Epoch: 0, Loss: 0.635146975517273\n","Epoch: 0, Loss: 0.6965082287788391\n","Epoch: 0, Loss: 0.7315294742584229\n","Epoch: 0, Loss: 0.7607638835906982\n","Epoch: 0, Loss: 0.6387670636177063\n","Epoch: 0, Loss: 0.7895417213439941\n","Epoch: 0, Loss: 0.650775671005249\n","Epoch: 0, Loss: 0.725893497467041\n","Epoch: 0, Loss: 0.8711387515068054\n","Epoch: 0, Loss: 0.566001296043396\n","Epoch: 0, Loss: 0.84657222032547\n","Epoch: 0, Loss: 0.6035802960395813\n","Epoch: 0, Loss: 0.8318659663200378\n","Epoch: 0, Loss: 0.7005089521408081\n","Epoch: 0, Loss: 0.7724959850311279\n","Epoch: 0, Loss: 0.6872855424880981\n","Epoch: 0, Loss: 0.7399703860282898\n","Epoch: 0, Loss: 0.6081395745277405\n","Epoch: 0, Loss: 0.8253319263458252\n","Epoch: 0, Loss: 0.6628156304359436\n","Epoch: 0, Loss: 0.7503926753997803\n","Epoch: 0, Loss: 0.6828201413154602\n","Epoch: 0, Loss: 0.6936247944831848\n","Epoch: 0, Loss: 0.7065172791481018\n","Epoch: 0, Loss: 0.7048220634460449\n","Epoch: 0, Loss: 0.7035073637962341\n","Epoch: 0, Loss: 0.824938952922821\n","Epoch: 0, Loss: 0.7174448370933533\n","Epoch: 0, Loss: 0.6292797923088074\n","Epoch: 0, Loss: 0.642195463180542\n","Epoch: 0, Loss: 0.6289716362953186\n","Epoch: 0, Loss: 0.7117162346839905\n","Epoch: 0, Loss: 0.7381038069725037\n","Epoch: 0, Loss: 0.7481452822685242\n","Epoch: 0, Loss: 0.7081726789474487\n","Epoch: 0, Loss: 0.7385517954826355\n","Epoch: 0, Loss: 0.6882453560829163\n","Epoch: 0, Loss: 0.7602073550224304\n","Epoch: 0, Loss: 0.6843577027320862\n","Epoch: 0, Loss: 0.735451877117157\n","Epoch: 0, Loss: 0.7870022058486938\n","Epoch: 0, Loss: 0.7659860849380493\n","Epoch: 0, Loss: 0.7498338222503662\n","Epoch: 0, Loss: 0.7247021198272705\n","Epoch: 0, Loss: 0.6722704172134399\n","Epoch: 0, Loss: 0.6504737734794617\n","Epoch: 0, Loss: 0.7303198575973511\n","Epoch: 0, Loss: 0.69638991355896\n","Epoch: 0, Loss: 0.7644587159156799\n","Epoch: 0, Loss: 0.631787896156311\n","Epoch: 0, Loss: 0.7589514851570129\n","Epoch: 0, Loss: 0.7154222130775452\n","Epoch: 0, Loss: 0.597396969795227\n","Epoch: 0, Loss: 0.6582515835762024\n","Epoch: 0, Loss: 0.7370303869247437\n","Epoch: 0, Loss: 0.7065920233726501\n","Epoch: 0, Loss: 0.7241336107254028\n","Epoch: 0, Loss: 0.7432355880737305\n","Epoch: 0, Loss: 0.7890157699584961\n","Epoch: 0, Loss: 0.7458226084709167\n","Epoch: 0, Loss: 0.7569907903671265\n","Epoch: 0, Loss: 0.6543284058570862\n","Epoch: 0, Loss: 0.8083471059799194\n","Epoch: 0, Loss: 0.728301465511322\n","Epoch: 0, Loss: 0.6559529304504395\n","Epoch: 0, Loss: 0.7114746570587158\n","Epoch: 0, Loss: 0.708717942237854\n","Epoch: 0, Loss: 0.7280498743057251\n","Epoch: 0, Loss: 0.7203143835067749\n","Epoch: 0, Loss: 0.673038899898529\n","Epoch: 0, Loss: 0.702203094959259\n","Epoch: 0, Loss: 0.6771745085716248\n","Epoch: 0, Loss: 0.7885680198669434\n","Epoch: 0, Loss: 0.6420050859451294\n","Epoch: 0, Loss: 0.7369738817214966\n","Epoch: 0, Loss: 0.7359102368354797\n","Epoch: 0, Loss: 0.6183977723121643\n","Epoch: 0, Loss: 0.7426639795303345\n","Epoch: 0, Loss: 0.6263090968132019\n","Epoch: 0, Loss: 0.6556997895240784\n","Epoch: 0, Loss: 0.7012412548065186\n","Epoch: 0, Loss: 0.5956252813339233\n","Epoch: 0, Loss: 0.8097843527793884\n","Epoch: 0, Loss: 0.6830301284790039\n","Epoch: 0, Loss: 0.667888879776001\n","Epoch: 0, Loss: 0.7047562599182129\n","Epoch: 0, Loss: 0.6784774661064148\n","Epoch: 0, Loss: 0.7190864086151123\n","Epoch: 0, Loss: 0.7409375905990601\n","Epoch: 0, Loss: 0.6878652572631836\n","Epoch: 0, Loss: 0.6175550222396851\n","Epoch: 0, Loss: 0.7836255431175232\n","Epoch: 0, Loss: 0.6587425470352173\n","Epoch: 0, Loss: 0.7853690385818481\n","Epoch: 0, Loss: 0.5938404202461243\n","Epoch: 0, Loss: 0.626062273979187\n","Epoch: 0, Loss: 0.7970412969589233\n","Epoch: 0, Loss: 0.7423751354217529\n","Epoch: 0, Loss: 0.721782922744751\n","Epoch: 0, Loss: 0.7841067314147949\n","Epoch: 0, Loss: 0.7017714977264404\n","Epoch: 0, Loss: 0.7154585123062134\n","Epoch: 0, Loss: 0.8063572645187378\n","Epoch: 1, Loss: 0.7618799209594727\n","Epoch: 1, Loss: 0.7068052291870117\n","Epoch: 1, Loss: 0.6248766183853149\n","Epoch: 1, Loss: 0.7651752233505249\n","Epoch: 1, Loss: 0.7855433225631714\n","Epoch: 1, Loss: 0.7455140352249146\n","Epoch: 1, Loss: 0.7567108273506165\n","Epoch: 1, Loss: 0.6308227181434631\n","Epoch: 1, Loss: 0.7977671027183533\n","Epoch: 1, Loss: 0.6491047143936157\n","Epoch: 1, Loss: 0.7971540689468384\n","Epoch: 1, Loss: 0.6856015920639038\n","Epoch: 1, Loss: 0.6746439933776855\n","Epoch: 1, Loss: 0.6379538774490356\n","Epoch: 1, Loss: 0.6844319105148315\n","Epoch: 1, Loss: 0.713884711265564\n","Epoch: 1, Loss: 0.6400356292724609\n","Epoch: 1, Loss: 0.6712477207183838\n","Epoch: 1, Loss: 0.7598784565925598\n","Epoch: 1, Loss: 0.5971367359161377\n","Epoch: 1, Loss: 0.6860467195510864\n","Epoch: 1, Loss: 0.6507677435874939\n","Epoch: 1, Loss: 0.6438884139060974\n","Epoch: 1, Loss: 0.7200028896331787\n","Epoch: 1, Loss: 0.7108380198478699\n","Epoch: 1, Loss: 0.7011677026748657\n","Epoch: 1, Loss: 0.6855274438858032\n","Epoch: 1, Loss: 0.7293332815170288\n","Epoch: 1, Loss: 0.6865191459655762\n","Epoch: 1, Loss: 0.6681743860244751\n","Epoch: 1, Loss: 0.6904488801956177\n","Epoch: 1, Loss: 0.7813654541969299\n","Epoch: 1, Loss: 0.6754708886146545\n","Epoch: 1, Loss: 0.6807504892349243\n","Epoch: 1, Loss: 0.676385760307312\n","Epoch: 1, Loss: 0.6689524054527283\n","Epoch: 1, Loss: 0.6180725693702698\n","Epoch: 1, Loss: 0.6362831592559814\n","Epoch: 1, Loss: 0.732790470123291\n","Epoch: 1, Loss: 0.9443172812461853\n","Epoch: 1, Loss: 0.6802380681037903\n","Epoch: 1, Loss: 0.618195116519928\n","Epoch: 1, Loss: 0.5897713303565979\n","Epoch: 1, Loss: 0.8352721333503723\n","Epoch: 1, Loss: 0.8190649151802063\n","Epoch: 1, Loss: 0.8703975677490234\n","Epoch: 1, Loss: 0.7805703282356262\n","Epoch: 1, Loss: 0.7355911135673523\n","Epoch: 1, Loss: 0.7315077781677246\n","Epoch: 1, Loss: 0.7355931401252747\n","Epoch: 1, Loss: 0.7190127372741699\n","Epoch: 1, Loss: 0.7617405652999878\n","Epoch: 1, Loss: 0.5976804494857788\n","Epoch: 1, Loss: 0.6910541653633118\n","Epoch: 1, Loss: 0.883773922920227\n","Epoch: 1, Loss: 0.7256907224655151\n","Epoch: 1, Loss: 0.8175668716430664\n","Epoch: 1, Loss: 0.8905700445175171\n","Epoch: 1, Loss: 0.6619116067886353\n","Epoch: 1, Loss: 0.7044395804405212\n","Epoch: 1, Loss: 0.6194651126861572\n","Epoch: 1, Loss: 0.7742343544960022\n","Epoch: 1, Loss: 0.6725716590881348\n","Epoch: 1, Loss: 0.6894977688789368\n","Epoch: 1, Loss: 0.6705977916717529\n","Epoch: 1, Loss: 0.6291258335113525\n","Epoch: 1, Loss: 0.6744161248207092\n","Epoch: 1, Loss: 0.7878313660621643\n","Epoch: 1, Loss: 0.6668583154678345\n","Epoch: 1, Loss: 0.6956404447555542\n","Epoch: 1, Loss: 0.7405017614364624\n","Epoch: 1, Loss: 0.7851475477218628\n","Epoch: 1, Loss: 0.6901236772537231\n","Epoch: 1, Loss: 0.7024968862533569\n","Epoch: 1, Loss: 0.7782036066055298\n","Epoch: 1, Loss: 0.6490548253059387\n","Epoch: 1, Loss: 0.6552454829216003\n","Epoch: 1, Loss: 0.7133063077926636\n","Epoch: 1, Loss: 0.7490503191947937\n","Epoch: 1, Loss: 0.6739535927772522\n","Epoch: 1, Loss: 0.6890576481819153\n","Epoch: 1, Loss: 0.7737429738044739\n","Epoch: 1, Loss: 0.7502543926239014\n","Epoch: 1, Loss: 0.759247899055481\n","Epoch: 1, Loss: 0.6690343618392944\n","Epoch: 1, Loss: 0.6449790596961975\n","Epoch: 1, Loss: 0.6429443359375\n","Epoch: 1, Loss: 0.6644780039787292\n","Epoch: 1, Loss: 0.6911430358886719\n","Epoch: 1, Loss: 0.652965247631073\n","Epoch: 1, Loss: 0.6789041757583618\n","Epoch: 1, Loss: 0.6309195756912231\n","Epoch: 1, Loss: 0.6884031891822815\n","Epoch: 1, Loss: 0.6736338138580322\n","Epoch: 1, Loss: 0.705958366394043\n","Epoch: 1, Loss: 0.6831775903701782\n","Epoch: 1, Loss: 0.7587860822677612\n","Epoch: 1, Loss: 0.7069203853607178\n","Epoch: 1, Loss: 0.709726870059967\n","Epoch: 1, Loss: 0.8096849322319031\n","Epoch: 1, Loss: 0.7088230848312378\n","Epoch: 1, Loss: 0.7097656726837158\n","Epoch: 1, Loss: 0.6503534317016602\n","Epoch: 1, Loss: 0.7391364574432373\n","Epoch: 1, Loss: 0.7133345603942871\n","Epoch: 1, Loss: 0.7353955507278442\n","Epoch: 1, Loss: 0.6856482028961182\n","Epoch: 1, Loss: 0.6968821287155151\n","Epoch: 1, Loss: 0.6846689581871033\n","Epoch: 1, Loss: 0.76155686378479\n","Epoch: 1, Loss: 0.6225048899650574\n","Epoch: 1, Loss: 0.7599911689758301\n","Epoch: 1, Loss: 0.7111690640449524\n","Epoch: 1, Loss: 0.6757810711860657\n","Epoch: 1, Loss: 0.7132605910301208\n","Epoch: 1, Loss: 0.7183969020843506\n","Epoch: 1, Loss: 0.6736598610877991\n","Epoch: 1, Loss: 0.6975093483924866\n","Epoch: 1, Loss: 0.7307161092758179\n","Epoch: 1, Loss: 0.751166820526123\n","Epoch: 1, Loss: 0.6807534694671631\n","Epoch: 1, Loss: 0.7601117491722107\n","Epoch: 1, Loss: 0.704285740852356\n","Epoch: 1, Loss: 0.7128052115440369\n","Epoch: 1, Loss: 0.7417154908180237\n","Epoch: 1, Loss: 0.7530133128166199\n","Epoch: 1, Loss: 0.6779263615608215\n","Epoch: 1, Loss: 0.6868147253990173\n","Epoch: 1, Loss: 0.7300560474395752\n","Epoch: 1, Loss: 0.7617144584655762\n","Epoch: 1, Loss: 0.6467909812927246\n","Epoch: 1, Loss: 0.7313761115074158\n","Epoch: 1, Loss: 0.7703102827072144\n","Epoch: 1, Loss: 0.6960369944572449\n","Epoch: 1, Loss: 0.7087962627410889\n","Epoch: 1, Loss: 0.790212094783783\n","Epoch: 1, Loss: 0.6815057396888733\n","Epoch: 1, Loss: 0.618858277797699\n","Epoch: 1, Loss: 0.6120408177375793\n","Epoch: 1, Loss: 0.6231634616851807\n","Epoch: 1, Loss: 0.7550449967384338\n","Epoch: 1, Loss: 0.6812905073165894\n","Epoch: 1, Loss: 0.7454572916030884\n","Epoch: 1, Loss: 0.6839929819107056\n","Epoch: 1, Loss: 0.6510064601898193\n","Epoch: 1, Loss: 0.6659713387489319\n","Epoch: 1, Loss: 0.7564156651496887\n","Epoch: 1, Loss: 0.746221661567688\n","Epoch: 1, Loss: 0.7692952752113342\n","Epoch: 1, Loss: 0.6980885863304138\n","Epoch: 1, Loss: 0.7220998406410217\n","Epoch: 1, Loss: 0.743861198425293\n","Epoch: 1, Loss: 0.5843402147293091\n","Epoch: 1, Loss: 0.6464920043945312\n","Epoch: 1, Loss: 0.6937257051467896\n","Epoch: 1, Loss: 0.6918346881866455\n","Epoch: 1, Loss: 0.7783499956130981\n","Epoch: 1, Loss: 0.727000892162323\n","Epoch: 1, Loss: 0.7333828210830688\n","Epoch: 1, Loss: 0.6954390406608582\n","Epoch: 1, Loss: 0.7613744139671326\n","Epoch: 1, Loss: 0.7745530009269714\n","Epoch: 1, Loss: 0.7655352354049683\n","Epoch: 1, Loss: 0.6795099973678589\n","Epoch: 1, Loss: 0.6330312490463257\n","Epoch: 1, Loss: 0.6807183027267456\n","Epoch: 1, Loss: 0.8257926106452942\n","Epoch: 1, Loss: 0.6914735436439514\n","Epoch: 1, Loss: 0.6723048686981201\n","Epoch: 1, Loss: 0.697092592716217\n","Epoch: 1, Loss: 0.793971061706543\n","Epoch: 1, Loss: 0.6679885983467102\n","Epoch: 1, Loss: 0.7531560659408569\n","Epoch: 1, Loss: 0.5991336703300476\n","Epoch: 1, Loss: 0.7362373471260071\n","Epoch: 1, Loss: 0.681011438369751\n","Epoch: 1, Loss: 0.6803481578826904\n","Epoch: 1, Loss: 0.72502601146698\n","Epoch: 1, Loss: 0.7240626811981201\n","Epoch: 1, Loss: 0.5951821804046631\n","Epoch: 1, Loss: 0.7060320377349854\n","Epoch: 1, Loss: 0.7469826936721802\n","Epoch: 1, Loss: 0.6636871099472046\n","Epoch: 1, Loss: 0.7327799797058105\n","Epoch: 1, Loss: 0.7802830338478088\n","Epoch: 1, Loss: 0.651094377040863\n","Epoch: 1, Loss: 0.6586430668830872\n","Epoch: 1, Loss: 0.6863594651222229\n","Epoch: 1, Loss: 0.7695298194885254\n","Epoch: 1, Loss: 0.7175436615943909\n","Epoch: 1, Loss: 0.7239038944244385\n","Epoch: 1, Loss: 0.6974532604217529\n","Epoch: 1, Loss: 0.7205554842948914\n","Epoch: 1, Loss: 0.720659077167511\n","Epoch: 1, Loss: 0.6899913549423218\n","Epoch: 1, Loss: 0.6476122140884399\n","Epoch: 1, Loss: 0.7810827493667603\n","Epoch: 1, Loss: 0.6814484596252441\n","Epoch: 1, Loss: 0.7456884980201721\n","Epoch: 1, Loss: 0.7320461869239807\n","Epoch: 1, Loss: 0.7515180706977844\n","Epoch: 1, Loss: 0.6770996451377869\n","Epoch: 1, Loss: 0.669546365737915\n","Epoch: 1, Loss: 0.7015559077262878\n","Epoch: 1, Loss: 0.7058731913566589\n","Epoch: 1, Loss: 0.6902933120727539\n","Epoch: 1, Loss: 0.6642463803291321\n","Epoch: 1, Loss: 0.7292953133583069\n","Epoch: 1, Loss: 0.6835632920265198\n","Epoch: 1, Loss: 0.6169471144676208\n","Epoch: 1, Loss: 0.7223933935165405\n","Epoch: 1, Loss: 0.7364915609359741\n","Epoch: 1, Loss: 0.6152665615081787\n","Epoch: 1, Loss: 0.6661674976348877\n","Epoch: 1, Loss: 0.7925055623054504\n","Epoch: 1, Loss: 0.6356788873672485\n","Epoch: 1, Loss: 0.7500901222229004\n","Epoch: 1, Loss: 0.6481709480285645\n","Epoch: 1, Loss: 0.7147290110588074\n","Epoch: 1, Loss: 0.7524397969245911\n","Epoch: 1, Loss: 0.6309923529624939\n","Epoch: 1, Loss: 0.7098895907402039\n","Epoch: 1, Loss: 0.6331157088279724\n","Epoch: 1, Loss: 0.6637811660766602\n","Epoch: 1, Loss: 0.6749312877655029\n","Epoch: 1, Loss: 0.7797317504882812\n","Epoch: 1, Loss: 0.7161134481430054\n","Epoch: 1, Loss: 0.7729750871658325\n","Epoch: 1, Loss: 0.6671079397201538\n","Epoch: 1, Loss: 0.6682491302490234\n","Epoch: 1, Loss: 0.7371842265129089\n","Epoch: 1, Loss: 0.7262260317802429\n","Epoch: 1, Loss: 0.7405655980110168\n","Epoch: 1, Loss: 0.777757465839386\n","Epoch: 1, Loss: 0.6796938180923462\n","Epoch: 1, Loss: 0.6342489719390869\n","Epoch: 1, Loss: 0.6544582843780518\n","Epoch: 1, Loss: 0.7609437704086304\n","Epoch: 1, Loss: 0.7059796452522278\n","Epoch: 1, Loss: 0.6976727247238159\n","Epoch: 1, Loss: 0.6633891463279724\n","Epoch: 1, Loss: 0.6618837118148804\n","Epoch: 1, Loss: 0.724878191947937\n","Epoch: 1, Loss: 0.7287170886993408\n","Epoch: 1, Loss: 0.6450236439704895\n","Epoch: 1, Loss: 0.7187949419021606\n","Epoch: 1, Loss: 0.7280632257461548\n","Epoch: 1, Loss: 0.6736708879470825\n","Epoch: 1, Loss: 0.6942507028579712\n","Epoch: 1, Loss: 0.689795732498169\n","Epoch: 1, Loss: 0.7135992050170898\n","Epoch: 1, Loss: 0.7253845930099487\n","Epoch: 1, Loss: 0.6692264080047607\n","Epoch: 1, Loss: 0.7506166100502014\n","Epoch: 1, Loss: 0.7251529097557068\n","Epoch: 1, Loss: 0.7386583089828491\n","Epoch: 1, Loss: 0.7554929852485657\n","Epoch: 1, Loss: 0.7073332667350769\n","Epoch: 1, Loss: 0.6971158385276794\n","Epoch: 1, Loss: 0.6944812536239624\n","Epoch: 1, Loss: 0.7254112958908081\n","Epoch: 1, Loss: 0.6884651780128479\n","Epoch: 1, Loss: 0.6721611618995667\n","Epoch: 1, Loss: 0.6946289539337158\n","Epoch: 1, Loss: 0.7370161414146423\n","Epoch: 1, Loss: 0.6665443181991577\n","Epoch: 1, Loss: 0.6808167099952698\n","Epoch: 1, Loss: 0.7213085889816284\n","Epoch: 1, Loss: 0.6658424735069275\n","Epoch: 1, Loss: 0.687430739402771\n","Epoch: 1, Loss: 0.673183262348175\n","Epoch: 1, Loss: 0.615354597568512\n","Epoch: 1, Loss: 0.6808643341064453\n","Epoch: 1, Loss: 0.6908504962921143\n","Epoch: 1, Loss: 0.6631724238395691\n","Epoch: 1, Loss: 0.7392676472663879\n","Epoch: 1, Loss: 0.6750012636184692\n","Epoch: 1, Loss: 0.7118808627128601\n","Epoch: 1, Loss: 0.6753496527671814\n","Epoch: 1, Loss: 0.6907013058662415\n","Epoch: 1, Loss: 0.6900689601898193\n","Epoch: 1, Loss: 0.7026956081390381\n","Epoch: 1, Loss: 0.6240795850753784\n","Epoch: 1, Loss: 0.677030086517334\n","Epoch: 1, Loss: 0.654538094997406\n","Epoch: 1, Loss: 0.7409873008728027\n","Epoch: 1, Loss: 0.6777999997138977\n","Epoch: 1, Loss: 0.639464259147644\n","Epoch: 1, Loss: 0.5948275327682495\n","Epoch: 1, Loss: 0.6271173357963562\n","Epoch: 1, Loss: 0.7223005294799805\n","Epoch: 1, Loss: 0.7360607385635376\n","Epoch: 1, Loss: 0.6158462166786194\n","Epoch: 1, Loss: 0.6312066912651062\n","Epoch: 1, Loss: 0.6062421202659607\n","Epoch: 1, Loss: 0.7324930429458618\n","Epoch: 1, Loss: 0.6575859785079956\n","Epoch: 1, Loss: 0.7221512198448181\n","Epoch: 1, Loss: 0.6755216121673584\n","Epoch: 1, Loss: 0.638002872467041\n","Epoch: 1, Loss: 0.6386640071868896\n","Epoch: 1, Loss: 0.573654294013977\n","Epoch: 1, Loss: 0.6556833982467651\n","Epoch: 1, Loss: 0.773509681224823\n","Epoch: 1, Loss: 0.7150335907936096\n","Epoch: 1, Loss: 0.7922347187995911\n","Epoch: 1, Loss: 0.7171602845191956\n","Epoch: 1, Loss: 0.849053144454956\n","Epoch: 1, Loss: 0.6892848014831543\n","Epoch: 1, Loss: 0.7145802974700928\n","Epoch: 1, Loss: 0.7488159537315369\n","Epoch: 1, Loss: 0.6458266973495483\n","Epoch: 1, Loss: 0.6845796704292297\n","Epoch: 1, Loss: 0.7597565650939941\n","Epoch: 1, Loss: 0.809851884841919\n","Epoch: 1, Loss: 0.7225077152252197\n","Epoch: 1, Loss: 0.643090009689331\n","Epoch: 1, Loss: 0.7614503502845764\n","Epoch: 1, Loss: 0.6972751617431641\n","Epoch: 1, Loss: 0.6959174871444702\n","Epoch: 1, Loss: 0.7451589107513428\n","Epoch: 1, Loss: 0.6394973397254944\n","Epoch: 1, Loss: 0.6867212057113647\n","Epoch: 1, Loss: 0.7626338601112366\n","Epoch: 1, Loss: 0.6859449148178101\n","Epoch: 1, Loss: 0.6385756731033325\n","Epoch: 1, Loss: 0.7119133472442627\n","Epoch: 1, Loss: 0.6284926533699036\n","Epoch: 1, Loss: 0.7047207355499268\n","Epoch: 1, Loss: 0.6373043656349182\n","Epoch: 1, Loss: 0.7387866377830505\n","Epoch: 1, Loss: 0.6961929798126221\n","Epoch: 1, Loss: 0.6958645582199097\n","Epoch: 1, Loss: 0.6528856754302979\n","Epoch: 1, Loss: 0.6661854386329651\n","Epoch: 1, Loss: 0.6982515454292297\n","Epoch: 1, Loss: 0.6667089462280273\n","Epoch: 1, Loss: 0.7028934955596924\n","Epoch: 1, Loss: 0.7022912502288818\n","Epoch: 1, Loss: 0.8082147240638733\n","Epoch: 1, Loss: 0.5837047100067139\n","Epoch: 1, Loss: 0.6326392292976379\n","Epoch: 1, Loss: 0.7844862937927246\n","Epoch: 1, Loss: 0.6887432336807251\n","Epoch: 1, Loss: 0.5973156690597534\n","Epoch: 1, Loss: 0.7650255560874939\n","Epoch: 1, Loss: 0.6744444370269775\n","Epoch: 1, Loss: 0.720025360584259\n","Epoch: 1, Loss: 0.6514269113540649\n","Epoch: 1, Loss: 0.6648359298706055\n","Epoch: 1, Loss: 0.6671108603477478\n","Epoch: 1, Loss: 0.656586229801178\n","Epoch: 1, Loss: 0.7127498984336853\n","Epoch: 1, Loss: 0.6493787169456482\n","Epoch: 1, Loss: 0.6806076169013977\n","Epoch: 1, Loss: 0.6902688145637512\n","Epoch: 1, Loss: 0.7409822344779968\n","Epoch: 1, Loss: 0.6294847130775452\n","Epoch: 1, Loss: 0.7328490614891052\n","Epoch: 1, Loss: 0.702338695526123\n","Epoch: 1, Loss: 0.711314857006073\n","Epoch: 1, Loss: 0.6704279780387878\n","Epoch: 1, Loss: 0.8026174306869507\n","Epoch: 1, Loss: 0.7295666933059692\n","Epoch: 1, Loss: 0.6641684174537659\n","Epoch: 1, Loss: 0.6859833002090454\n","Epoch: 1, Loss: 0.7212077975273132\n","Epoch: 1, Loss: 0.710991382598877\n","Epoch: 1, Loss: 0.7370267510414124\n","Epoch: 1, Loss: 0.7681960463523865\n","Epoch: 1, Loss: 0.6579472422599792\n","Epoch: 1, Loss: 0.7060254812240601\n","Epoch: 1, Loss: 0.6419593691825867\n","Epoch: 1, Loss: 0.6965965032577515\n","Epoch: 1, Loss: 0.731993556022644\n","Epoch: 1, Loss: 0.7691266536712646\n","Epoch: 1, Loss: 0.743649959564209\n","Epoch: 1, Loss: 0.7312202453613281\n","Epoch: 1, Loss: 0.6055962443351746\n","Epoch: 1, Loss: 0.6504326462745667\n","Epoch: 1, Loss: 0.6503642797470093\n","Epoch: 1, Loss: 0.7220171689987183\n","Epoch: 1, Loss: 0.671892523765564\n","Epoch: 1, Loss: 0.6855900883674622\n","Epoch: 1, Loss: 0.6556755304336548\n","Epoch: 1, Loss: 0.6730112433433533\n","Epoch: 1, Loss: 0.7649238109588623\n","Epoch: 1, Loss: 0.7159872055053711\n","Epoch: 1, Loss: 0.6731536984443665\n","Epoch: 1, Loss: 0.6952775716781616\n","Epoch: 1, Loss: 0.7207461595535278\n","Epoch: 1, Loss: 0.7729706168174744\n","Epoch: 1, Loss: 0.7054689526557922\n","Epoch: 1, Loss: 0.6989622116088867\n","Epoch: 1, Loss: 0.7075226306915283\n","Epoch: 1, Loss: 0.6912268400192261\n","Epoch: 1, Loss: 0.6801626086235046\n","Epoch: 1, Loss: 0.6979732513427734\n","Epoch: 1, Loss: 0.6998391151428223\n","Epoch: 1, Loss: 0.7216269373893738\n","Epoch: 1, Loss: 0.6440622210502625\n","Epoch: 1, Loss: 0.7150130867958069\n","Epoch: 1, Loss: 0.6385138034820557\n","Epoch: 1, Loss: 0.7283337712287903\n","Epoch: 1, Loss: 0.7308835387229919\n","Epoch: 1, Loss: 0.7005389332771301\n","Epoch: 1, Loss: 0.7689693570137024\n","Epoch: 1, Loss: 0.7526886463165283\n","Epoch: 1, Loss: 0.6641440391540527\n","Epoch: 1, Loss: 0.7002008557319641\n","Epoch: 1, Loss: 0.650763988494873\n","Epoch: 1, Loss: 0.6427066326141357\n","Epoch: 1, Loss: 0.6964476108551025\n","Epoch: 1, Loss: 0.6309753656387329\n","Epoch: 1, Loss: 0.6750108003616333\n","Epoch: 1, Loss: 0.666377067565918\n","Epoch: 1, Loss: 0.7307563424110413\n","Epoch: 1, Loss: 0.7657040953636169\n","Epoch: 1, Loss: 0.655282199382782\n","Epoch: 1, Loss: 0.7312953472137451\n","Epoch: 1, Loss: 0.8276470303535461\n","Epoch: 1, Loss: 0.7062572240829468\n","Epoch: 1, Loss: 0.6091381311416626\n","Epoch: 1, Loss: 0.6803914904594421\n","Epoch: 1, Loss: 0.7640770077705383\n","Epoch: 1, Loss: 0.6831231117248535\n","Epoch: 1, Loss: 0.6842881441116333\n","Epoch: 1, Loss: 0.7184935212135315\n","Epoch: 1, Loss: 0.7037138342857361\n","Epoch: 1, Loss: 0.6820125579833984\n","Epoch: 1, Loss: 0.705276608467102\n","Epoch: 1, Loss: 0.6753496527671814\n","Epoch: 1, Loss: 0.664491593837738\n","Epoch: 1, Loss: 0.7486485242843628\n","Epoch: 1, Loss: 0.6837220788002014\n","Epoch: 1, Loss: 0.689253032207489\n","Epoch: 1, Loss: 0.7852834463119507\n","Epoch: 1, Loss: 0.6656530499458313\n","Epoch: 1, Loss: 0.6086238622665405\n","Epoch: 1, Loss: 0.7000684142112732\n","Epoch: 1, Loss: 0.7676982283592224\n","Epoch: 1, Loss: 0.6120765209197998\n","Epoch: 1, Loss: 0.6699968576431274\n","Epoch: 1, Loss: 0.6825213432312012\n","Epoch: 1, Loss: 0.7157894372940063\n","Epoch: 1, Loss: 0.6436243653297424\n","Epoch: 1, Loss: 0.8074513077735901\n","Epoch: 1, Loss: 0.7230947613716125\n","Epoch: 1, Loss: 0.7526522874832153\n","Epoch: 1, Loss: 0.7455034852027893\n","Epoch: 1, Loss: 0.6760163903236389\n","Epoch: 1, Loss: 0.6256777048110962\n","Epoch: 1, Loss: 0.6829080581665039\n","Epoch: 1, Loss: 0.7868024110794067\n","Epoch: 1, Loss: 0.7275556325912476\n","Epoch: 1, Loss: 0.7600432634353638\n","Epoch: 1, Loss: 0.6885068416595459\n","Epoch: 1, Loss: 0.6675827503204346\n","Epoch: 1, Loss: 0.6561700105667114\n","Epoch: 1, Loss: 0.7343940138816833\n","Epoch: 1, Loss: 0.6825587153434753\n","Epoch: 1, Loss: 0.6043288707733154\n","Epoch: 1, Loss: 0.7430295944213867\n","Epoch: 1, Loss: 0.708525538444519\n","Epoch: 1, Loss: 0.7963005304336548\n","Epoch: 1, Loss: 0.740338921546936\n","Epoch: 1, Loss: 0.6990393400192261\n","Epoch: 1, Loss: 0.6977190971374512\n","Epoch: 1, Loss: 0.7375643253326416\n","Epoch: 1, Loss: 0.6876673698425293\n","Epoch: 1, Loss: 0.7025954127311707\n","Epoch: 1, Loss: 0.6934239268302917\n","Epoch: 1, Loss: 0.6248864531517029\n","Epoch: 1, Loss: 0.699402391910553\n","Epoch: 1, Loss: 0.7220056056976318\n","Epoch: 1, Loss: 0.6911011934280396\n","Epoch: 1, Loss: 0.7352758049964905\n","Epoch: 1, Loss: 0.7594888806343079\n","Epoch: 1, Loss: 0.6979703903198242\n","Epoch: 1, Loss: 0.6910786628723145\n","Epoch: 1, Loss: 0.7391164898872375\n","Epoch: 1, Loss: 0.7027335166931152\n","Epoch: 1, Loss: 0.6937689185142517\n","Epoch: 1, Loss: 0.6157855987548828\n","Epoch: 1, Loss: 0.7167096734046936\n","Epoch: 1, Loss: 0.6699459552764893\n","Epoch: 1, Loss: 0.6910051107406616\n","Epoch: 1, Loss: 0.7782579064369202\n","Epoch: 1, Loss: 0.7195169925689697\n","Epoch: 1, Loss: 0.6643522381782532\n","Epoch: 1, Loss: 0.7294191122055054\n","Epoch: 1, Loss: 0.6118081212043762\n","Epoch: 1, Loss: 0.6387020349502563\n","Epoch: 1, Loss: 0.7373911142349243\n","Epoch: 1, Loss: 0.7127698659896851\n","Epoch: 1, Loss: 0.7013345956802368\n","Epoch: 1, Loss: 0.8477359414100647\n","Epoch: 1, Loss: 0.7653245329856873\n","Epoch: 1, Loss: 0.6489518284797668\n","Epoch: 1, Loss: 0.6953399181365967\n","Epoch: 1, Loss: 0.6834904551506042\n","Epoch: 1, Loss: 0.7617985606193542\n","Epoch: 1, Loss: 0.7210688591003418\n","Epoch: 1, Loss: 0.6292058229446411\n","Epoch: 1, Loss: 0.7592102289199829\n","Epoch: 1, Loss: 0.6894168853759766\n","Epoch: 1, Loss: 0.7635787725448608\n","Epoch: 1, Loss: 0.7012101411819458\n","Epoch: 1, Loss: 0.7794430255889893\n","Epoch: 1, Loss: 0.7955259680747986\n","Epoch: 1, Loss: 0.720087468624115\n","Epoch: 1, Loss: 0.6829835772514343\n","Epoch: 1, Loss: 0.7767730951309204\n","Epoch: 1, Loss: 0.766910195350647\n","Epoch: 1, Loss: 0.6756342649459839\n","Epoch: 1, Loss: 0.7987017631530762\n","Epoch: 1, Loss: 0.6810449361801147\n","Epoch: 1, Loss: 0.7157514691352844\n","Epoch: 1, Loss: 0.6761146187782288\n","Epoch: 1, Loss: 0.6371897459030151\n","Epoch: 1, Loss: 0.6199395060539246\n","Epoch: 1, Loss: 0.6530686616897583\n","Epoch: 1, Loss: 0.63858962059021\n","Epoch: 1, Loss: 0.6762607097625732\n","Epoch: 1, Loss: 0.6224882006645203\n","Epoch: 1, Loss: 0.6906737089157104\n","Epoch: 1, Loss: 0.7051175832748413\n","Epoch: 1, Loss: 0.6034388542175293\n","Epoch: 1, Loss: 0.7302882075309753\n","Epoch: 1, Loss: 0.8215311169624329\n","Epoch: 1, Loss: 0.7329692840576172\n","Epoch: 1, Loss: 0.6882306933403015\n","Epoch: 1, Loss: 0.7032164335250854\n","Epoch: 1, Loss: 0.7910802364349365\n","Epoch: 1, Loss: 0.7219219207763672\n","Epoch: 1, Loss: 0.6318419575691223\n","Epoch: 1, Loss: 0.7648977041244507\n","Epoch: 1, Loss: 0.6398128271102905\n","Epoch: 1, Loss: 0.7604645490646362\n","Epoch: 1, Loss: 0.769044816493988\n","Epoch: 1, Loss: 0.7532521486282349\n","Epoch: 1, Loss: 0.6528518199920654\n","Epoch: 1, Loss: 0.7094293832778931\n","Epoch: 1, Loss: 0.7128934264183044\n","Epoch: 1, Loss: 0.7723783850669861\n","Epoch: 1, Loss: 0.6917275190353394\n","Epoch: 1, Loss: 0.6646217703819275\n","Epoch: 1, Loss: 0.7100369930267334\n","Epoch: 1, Loss: 0.6450034976005554\n","Epoch: 1, Loss: 0.6744176745414734\n","Epoch: 1, Loss: 0.7398455142974854\n","Epoch: 1, Loss: 0.7396569848060608\n","Epoch: 1, Loss: 0.6956416964530945\n","Epoch: 1, Loss: 0.7194775342941284\n","Epoch: 1, Loss: 0.7775508165359497\n","Epoch: 1, Loss: 0.6946349740028381\n","Epoch: 1, Loss: 0.6517826914787292\n","Epoch: 1, Loss: 0.6159693598747253\n","Epoch: 1, Loss: 0.7005731463432312\n","Epoch: 1, Loss: 0.664766788482666\n","Epoch: 1, Loss: 0.662919282913208\n","Epoch: 1, Loss: 0.6596188545227051\n","Epoch: 1, Loss: 0.6667201519012451\n","Epoch: 1, Loss: 0.7067036032676697\n","Epoch: 1, Loss: 0.7144331932067871\n","Epoch: 1, Loss: 0.6284536123275757\n","Epoch: 1, Loss: 0.6940248012542725\n","Epoch: 1, Loss: 0.8752288818359375\n","Epoch: 1, Loss: 0.5361303687095642\n","Epoch: 1, Loss: 0.6672552824020386\n","Epoch: 1, Loss: 0.8310313820838928\n","Epoch: 1, Loss: 0.7962976098060608\n","Epoch: 1, Loss: 0.640816330909729\n","Epoch: 1, Loss: 0.5498719215393066\n","Epoch: 1, Loss: 0.6896106600761414\n","Epoch: 1, Loss: 0.6945210695266724\n","Epoch: 1, Loss: 0.682239294052124\n","Epoch: 1, Loss: 0.7248175144195557\n","Epoch: 1, Loss: 0.6492149829864502\n","Epoch: 1, Loss: 0.6275925636291504\n","Epoch: 1, Loss: 0.6101066470146179\n","Epoch: 1, Loss: 0.7290398478507996\n","Epoch: 1, Loss: 0.6460629105567932\n","Epoch: 1, Loss: 0.7415191531181335\n","Epoch: 1, Loss: 0.6521874666213989\n","Epoch: 1, Loss: 0.772327721118927\n","Epoch: 1, Loss: 0.7364121675491333\n","Epoch: 1, Loss: 0.5948583483695984\n","Epoch: 1, Loss: 0.6666320562362671\n","Epoch: 1, Loss: 0.7707818746566772\n","Epoch: 1, Loss: 0.647383987903595\n","Epoch: 1, Loss: 0.66542649269104\n","Epoch: 1, Loss: 0.6032848358154297\n","Epoch: 1, Loss: 0.661173403263092\n","Epoch: 1, Loss: 0.7561757564544678\n","Epoch: 1, Loss: 0.6971116065979004\n","Epoch: 1, Loss: 0.725454568862915\n","Epoch: 1, Loss: 0.7625224590301514\n","Epoch: 1, Loss: 0.6723855137825012\n","Epoch: 1, Loss: 0.6642230153083801\n","Epoch: 1, Loss: 0.7740809917449951\n","Epoch: 1, Loss: 0.7252130508422852\n","Epoch: 1, Loss: 0.7433640956878662\n","Epoch: 1, Loss: 0.6535146236419678\n","Epoch: 1, Loss: 0.662242591381073\n","Epoch: 1, Loss: 0.6399841904640198\n","Epoch: 1, Loss: 0.7000975012779236\n","Epoch: 1, Loss: 0.6675446629524231\n","Epoch: 1, Loss: 0.7948792576789856\n","Epoch: 1, Loss: 0.6958654522895813\n","Epoch: 1, Loss: 0.656050443649292\n","Epoch: 1, Loss: 0.6563650369644165\n","Epoch: 1, Loss: 0.697046160697937\n","Epoch: 1, Loss: 0.6181626915931702\n","Epoch: 1, Loss: 0.7993203401565552\n","Epoch: 1, Loss: 0.795716404914856\n","Epoch: 1, Loss: 0.8278073668479919\n","Epoch: 1, Loss: 0.6496558785438538\n","Epoch: 1, Loss: 0.7776466608047485\n","Epoch: 1, Loss: 0.7761925458908081\n","Epoch: 1, Loss: 0.7177460193634033\n","Epoch: 1, Loss: 0.6995384097099304\n","Epoch: 1, Loss: 0.696286678314209\n","Epoch: 1, Loss: 0.6874198317527771\n","Epoch: 1, Loss: 0.6843743920326233\n","Epoch: 1, Loss: 0.6863822340965271\n","Epoch: 1, Loss: 0.7157638669013977\n","Epoch: 1, Loss: 0.6884485483169556\n","Epoch: 1, Loss: 0.6781785488128662\n","Epoch: 1, Loss: 0.6967756748199463\n","Epoch: 1, Loss: 0.716882586479187\n","Epoch: 1, Loss: 0.745218813419342\n","Epoch: 1, Loss: 0.6968115568161011\n","Epoch: 1, Loss: 0.7026492953300476\n","Epoch: 1, Loss: 0.740771472454071\n","Epoch: 1, Loss: 0.6910686492919922\n","Epoch: 1, Loss: 0.7111386656761169\n","Epoch: 1, Loss: 0.7121666669845581\n","Epoch: 1, Loss: 0.745664656162262\n","Epoch: 1, Loss: 0.7352197170257568\n","Epoch: 1, Loss: 0.6950135231018066\n","Epoch: 1, Loss: 0.6910950541496277\n","Epoch: 1, Loss: 0.6752076148986816\n","Epoch: 1, Loss: 0.7286866903305054\n","Epoch: 1, Loss: 0.6421207189559937\n","Epoch: 1, Loss: 0.7149186134338379\n","Epoch: 1, Loss: 0.7012860178947449\n","Epoch: 1, Loss: 0.6504459381103516\n","Epoch: 1, Loss: 0.6521443128585815\n","Epoch: 1, Loss: 0.8148442506790161\n","Epoch: 1, Loss: 0.6394020915031433\n","Epoch: 1, Loss: 0.635875940322876\n","Epoch: 1, Loss: 0.7625076770782471\n","Epoch: 1, Loss: 0.6757593154907227\n","Epoch: 1, Loss: 0.7660405039787292\n","Epoch: 1, Loss: 0.6345804929733276\n","Epoch: 1, Loss: 0.555875301361084\n","Epoch: 1, Loss: 0.5818675756454468\n","Epoch: 1, Loss: 0.7786155939102173\n","Epoch: 1, Loss: 0.677767276763916\n","Epoch: 1, Loss: 0.7351268529891968\n","Epoch: 1, Loss: 0.6519983410835266\n","Epoch: 1, Loss: 0.7502095699310303\n","Epoch: 1, Loss: 0.5824003219604492\n","Epoch: 1, Loss: 0.7935676574707031\n","Epoch: 1, Loss: 0.7486393451690674\n","Epoch: 1, Loss: 0.5934650897979736\n","Epoch: 1, Loss: 0.6757611036300659\n","Epoch: 1, Loss: 0.6514303684234619\n","Epoch: 1, Loss: 0.7545243501663208\n","Epoch: 1, Loss: 0.8002962470054626\n","Epoch: 1, Loss: 0.6667526364326477\n","Epoch: 1, Loss: 0.698433518409729\n","Epoch: 1, Loss: 0.6699333190917969\n","Epoch: 1, Loss: 0.712224543094635\n","Epoch: 1, Loss: 0.7313910126686096\n","Epoch: 1, Loss: 0.675829291343689\n","Epoch: 1, Loss: 0.657935380935669\n","Epoch: 1, Loss: 0.6928825378417969\n","Epoch: 1, Loss: 0.7239848375320435\n","Epoch: 1, Loss: 0.7215743660926819\n","Epoch: 1, Loss: 0.734279990196228\n","Epoch: 1, Loss: 0.6953948736190796\n","Epoch: 1, Loss: 0.7030192613601685\n","Epoch: 1, Loss: 0.744539201259613\n","Epoch: 1, Loss: 0.7017806172370911\n","Epoch: 1, Loss: 0.8253552913665771\n","Epoch: 1, Loss: 0.6898515224456787\n","Epoch: 1, Loss: 0.749962568283081\n","Epoch: 1, Loss: 0.7301613092422485\n","Epoch: 1, Loss: 0.692607045173645\n","Epoch: 1, Loss: 0.7319074273109436\n","Epoch: 1, Loss: 0.7031053304672241\n","Epoch: 1, Loss: 0.6546858549118042\n","Epoch: 1, Loss: 0.7315354943275452\n","Epoch: 1, Loss: 0.7240140438079834\n","Epoch: 1, Loss: 0.6542792916297913\n","Epoch: 1, Loss: 0.7527145147323608\n","Epoch: 1, Loss: 0.6671179533004761\n","Epoch: 1, Loss: 0.6206636428833008\n","Epoch: 1, Loss: 0.7230067253112793\n","Epoch: 1, Loss: 0.737977147102356\n","Epoch: 1, Loss: 0.7319831252098083\n","Epoch: 1, Loss: 0.696657657623291\n","Epoch: 1, Loss: 0.6924351453781128\n","Epoch: 1, Loss: 0.6244972348213196\n","Epoch: 1, Loss: 0.689111053943634\n","Epoch: 1, Loss: 0.6179267764091492\n","Epoch: 1, Loss: 0.6821050047874451\n","Epoch: 1, Loss: 0.7645801305770874\n","Epoch: 1, Loss: 0.6825680732727051\n","Epoch: 1, Loss: 0.7174475789070129\n","Epoch: 1, Loss: 0.6801286339759827\n","Epoch: 1, Loss: 0.6760488152503967\n","Epoch: 1, Loss: 0.6748138666152954\n","Epoch: 1, Loss: 0.6886623501777649\n","Epoch: 1, Loss: 0.7019672989845276\n","Epoch: 1, Loss: 0.7269774079322815\n","Epoch: 1, Loss: 0.6696084141731262\n","Epoch: 1, Loss: 0.5951226949691772\n","Epoch: 1, Loss: 0.8010113835334778\n","Epoch: 1, Loss: 0.6315576434135437\n","Epoch: 1, Loss: 0.6479345560073853\n","Epoch: 1, Loss: 0.7244846820831299\n","Epoch: 1, Loss: 0.7974488735198975\n","Epoch: 1, Loss: 0.7256337404251099\n","Epoch: 1, Loss: 0.7698558568954468\n","Epoch: 1, Loss: 0.7081770896911621\n","Epoch: 1, Loss: 0.7796056270599365\n","Epoch: 1, Loss: 0.6402716636657715\n","Epoch: 1, Loss: 0.6563984751701355\n","Epoch: 1, Loss: 0.6616807579994202\n","Epoch: 1, Loss: 0.7299806475639343\n","Epoch: 1, Loss: 0.7083122730255127\n","Epoch: 1, Loss: 0.6759745478630066\n","Epoch: 1, Loss: 0.7318465113639832\n","Epoch: 1, Loss: 0.7869949340820312\n","Epoch: 1, Loss: 0.5973106026649475\n","Epoch: 1, Loss: 0.7166057229042053\n","Epoch: 1, Loss: 0.7144027948379517\n","Epoch: 1, Loss: 0.7159562706947327\n","Epoch: 1, Loss: 0.7422707080841064\n","Epoch: 1, Loss: 0.7808342576026917\n","Epoch: 1, Loss: 0.6501820087432861\n","Epoch: 1, Loss: 0.7041489481925964\n","Epoch: 1, Loss: 0.7510040998458862\n","Epoch: 1, Loss: 0.7315376400947571\n","Epoch: 1, Loss: 0.7093976140022278\n","Epoch: 1, Loss: 0.6996668577194214\n","Epoch: 1, Loss: 0.7077680826187134\n","Epoch: 1, Loss: 0.7139596939086914\n","Epoch: 1, Loss: 0.745858371257782\n","Epoch: 1, Loss: 0.7497356534004211\n","Epoch: 1, Loss: 0.6295077204704285\n","Epoch: 1, Loss: 0.6462451219558716\n","Epoch: 1, Loss: 0.7997225522994995\n","Epoch: 1, Loss: 0.805124819278717\n","Epoch: 1, Loss: 0.7379054427146912\n","Epoch: 1, Loss: 0.716661810874939\n","Epoch: 1, Loss: 0.7206961512565613\n","Epoch: 1, Loss: 0.7328858971595764\n","Epoch: 1, Loss: 0.6921356916427612\n","Epoch: 1, Loss: 0.7258701324462891\n","Epoch: 1, Loss: 0.6735565066337585\n","Epoch: 1, Loss: 0.7715066075325012\n","Epoch: 1, Loss: 0.645524263381958\n","Epoch: 1, Loss: 0.6984238624572754\n","Epoch: 1, Loss: 0.7390537858009338\n","Epoch: 1, Loss: 0.6783846616744995\n","Epoch: 1, Loss: 0.648892343044281\n","Epoch: 1, Loss: 0.6687083840370178\n","Epoch: 1, Loss: 0.719539225101471\n","Epoch: 1, Loss: 0.6616258025169373\n","Epoch: 1, Loss: 0.6641957759857178\n","Epoch: 1, Loss: 0.7238554954528809\n","Epoch: 1, Loss: 0.6683053374290466\n","Epoch: 1, Loss: 0.6914036273956299\n","Epoch: 1, Loss: 0.7427615523338318\n","Epoch: 1, Loss: 0.7578213214874268\n","Epoch: 1, Loss: 0.7126047015190125\n","Epoch: 1, Loss: 0.6840912699699402\n","Epoch: 1, Loss: 0.6354470252990723\n","Epoch: 1, Loss: 0.7203512787818909\n","Epoch: 1, Loss: 0.6217878460884094\n","Epoch: 1, Loss: 0.7083562612533569\n","Epoch: 1, Loss: 0.7418451905250549\n","Epoch: 1, Loss: 0.7050662040710449\n","Epoch: 1, Loss: 0.6744294166564941\n","Epoch: 1, Loss: 0.6411957740783691\n","Epoch: 1, Loss: 0.7144683599472046\n","Epoch: 1, Loss: 0.7114178538322449\n","Epoch: 1, Loss: 0.6764367818832397\n","Epoch: 1, Loss: 0.7152196168899536\n","Epoch: 1, Loss: 0.6558563709259033\n","Epoch: 1, Loss: 0.7235995531082153\n","Epoch: 1, Loss: 0.68092280626297\n","Epoch: 1, Loss: 0.7087174654006958\n","Epoch: 1, Loss: 0.6426931023597717\n","Epoch: 1, Loss: 0.6801501512527466\n","Epoch: 1, Loss: 0.7096179723739624\n","Epoch: 1, Loss: 0.6353164911270142\n","Epoch: 1, Loss: 0.6515529751777649\n","Epoch: 1, Loss: 0.7251410484313965\n","Epoch: 1, Loss: 0.7226583957672119\n","Epoch: 1, Loss: 0.7801576852798462\n","Epoch: 1, Loss: 0.7031846046447754\n","Epoch: 1, Loss: 0.7122454047203064\n","Epoch: 1, Loss: 0.6905466914176941\n","Epoch: 1, Loss: 0.7420011758804321\n","Epoch: 1, Loss: 0.672872006893158\n","Epoch: 1, Loss: 0.8468053340911865\n","Epoch: 1, Loss: 0.6547263264656067\n","Epoch: 1, Loss: 0.6887185573577881\n","Epoch: 1, Loss: 0.6626492142677307\n","Epoch: 1, Loss: 0.7106721997261047\n","Epoch: 1, Loss: 0.6992820501327515\n","Epoch: 1, Loss: 0.6850924491882324\n","Epoch: 1, Loss: 0.6818792819976807\n","Epoch: 1, Loss: 0.6833207607269287\n","Epoch: 1, Loss: 0.7298563718795776\n","Epoch: 1, Loss: 0.7235923409461975\n","Epoch: 1, Loss: 0.728961706161499\n","Epoch: 1, Loss: 0.7025356292724609\n","Epoch: 1, Loss: 0.6682705879211426\n","Epoch: 1, Loss: 0.7274390459060669\n","Epoch: 1, Loss: 0.6790350675582886\n","Epoch: 1, Loss: 0.6442639827728271\n","Epoch: 1, Loss: 0.7261933088302612\n","Epoch: 1, Loss: 0.6939724087715149\n","Epoch: 1, Loss: 0.6779934167861938\n","Epoch: 1, Loss: 0.6776789426803589\n","Epoch: 1, Loss: 0.6887520551681519\n","Epoch: 1, Loss: 0.6869987845420837\n","Epoch: 1, Loss: 0.7125301957130432\n","Epoch: 1, Loss: 0.6910424828529358\n","Epoch: 1, Loss: 0.7895458936691284\n","Epoch: 1, Loss: 0.8737625479698181\n","Epoch: 1, Loss: 0.6267894506454468\n","Epoch: 1, Loss: 0.6918221116065979\n","Epoch: 1, Loss: 0.7307330965995789\n","Epoch: 1, Loss: 0.6884981393814087\n","Epoch: 1, Loss: 0.7013161778450012\n","Epoch: 1, Loss: 0.7550811171531677\n","Epoch: 1, Loss: 0.753495991230011\n","Epoch: 1, Loss: 0.6932435035705566\n","Epoch: 1, Loss: 0.6197974681854248\n","Epoch: 1, Loss: 0.7256211042404175\n","Epoch: 1, Loss: 0.7270290851593018\n","Epoch: 1, Loss: 0.731475293636322\n","Epoch: 1, Loss: 0.6677058935165405\n","Epoch: 1, Loss: 0.7060861587524414\n","Epoch: 1, Loss: 0.6825495958328247\n","Epoch: 1, Loss: 0.7024438977241516\n","Epoch: 1, Loss: 0.7301836013793945\n","Epoch: 1, Loss: 0.7362971305847168\n","Epoch: 1, Loss: 0.710385262966156\n","Epoch: 1, Loss: 0.7080704569816589\n","Epoch: 1, Loss: 0.715348482131958\n","Epoch: 1, Loss: 0.6869633793830872\n","Epoch: 1, Loss: 0.6668848991394043\n","Epoch: 1, Loss: 0.7233030200004578\n","Epoch: 1, Loss: 0.651985764503479\n","Epoch: 1, Loss: 0.7251760959625244\n","Epoch: 1, Loss: 0.6624385714530945\n","Epoch: 1, Loss: 0.6943709850311279\n","Epoch: 1, Loss: 0.7033811211585999\n","Epoch: 1, Loss: 0.7240363359451294\n","Epoch: 1, Loss: 0.7054092884063721\n","Epoch: 1, Loss: 0.7243423461914062\n","Epoch: 1, Loss: 0.7398462891578674\n","Epoch: 1, Loss: 0.6965380907058716\n","Epoch: 1, Loss: 0.7106142640113831\n","Epoch: 1, Loss: 0.7300048470497131\n","Epoch: 1, Loss: 0.7169951796531677\n","Epoch: 1, Loss: 0.7290328741073608\n","Epoch: 1, Loss: 0.6683235764503479\n","Epoch: 1, Loss: 0.7242091298103333\n","Epoch: 1, Loss: 0.7598696351051331\n","Epoch: 1, Loss: 0.7341927289962769\n","Epoch: 1, Loss: 0.6635998487472534\n","Epoch: 1, Loss: 0.7076464891433716\n","Epoch: 1, Loss: 0.7097295522689819\n","Epoch: 1, Loss: 0.7600587606430054\n","Epoch: 1, Loss: 0.6938638091087341\n","Epoch: 1, Loss: 0.7170847058296204\n","Epoch: 1, Loss: 0.7058889269828796\n","Epoch: 1, Loss: 0.6812264919281006\n","Epoch: 1, Loss: 0.6962262988090515\n","Epoch: 1, Loss: 0.6801512241363525\n","Epoch: 1, Loss: 0.6829488277435303\n","Epoch: 1, Loss: 0.7122073769569397\n","Epoch: 1, Loss: 0.7213259339332581\n","Epoch: 1, Loss: 0.6758792996406555\n","Epoch: 1, Loss: 0.6343681812286377\n","Epoch: 1, Loss: 0.7399407029151917\n","Epoch: 1, Loss: 0.7392122149467468\n","Epoch: 1, Loss: 0.6970646977424622\n","Epoch: 1, Loss: 0.6393361687660217\n","Epoch: 1, Loss: 0.745384156703949\n","Epoch: 1, Loss: 0.6076611876487732\n","Epoch: 1, Loss: 0.7050004005432129\n","Epoch: 1, Loss: 0.743057131767273\n","Epoch: 1, Loss: 0.7585301399230957\n","Epoch: 1, Loss: 0.5933759212493896\n","Epoch: 1, Loss: 0.8347938060760498\n","Epoch: 1, Loss: 0.7803236246109009\n","Epoch: 1, Loss: 0.6619434356689453\n","Epoch: 1, Loss: 0.718916118144989\n","Epoch: 1, Loss: 0.7732031345367432\n","Epoch: 1, Loss: 0.6711059808731079\n","Epoch: 1, Loss: 0.6786152720451355\n","Epoch: 1, Loss: 0.6728090047836304\n","Epoch: 1, Loss: 0.6669631600379944\n","Epoch: 1, Loss: 0.6515414118766785\n","Epoch: 1, Loss: 0.6909364461898804\n","Epoch: 1, Loss: 0.7160823345184326\n","Epoch: 1, Loss: 0.7572100162506104\n","Epoch: 1, Loss: 0.6849591135978699\n","Epoch: 1, Loss: 0.7006500363349915\n","Epoch: 1, Loss: 0.6715161800384521\n","Epoch: 1, Loss: 0.6895697116851807\n","Epoch: 1, Loss: 0.6810266375541687\n","Epoch: 1, Loss: 0.6932198405265808\n","Epoch: 1, Loss: 0.6799356937408447\n","Epoch: 1, Loss: 0.7108017206192017\n","Epoch: 1, Loss: 0.6767233610153198\n","Epoch: 1, Loss: 0.6676061749458313\n","Epoch: 1, Loss: 0.6552935242652893\n","Epoch: 1, Loss: 0.7238957285881042\n","Epoch: 1, Loss: 0.6600847840309143\n","Epoch: 1, Loss: 0.6720356941223145\n","Epoch: 1, Loss: 0.6569154262542725\n","Epoch: 1, Loss: 0.7107153534889221\n","Epoch: 1, Loss: 0.6842285394668579\n","Epoch: 1, Loss: 0.6594043970108032\n","Epoch: 1, Loss: 0.8154300451278687\n","Epoch: 1, Loss: 0.7401922941207886\n","Epoch: 1, Loss: 0.7067776322364807\n","Epoch: 1, Loss: 0.6573657989501953\n","Epoch: 1, Loss: 0.7220150232315063\n","Epoch: 1, Loss: 0.7028736472129822\n","Epoch: 1, Loss: 0.7269977927207947\n","Epoch: 1, Loss: 0.7887030839920044\n","Epoch: 1, Loss: 0.7183392643928528\n","Epoch: 1, Loss: 0.6541973948478699\n","Epoch: 1, Loss: 0.6919223070144653\n","Epoch: 1, Loss: 0.8398553729057312\n","Epoch: 1, Loss: 0.6919457316398621\n","Epoch: 2, Loss: 0.6676433682441711\n","Epoch: 2, Loss: 0.7029228210449219\n","Epoch: 2, Loss: 0.6414576768875122\n","Epoch: 2, Loss: 0.7504396438598633\n","Epoch: 2, Loss: 0.6799057126045227\n","Epoch: 2, Loss: 0.680987536907196\n","Epoch: 2, Loss: 0.7187656760215759\n","Epoch: 2, Loss: 0.6977758407592773\n","Epoch: 2, Loss: 0.6644585728645325\n","Epoch: 2, Loss: 0.7287032604217529\n","Epoch: 2, Loss: 0.7153769731521606\n","Epoch: 2, Loss: 0.6838783025741577\n","Epoch: 2, Loss: 0.6565642356872559\n","Epoch: 2, Loss: 0.6868888139724731\n","Epoch: 2, Loss: 0.6761980056762695\n","Epoch: 2, Loss: 0.8405333757400513\n","Epoch: 2, Loss: 0.7264657616615295\n","Epoch: 2, Loss: 0.7123942971229553\n","Epoch: 2, Loss: 0.6957153081893921\n","Epoch: 2, Loss: 0.6887215971946716\n","Epoch: 2, Loss: 0.7028146386146545\n","Epoch: 2, Loss: 0.7589699625968933\n","Epoch: 2, Loss: 0.6917333006858826\n","Epoch: 2, Loss: 0.6391271352767944\n","Epoch: 2, Loss: 0.7038765549659729\n","Epoch: 2, Loss: 0.6777826547622681\n","Epoch: 2, Loss: 0.7379542589187622\n","Epoch: 2, Loss: 0.6465551853179932\n","Epoch: 2, Loss: 0.7006006836891174\n","Epoch: 2, Loss: 0.6988323926925659\n","Epoch: 2, Loss: 0.6812747716903687\n","Epoch: 2, Loss: 0.6929215788841248\n","Epoch: 2, Loss: 0.6909649968147278\n","Epoch: 2, Loss: 0.7157090306282043\n","Epoch: 2, Loss: 0.7291878461837769\n","Epoch: 2, Loss: 0.6488741040229797\n","Epoch: 2, Loss: 0.6751033663749695\n","Epoch: 2, Loss: 0.733453631401062\n","Epoch: 2, Loss: 0.7856597900390625\n","Epoch: 2, Loss: 0.7542835474014282\n","Epoch: 2, Loss: 0.5929445028305054\n","Epoch: 2, Loss: 0.6901307106018066\n","Epoch: 2, Loss: 0.8516058325767517\n","Epoch: 2, Loss: 0.7943914532661438\n","Epoch: 2, Loss: 0.7799338698387146\n","Epoch: 2, Loss: 0.7593402862548828\n","Epoch: 2, Loss: 0.7253954410552979\n","Epoch: 2, Loss: 0.6742655038833618\n","Epoch: 2, Loss: 0.6578401923179626\n","Epoch: 2, Loss: 0.7446448802947998\n","Epoch: 2, Loss: 0.6783478260040283\n","Epoch: 2, Loss: 0.6731357574462891\n","Epoch: 2, Loss: 0.6513863205909729\n","Epoch: 2, Loss: 0.6731451749801636\n","Epoch: 2, Loss: 0.6861411333084106\n","Epoch: 2, Loss: 0.6580104827880859\n","Epoch: 2, Loss: 0.6999940276145935\n","Epoch: 2, Loss: 0.6978009939193726\n","Epoch: 2, Loss: 0.6513630151748657\n","Epoch: 2, Loss: 0.6790900230407715\n","Epoch: 2, Loss: 0.7160208225250244\n","Epoch: 2, Loss: 0.8202338218688965\n","Epoch: 2, Loss: 0.6905120015144348\n","Epoch: 2, Loss: 0.6939423680305481\n","Epoch: 2, Loss: 0.7397140860557556\n","Epoch: 2, Loss: 0.7580626606941223\n","Epoch: 2, Loss: 0.7232081890106201\n","Epoch: 2, Loss: 0.6735476851463318\n","Epoch: 2, Loss: 0.7628424167633057\n","Epoch: 2, Loss: 0.698113203048706\n","Epoch: 2, Loss: 0.7656144499778748\n","Epoch: 2, Loss: 0.6628404855728149\n","Epoch: 2, Loss: 0.7024528980255127\n","Epoch: 2, Loss: 0.7091050148010254\n","Epoch: 2, Loss: 0.6855276226997375\n","Epoch: 2, Loss: 0.7130571007728577\n","Epoch: 2, Loss: 0.7442930936813354\n","Epoch: 2, Loss: 0.6483521461486816\n","Epoch: 2, Loss: 0.667299211025238\n","Epoch: 2, Loss: 0.7055425047874451\n","Epoch: 2, Loss: 0.6633533239364624\n","Epoch: 2, Loss: 0.7612304091453552\n","Epoch: 2, Loss: 0.6858932375907898\n","Epoch: 2, Loss: 0.6904679536819458\n","Epoch: 2, Loss: 0.7006971836090088\n","Epoch: 2, Loss: 0.6809742450714111\n","Epoch: 2, Loss: 0.6623356938362122\n","Epoch: 2, Loss: 0.6850893497467041\n","Epoch: 2, Loss: 0.6678866744041443\n","Epoch: 2, Loss: 0.6814788579940796\n","Epoch: 2, Loss: 0.7210255861282349\n","Epoch: 2, Loss: 0.7575531601905823\n","Epoch: 2, Loss: 0.6871640086174011\n","Epoch: 2, Loss: 0.6117158532142639\n","Epoch: 2, Loss: 0.6811288595199585\n","Epoch: 2, Loss: 0.7516529560089111\n","Epoch: 2, Loss: 0.721479594707489\n","Epoch: 2, Loss: 0.6976370811462402\n","Epoch: 2, Loss: 0.6988841891288757\n","Epoch: 2, Loss: 0.7354037761688232\n","Epoch: 2, Loss: 0.6833817362785339\n","Epoch: 2, Loss: 0.7253739833831787\n","Epoch: 2, Loss: 0.7135431170463562\n","Epoch: 2, Loss: 0.7316961884498596\n","Epoch: 2, Loss: 0.6501067876815796\n","Epoch: 2, Loss: 0.6679677963256836\n","Epoch: 2, Loss: 0.6917819976806641\n","Epoch: 2, Loss: 0.7627221345901489\n","Epoch: 2, Loss: 0.7100573778152466\n","Epoch: 2, Loss: 0.7344530820846558\n","Epoch: 2, Loss: 0.6473717093467712\n","Epoch: 2, Loss: 0.767947793006897\n","Epoch: 2, Loss: 0.6863527297973633\n","Epoch: 2, Loss: 0.7093601226806641\n","Epoch: 2, Loss: 0.6716293096542358\n","Epoch: 2, Loss: 0.6672961711883545\n","Epoch: 2, Loss: 0.6621900796890259\n","Epoch: 2, Loss: 0.6958521604537964\n","Epoch: 2, Loss: 0.6775032877922058\n","Epoch: 2, Loss: 0.6886225938796997\n","Epoch: 2, Loss: 0.7067872881889343\n","Epoch: 2, Loss: 0.7885128259658813\n","Epoch: 2, Loss: 0.7750032544136047\n","Epoch: 2, Loss: 0.6364814639091492\n","Epoch: 2, Loss: 0.7308341264724731\n","Epoch: 2, Loss: 0.6969044804573059\n","Epoch: 2, Loss: 0.6622335314750671\n","Epoch: 2, Loss: 0.698826253414154\n","Epoch: 2, Loss: 0.6739157438278198\n","Epoch: 2, Loss: 0.712100625038147\n","Epoch: 2, Loss: 0.7482761144638062\n","Epoch: 2, Loss: 0.6708995699882507\n","Epoch: 2, Loss: 0.6500676870346069\n","Epoch: 2, Loss: 0.7069054841995239\n","Epoch: 2, Loss: 0.6534004807472229\n","Epoch: 2, Loss: 0.7290191650390625\n","Epoch: 2, Loss: 0.7619526386260986\n","Epoch: 2, Loss: 0.6720014810562134\n","Epoch: 2, Loss: 0.6740322113037109\n","Epoch: 2, Loss: 0.6139565706253052\n","Epoch: 2, Loss: 0.70570307970047\n","Epoch: 2, Loss: 0.6616051197052002\n","Epoch: 2, Loss: 0.7126525640487671\n","Epoch: 2, Loss: 0.6063169240951538\n","Epoch: 2, Loss: 0.7299081087112427\n","Epoch: 2, Loss: 0.7410430908203125\n","Epoch: 2, Loss: 0.7482889294624329\n","Epoch: 2, Loss: 0.6512107253074646\n","Epoch: 2, Loss: 0.7648646831512451\n","Epoch: 2, Loss: 0.7987362146377563\n","Epoch: 2, Loss: 0.7634877562522888\n","Epoch: 2, Loss: 0.8555657267570496\n","Epoch: 2, Loss: 0.7284108400344849\n","Epoch: 2, Loss: 0.7360112071037292\n","Epoch: 2, Loss: 0.6986604928970337\n","Epoch: 2, Loss: 0.6547921895980835\n","Epoch: 2, Loss: 0.6823306083679199\n","Epoch: 2, Loss: 0.7097281217575073\n","Epoch: 2, Loss: 0.6769872307777405\n","Epoch: 2, Loss: 0.6902268528938293\n","Epoch: 2, Loss: 0.7130967378616333\n","Epoch: 2, Loss: 0.6934576034545898\n","Epoch: 2, Loss: 0.6501240730285645\n","Epoch: 2, Loss: 0.6772056221961975\n","Epoch: 2, Loss: 0.6951417326927185\n","Epoch: 2, Loss: 0.7106755971908569\n","Epoch: 2, Loss: 0.6925715208053589\n","Epoch: 2, Loss: 0.7606107592582703\n","Epoch: 2, Loss: 0.8722067475318909\n","Epoch: 2, Loss: 0.6565914154052734\n","Epoch: 2, Loss: 0.6269403100013733\n","Epoch: 2, Loss: 0.7463996410369873\n","Epoch: 2, Loss: 0.649257242679596\n","Epoch: 2, Loss: 0.7506977319717407\n","Epoch: 2, Loss: 0.6486321687698364\n","Epoch: 2, Loss: 0.7179359197616577\n","Epoch: 2, Loss: 0.7428181171417236\n","Epoch: 2, Loss: 0.7394678592681885\n","Epoch: 2, Loss: 0.6963357329368591\n","Epoch: 2, Loss: 0.6917564868927002\n","Epoch: 2, Loss: 0.7254354953765869\n","Epoch: 2, Loss: 0.7113597989082336\n","Epoch: 2, Loss: 0.7579725980758667\n","Epoch: 2, Loss: 0.6857024431228638\n","Epoch: 2, Loss: 0.6690036058425903\n","Epoch: 2, Loss: 0.6712275147438049\n","Epoch: 2, Loss: 0.7028495073318481\n","Epoch: 2, Loss: 0.7060843706130981\n","Epoch: 2, Loss: 0.7134400010108948\n","Epoch: 2, Loss: 0.7009646892547607\n","Epoch: 2, Loss: 0.6933154463768005\n","Epoch: 2, Loss: 0.7099158763885498\n","Epoch: 2, Loss: 0.6760565042495728\n","Epoch: 2, Loss: 0.64166659116745\n","Epoch: 2, Loss: 0.6804593801498413\n","Epoch: 2, Loss: 0.6974081993103027\n","Epoch: 2, Loss: 0.6639933586120605\n","Epoch: 2, Loss: 0.6942941546440125\n","Epoch: 2, Loss: 0.7211549878120422\n","Epoch: 2, Loss: 0.8482234477996826\n","Epoch: 2, Loss: 0.717685878276825\n","Epoch: 2, Loss: 0.7100131511688232\n","Epoch: 2, Loss: 0.7297670245170593\n","Epoch: 2, Loss: 0.6614395380020142\n","Epoch: 2, Loss: 0.7018212080001831\n","Epoch: 2, Loss: 0.7773887515068054\n","Epoch: 2, Loss: 0.6795332431793213\n","Epoch: 2, Loss: 0.6573460698127747\n","Epoch: 2, Loss: 0.6862127780914307\n","Epoch: 2, Loss: 0.7089785933494568\n","Epoch: 2, Loss: 0.7141691446304321\n","Epoch: 2, Loss: 0.6794977784156799\n","Epoch: 2, Loss: 0.7114781141281128\n","Epoch: 2, Loss: 0.6992864608764648\n","Epoch: 2, Loss: 0.7089008092880249\n","Epoch: 2, Loss: 0.6666369438171387\n","Epoch: 2, Loss: 0.7015011310577393\n","Epoch: 2, Loss: 0.699243426322937\n","Epoch: 2, Loss: 0.762814998626709\n","Epoch: 2, Loss: 0.7294517755508423\n","Epoch: 2, Loss: 0.7027231454849243\n","Epoch: 2, Loss: 0.6603021025657654\n","Epoch: 2, Loss: 0.6575394868850708\n","Epoch: 2, Loss: 0.6795238256454468\n","Epoch: 2, Loss: 0.7535794377326965\n","Epoch: 2, Loss: 0.7175903916358948\n","Epoch: 2, Loss: 0.7134882211685181\n","Epoch: 2, Loss: 0.6344422101974487\n","Epoch: 2, Loss: 0.710616409778595\n","Epoch: 2, Loss: 0.7281219363212585\n","Epoch: 2, Loss: 0.6585685610771179\n","Epoch: 2, Loss: 0.6838293671607971\n","Epoch: 2, Loss: 0.6938342452049255\n","Epoch: 2, Loss: 0.6711018085479736\n","Epoch: 2, Loss: 0.6705912947654724\n","Epoch: 2, Loss: 0.716840922832489\n","Epoch: 2, Loss: 0.6985076665878296\n","Epoch: 2, Loss: 0.7346588373184204\n","Epoch: 2, Loss: 0.7199463248252869\n","Epoch: 2, Loss: 0.6637520790100098\n","Epoch: 2, Loss: 0.6682186126708984\n","Epoch: 2, Loss: 0.7198219299316406\n","Epoch: 2, Loss: 0.648327112197876\n","Epoch: 2, Loss: 0.6658200025558472\n","Epoch: 2, Loss: 0.7328041791915894\n","Epoch: 2, Loss: 0.6762914061546326\n","Epoch: 2, Loss: 0.6021640300750732\n","Epoch: 2, Loss: 0.6809946894645691\n","Epoch: 2, Loss: 0.66672682762146\n","Epoch: 2, Loss: 0.7020885348320007\n","Epoch: 2, Loss: 0.7936349511146545\n","Epoch: 2, Loss: 0.705073356628418\n","Epoch: 2, Loss: 0.6813738346099854\n","Epoch: 2, Loss: 0.8062180280685425\n","Epoch: 2, Loss: 0.7129748463630676\n","Epoch: 2, Loss: 0.7085381150245667\n","Epoch: 2, Loss: 0.7015369534492493\n","Epoch: 2, Loss: 0.64364093542099\n","Epoch: 2, Loss: 0.7062163949012756\n","Epoch: 2, Loss: 0.733098030090332\n","Epoch: 2, Loss: 0.683610200881958\n","Epoch: 2, Loss: 0.6999081373214722\n","Epoch: 2, Loss: 0.7261171340942383\n","Epoch: 2, Loss: 0.6973220705986023\n","Epoch: 2, Loss: 0.7346356511116028\n","Epoch: 2, Loss: 0.7220808863639832\n","Epoch: 2, Loss: 0.7403643131256104\n","Epoch: 2, Loss: 0.7033741474151611\n","Epoch: 2, Loss: 0.7092393636703491\n","Epoch: 2, Loss: 0.7042245268821716\n","Epoch: 2, Loss: 0.6660502552986145\n","Epoch: 2, Loss: 0.6982050538063049\n","Epoch: 2, Loss: 0.6783131957054138\n","Epoch: 2, Loss: 0.6827274560928345\n","Epoch: 2, Loss: 0.7049295902252197\n","Epoch: 2, Loss: 0.6998651027679443\n","Epoch: 2, Loss: 0.6895847320556641\n","Epoch: 2, Loss: 0.7055906653404236\n","Epoch: 2, Loss: 0.6917021870613098\n","Epoch: 2, Loss: 0.6813443303108215\n","Epoch: 2, Loss: 0.6919010281562805\n","Epoch: 2, Loss: 0.6822021007537842\n","Epoch: 2, Loss: 0.7039266228675842\n","Epoch: 2, Loss: 0.7705250978469849\n","Epoch: 2, Loss: 0.7005168199539185\n","Epoch: 2, Loss: 0.7073010206222534\n","Epoch: 2, Loss: 0.718698263168335\n","Epoch: 2, Loss: 0.6743360161781311\n","Epoch: 2, Loss: 0.7445992827415466\n","Epoch: 2, Loss: 0.6966251134872437\n","Epoch: 2, Loss: 0.6810033321380615\n","Epoch: 2, Loss: 0.6504595279693604\n","Epoch: 2, Loss: 0.710471510887146\n","Epoch: 2, Loss: 0.7508165240287781\n","Epoch: 2, Loss: 0.6846554279327393\n","Epoch: 2, Loss: 0.6803895831108093\n","Epoch: 2, Loss: 0.7220960855484009\n","Epoch: 2, Loss: 0.7306344509124756\n","Epoch: 2, Loss: 0.7266931533813477\n","Epoch: 2, Loss: 0.6600632667541504\n","Epoch: 2, Loss: 0.7348804473876953\n","Epoch: 2, Loss: 0.6771492958068848\n","Epoch: 2, Loss: 0.675761878490448\n","Epoch: 2, Loss: 0.7003493905067444\n","Epoch: 2, Loss: 0.7051713466644287\n","Epoch: 2, Loss: 0.6174905300140381\n","Epoch: 2, Loss: 0.6708687543869019\n","Epoch: 2, Loss: 0.7047330141067505\n","Epoch: 2, Loss: 0.7115527987480164\n","Epoch: 2, Loss: 0.6635140776634216\n","Epoch: 2, Loss: 0.6752405166625977\n","Epoch: 2, Loss: 0.6982064247131348\n","Epoch: 2, Loss: 0.7117224931716919\n","Epoch: 2, Loss: 0.6709221005439758\n","Epoch: 2, Loss: 0.6702383756637573\n","Epoch: 2, Loss: 0.6074804067611694\n","Epoch: 2, Loss: 0.6982443928718567\n","Epoch: 2, Loss: 0.6917120218276978\n","Epoch: 2, Loss: 0.7328121662139893\n","Epoch: 2, Loss: 0.628657341003418\n","Epoch: 2, Loss: 0.666009783744812\n","Epoch: 2, Loss: 0.675798237323761\n","Epoch: 2, Loss: 0.6607762575149536\n","Epoch: 2, Loss: 0.7068631649017334\n","Epoch: 2, Loss: 0.7763392329216003\n","Epoch: 2, Loss: 0.7317507863044739\n","Epoch: 2, Loss: 0.7737421989440918\n","Epoch: 2, Loss: 0.7628721594810486\n","Epoch: 2, Loss: 0.6775926351547241\n","Epoch: 2, Loss: 0.7049317359924316\n","Epoch: 2, Loss: 0.7689070701599121\n","Epoch: 2, Loss: 0.709889829158783\n","Epoch: 2, Loss: 0.6750865578651428\n","Epoch: 2, Loss: 0.7563865184783936\n","Epoch: 2, Loss: 0.6539324522018433\n","Epoch: 2, Loss: 0.6849483251571655\n","Epoch: 2, Loss: 0.693472146987915\n","Epoch: 2, Loss: 0.688971996307373\n","Epoch: 2, Loss: 0.7119318842887878\n","Epoch: 2, Loss: 0.6864161491394043\n","Epoch: 2, Loss: 0.7271470427513123\n","Epoch: 2, Loss: 0.7127941250801086\n","Epoch: 2, Loss: 0.6626627445220947\n","Epoch: 2, Loss: 0.6675940752029419\n","Epoch: 2, Loss: 0.6806454062461853\n","Epoch: 2, Loss: 0.7216895818710327\n","Epoch: 2, Loss: 0.7083922624588013\n","Epoch: 2, Loss: 0.6762293577194214\n","Epoch: 2, Loss: 0.7729286551475525\n","Epoch: 2, Loss: 0.7531337738037109\n","Epoch: 2, Loss: 0.7137079834938049\n","Epoch: 2, Loss: 0.7554160952568054\n","Epoch: 2, Loss: 0.7653664350509644\n","Epoch: 2, Loss: 0.7331511974334717\n","Epoch: 2, Loss: 0.7074715495109558\n","Epoch: 2, Loss: 0.682343065738678\n","Epoch: 2, Loss: 0.6923293471336365\n","Epoch: 2, Loss: 0.7241994738578796\n","Epoch: 2, Loss: 0.7218461036682129\n","Epoch: 2, Loss: 0.7490664720535278\n","Epoch: 2, Loss: 0.650610625743866\n","Epoch: 2, Loss: 0.734616219997406\n","Epoch: 2, Loss: 0.6901503205299377\n","Epoch: 2, Loss: 0.6750330328941345\n","Epoch: 2, Loss: 0.6379541158676147\n","Epoch: 2, Loss: 0.7139700651168823\n","Epoch: 2, Loss: 0.6794246435165405\n","Epoch: 2, Loss: 0.7041831612586975\n","Epoch: 2, Loss: 0.6628270149230957\n","Epoch: 2, Loss: 0.753370463848114\n","Epoch: 2, Loss: 0.6836590766906738\n","Epoch: 2, Loss: 0.6840976476669312\n","Epoch: 2, Loss: 0.7003009915351868\n","Epoch: 2, Loss: 0.7277008295059204\n","Epoch: 2, Loss: 0.6968945264816284\n","Epoch: 2, Loss: 0.6244503855705261\n","Epoch: 2, Loss: 0.7148561477661133\n","Epoch: 2, Loss: 0.6259401440620422\n","Epoch: 2, Loss: 0.8138730525970459\n","Epoch: 2, Loss: 0.8032445311546326\n","Epoch: 2, Loss: 0.7347318530082703\n","Epoch: 2, Loss: 0.6828774213790894\n","Epoch: 2, Loss: 0.7311197519302368\n","Epoch: 2, Loss: 0.7079603672027588\n","Epoch: 2, Loss: 0.6347731947898865\n","Epoch: 2, Loss: 0.7735304832458496\n","Epoch: 2, Loss: 0.6874338984489441\n","Epoch: 2, Loss: 0.6613560914993286\n","Epoch: 2, Loss: 0.7682994604110718\n","Epoch: 2, Loss: 0.6810275316238403\n","Epoch: 2, Loss: 0.7676854133605957\n","Epoch: 2, Loss: 0.7135624289512634\n","Epoch: 2, Loss: 0.7497488260269165\n","Epoch: 2, Loss: 0.6871297955513\n","Epoch: 2, Loss: 0.7069547772407532\n","Epoch: 2, Loss: 0.7182202339172363\n","Epoch: 2, Loss: 0.7620106339454651\n","Epoch: 2, Loss: 0.6949830651283264\n","Epoch: 2, Loss: 0.6891584396362305\n","Epoch: 2, Loss: 0.7313422560691833\n","Epoch: 2, Loss: 0.6457998752593994\n","Epoch: 2, Loss: 0.9274612665176392\n","Epoch: 2, Loss: 0.713333785533905\n","Epoch: 2, Loss: 0.7230716347694397\n","Epoch: 2, Loss: 0.707088053226471\n","Epoch: 2, Loss: 0.733634352684021\n","Epoch: 2, Loss: 0.6578549742698669\n","Epoch: 2, Loss: 0.6918206810951233\n","Epoch: 2, Loss: 0.9597667455673218\n","Epoch: 2, Loss: 0.732280969619751\n","Epoch: 2, Loss: 0.7344529032707214\n","Epoch: 2, Loss: 0.7424349188804626\n","Epoch: 2, Loss: 0.7395051121711731\n","Epoch: 2, Loss: 0.680073618888855\n","Epoch: 2, Loss: 0.6672156453132629\n","Epoch: 2, Loss: 0.6473220586776733\n","Epoch: 2, Loss: 0.6447463631629944\n","Epoch: 2, Loss: 0.5907614231109619\n","Epoch: 2, Loss: 0.7121919989585876\n","Epoch: 2, Loss: 0.7338445782661438\n","Epoch: 2, Loss: 0.674457311630249\n","Epoch: 2, Loss: 0.8392511010169983\n","Epoch: 2, Loss: 0.6290563344955444\n","Epoch: 2, Loss: 0.6194546222686768\n","Epoch: 2, Loss: 0.7715374231338501\n","Epoch: 2, Loss: 0.8022248148918152\n","Epoch: 2, Loss: 0.7111607193946838\n","Epoch: 2, Loss: 0.7113431692123413\n","Epoch: 2, Loss: 0.7308545112609863\n","Epoch: 2, Loss: 0.6629478931427002\n","Epoch: 2, Loss: 0.6144121885299683\n","Epoch: 2, Loss: 0.5995884537696838\n","Epoch: 2, Loss: 0.7309486269950867\n","Epoch: 2, Loss: 0.7684872150421143\n","Epoch: 2, Loss: 0.5385226011276245\n","Epoch: 2, Loss: 0.6660772562026978\n","Epoch: 2, Loss: 0.4272405505180359\n","Epoch: 2, Loss: 0.4713427722454071\n","Epoch: 2, Loss: 1.0632340908050537\n","Epoch: 2, Loss: 0.9551646113395691\n","Epoch: 2, Loss: 0.7808388471603394\n","Epoch: 2, Loss: 0.7576385736465454\n","Epoch: 2, Loss: 0.7740928530693054\n","Epoch: 2, Loss: 0.6844386458396912\n","Epoch: 2, Loss: 0.7883440256118774\n","Epoch: 2, Loss: 0.722960889339447\n","Epoch: 2, Loss: 0.6748251914978027\n","Epoch: 2, Loss: 0.6550724506378174\n","Epoch: 2, Loss: 0.7004082798957825\n","Epoch: 2, Loss: 0.6655502319335938\n","Epoch: 2, Loss: 0.7335725426673889\n","Epoch: 2, Loss: 0.6793469190597534\n","Epoch: 2, Loss: 0.7012122869491577\n","Epoch: 2, Loss: 0.6416938304901123\n","Epoch: 2, Loss: 0.6668137311935425\n","Epoch: 2, Loss: 0.6701903939247131\n","Epoch: 2, Loss: 0.6998241543769836\n","Epoch: 2, Loss: 0.6936533451080322\n","Epoch: 2, Loss: 0.6715144515037537\n","Epoch: 2, Loss: 0.6887523531913757\n","Epoch: 2, Loss: 0.6570491790771484\n","Epoch: 2, Loss: 0.6066429018974304\n","Epoch: 2, Loss: 0.7762099504470825\n","Epoch: 2, Loss: 0.6142791509628296\n","Epoch: 2, Loss: 0.6760111451148987\n","Epoch: 2, Loss: 0.7000075578689575\n","Epoch: 2, Loss: 0.7272228002548218\n","Epoch: 2, Loss: 0.6618907451629639\n","Epoch: 2, Loss: 0.7733320593833923\n","Epoch: 2, Loss: 0.7035331726074219\n","Epoch: 2, Loss: 0.6522707939147949\n","Epoch: 2, Loss: 0.7145271301269531\n","Epoch: 2, Loss: 0.6647270321846008\n","Epoch: 2, Loss: 0.6608936190605164\n","Epoch: 2, Loss: 0.6572810411453247\n","Epoch: 2, Loss: 0.6560095548629761\n","Epoch: 2, Loss: 0.6832846403121948\n","Epoch: 2, Loss: 0.7853779792785645\n","Epoch: 2, Loss: 0.7385885715484619\n","Epoch: 2, Loss: 0.733855664730072\n","Epoch: 2, Loss: 0.6968498826026917\n","Epoch: 2, Loss: 0.6489706039428711\n","Epoch: 2, Loss: 0.6436566114425659\n","Epoch: 2, Loss: 0.6940200924873352\n","Epoch: 2, Loss: 0.6268726587295532\n","Epoch: 2, Loss: 0.7037839889526367\n","Epoch: 2, Loss: 0.7859264612197876\n","Epoch: 2, Loss: 0.7064255475997925\n","Epoch: 2, Loss: 0.6771019697189331\n","Epoch: 2, Loss: 0.669121503829956\n","Epoch: 2, Loss: 0.6623163819313049\n","Epoch: 2, Loss: 0.6906952857971191\n","Epoch: 2, Loss: 0.7743194699287415\n","Epoch: 2, Loss: 0.7186174988746643\n","Epoch: 2, Loss: 0.7053108215332031\n","Epoch: 2, Loss: 0.6504144072532654\n","Epoch: 2, Loss: 0.6726023554801941\n","Epoch: 2, Loss: 0.6719937920570374\n","Epoch: 2, Loss: 0.7235172390937805\n","Epoch: 2, Loss: 0.6641201972961426\n","Epoch: 2, Loss: 0.7161431312561035\n","Epoch: 2, Loss: 0.728567361831665\n","Epoch: 2, Loss: 0.6459015011787415\n","Epoch: 2, Loss: 0.6805590391159058\n","Epoch: 2, Loss: 0.7345327138900757\n","Epoch: 2, Loss: 0.680330753326416\n","Epoch: 2, Loss: 0.7250625491142273\n","Epoch: 2, Loss: 0.6716573238372803\n","Epoch: 2, Loss: 0.6964216828346252\n","Epoch: 2, Loss: 0.7005329728126526\n","Epoch: 2, Loss: 0.7194584608078003\n","Epoch: 2, Loss: 0.7033880949020386\n","Epoch: 2, Loss: 0.7085380554199219\n","Epoch: 2, Loss: 0.7435668110847473\n","Epoch: 2, Loss: 0.6633324027061462\n","Epoch: 2, Loss: 0.6715676188468933\n","Epoch: 2, Loss: 0.7134624719619751\n","Epoch: 2, Loss: 0.6579231023788452\n","Epoch: 2, Loss: 0.6775407195091248\n","Epoch: 2, Loss: 0.66254061460495\n","Epoch: 2, Loss: 0.7168432474136353\n","Epoch: 2, Loss: 0.701644778251648\n","Epoch: 2, Loss: 0.665341854095459\n","Epoch: 2, Loss: 0.6812906265258789\n","Epoch: 2, Loss: 0.6948967576026917\n","Epoch: 2, Loss: 0.7026380300521851\n","Epoch: 2, Loss: 0.6859040856361389\n","Epoch: 2, Loss: 0.7313646674156189\n","Epoch: 2, Loss: 0.7033433318138123\n","Epoch: 2, Loss: 0.7011045217514038\n","Epoch: 2, Loss: 0.68143230676651\n","Epoch: 2, Loss: 0.6454261541366577\n","Epoch: 2, Loss: 0.6833662390708923\n","Epoch: 2, Loss: 0.6683306097984314\n","Epoch: 2, Loss: 0.7309354543685913\n","Epoch: 2, Loss: 0.696702778339386\n","Epoch: 2, Loss: 0.6706175208091736\n","Epoch: 2, Loss: 0.7122214436531067\n","Epoch: 2, Loss: 0.6730961799621582\n","Epoch: 2, Loss: 0.6817070245742798\n","Epoch: 2, Loss: 0.711421549320221\n","Epoch: 2, Loss: 0.6908946633338928\n","Epoch: 2, Loss: 0.6940412521362305\n","Epoch: 2, Loss: 0.6786266565322876\n","Epoch: 2, Loss: 0.679742157459259\n","Epoch: 2, Loss: 0.7059313654899597\n","Epoch: 2, Loss: 0.683515191078186\n","Epoch: 2, Loss: 0.7094714641571045\n","Epoch: 2, Loss: 0.7023547887802124\n","Epoch: 2, Loss: 0.7123044729232788\n","Epoch: 2, Loss: 0.666175127029419\n","Epoch: 2, Loss: 0.6671178340911865\n","Epoch: 2, Loss: 0.6853328347206116\n","Epoch: 2, Loss: 0.6969619989395142\n","Epoch: 2, Loss: 0.6591346859931946\n","Epoch: 2, Loss: 0.7310020327568054\n","Epoch: 2, Loss: 0.6967000961303711\n","Epoch: 2, Loss: 0.6880462169647217\n","Epoch: 2, Loss: 0.7002928853034973\n","Epoch: 2, Loss: 0.717836320400238\n","Epoch: 2, Loss: 0.7068788409233093\n","Epoch: 2, Loss: 0.7353647947311401\n","Epoch: 2, Loss: 0.7333997488021851\n","Epoch: 2, Loss: 0.6943334937095642\n","Epoch: 2, Loss: 0.6880894303321838\n","Epoch: 2, Loss: 0.6776801943778992\n","Epoch: 2, Loss: 0.6677602529525757\n","Epoch: 2, Loss: 0.7089003324508667\n","Epoch: 2, Loss: 0.7084982991218567\n","Epoch: 2, Loss: 0.7254643440246582\n","Epoch: 2, Loss: 0.6805213689804077\n","Epoch: 2, Loss: 0.6897273659706116\n","Epoch: 2, Loss: 0.7155242562294006\n","Epoch: 2, Loss: 0.7054465413093567\n","Epoch: 2, Loss: 0.726780891418457\n","Epoch: 2, Loss: 0.6903724670410156\n","Epoch: 2, Loss: 0.7040596604347229\n","Epoch: 2, Loss: 0.7065990567207336\n","Epoch: 2, Loss: 0.6843008399009705\n","Epoch: 2, Loss: 0.7149509191513062\n","Epoch: 2, Loss: 0.7258403897285461\n","Epoch: 2, Loss: 0.7076079249382019\n","Epoch: 2, Loss: 0.7320301532745361\n","Epoch: 2, Loss: 0.7053053975105286\n","Epoch: 2, Loss: 0.6891942620277405\n","Epoch: 2, Loss: 0.7163918018341064\n","Epoch: 2, Loss: 0.7012780904769897\n","Epoch: 2, Loss: 0.7230749726295471\n","Epoch: 2, Loss: 0.698205828666687\n","Epoch: 2, Loss: 0.7137255072593689\n","Epoch: 2, Loss: 0.6966007947921753\n","Epoch: 2, Loss: 0.6955574154853821\n","Epoch: 2, Loss: 0.6693866848945618\n","Epoch: 2, Loss: 0.6899623274803162\n","Epoch: 2, Loss: 0.6723401546478271\n","Epoch: 2, Loss: 0.7053942084312439\n","Epoch: 2, Loss: 0.666572630405426\n","Epoch: 2, Loss: 0.68575119972229\n","Epoch: 2, Loss: 0.7317249178886414\n","Epoch: 2, Loss: 0.6837307214736938\n","Epoch: 2, Loss: 0.6985279321670532\n","Epoch: 2, Loss: 0.6976855397224426\n","Epoch: 2, Loss: 0.6973633170127869\n","Epoch: 2, Loss: 0.7014568448066711\n","Epoch: 2, Loss: 0.6885063648223877\n","Epoch: 2, Loss: 0.7273112535476685\n","Epoch: 2, Loss: 0.705750048160553\n","Epoch: 2, Loss: 0.6819955110549927\n","Epoch: 2, Loss: 0.7167770862579346\n","Epoch: 2, Loss: 0.6948738694190979\n","Epoch: 2, Loss: 0.7014691829681396\n","Epoch: 2, Loss: 0.7278520464897156\n","Epoch: 2, Loss: 0.6841965913772583\n","Epoch: 2, Loss: 0.6948516368865967\n","Epoch: 2, Loss: 0.6841863393783569\n","Epoch: 2, Loss: 0.6963444352149963\n","Epoch: 2, Loss: 0.6850875020027161\n","Epoch: 2, Loss: 0.6995726823806763\n","Epoch: 2, Loss: 0.6655445694923401\n","Epoch: 2, Loss: 0.7048485279083252\n","Epoch: 2, Loss: 0.6826965808868408\n","Epoch: 2, Loss: 0.6992282271385193\n","Epoch: 2, Loss: 0.7053874135017395\n","Epoch: 2, Loss: 0.7100552916526794\n","Epoch: 2, Loss: 0.6952405571937561\n","Epoch: 2, Loss: 0.7294433116912842\n","Epoch: 2, Loss: 0.6778419017791748\n","Epoch: 2, Loss: 0.6900124549865723\n","Epoch: 2, Loss: 0.6828847527503967\n","Epoch: 2, Loss: 0.6937283277511597\n","Epoch: 2, Loss: 0.6897912621498108\n","Epoch: 2, Loss: 0.704060435295105\n","Epoch: 2, Loss: 0.692111611366272\n","Epoch: 2, Loss: 0.6980167031288147\n","Epoch: 2, Loss: 0.6637536883354187\n","Epoch: 2, Loss: 0.6769547462463379\n","Epoch: 2, Loss: 0.6727132797241211\n","Epoch: 2, Loss: 0.6916185021400452\n","Epoch: 2, Loss: 0.6932855248451233\n","Epoch: 2, Loss: 0.6957710385322571\n","Epoch: 2, Loss: 0.7004504799842834\n","Epoch: 2, Loss: 0.6974154114723206\n","Epoch: 2, Loss: 0.6894857883453369\n","Epoch: 2, Loss: 0.6720033288002014\n","Epoch: 2, Loss: 0.685465931892395\n","Epoch: 2, Loss: 0.6796538233757019\n","Epoch: 2, Loss: 0.7284665107727051\n","Epoch: 2, Loss: 0.7350266575813293\n","Epoch: 2, Loss: 0.6820275187492371\n","Epoch: 2, Loss: 0.683268666267395\n","Epoch: 2, Loss: 0.697839617729187\n","Epoch: 2, Loss: 0.6922717094421387\n","Epoch: 2, Loss: 0.6913369297981262\n","Epoch: 2, Loss: 0.6979398131370544\n","Epoch: 2, Loss: 0.6927744746208191\n","Epoch: 2, Loss: 0.7406694293022156\n","Epoch: 2, Loss: 0.712558388710022\n","Epoch: 2, Loss: 0.6869349479675293\n","Epoch: 2, Loss: 0.7060741782188416\n","Epoch: 2, Loss: 0.6871610879898071\n","Epoch: 2, Loss: 0.7054653167724609\n","Epoch: 2, Loss: 0.7149124145507812\n","Epoch: 2, Loss: 0.6925009489059448\n","Epoch: 2, Loss: 0.6850245594978333\n","Epoch: 2, Loss: 0.6829238533973694\n","Epoch: 2, Loss: 0.7056902050971985\n","Epoch: 2, Loss: 0.7058707475662231\n","Epoch: 2, Loss: 0.7063971757888794\n","Epoch: 2, Loss: 0.7017360329627991\n","Epoch: 2, Loss: 0.7148565053939819\n","Epoch: 2, Loss: 0.6985541582107544\n","Epoch: 2, Loss: 0.6667880415916443\n","Epoch: 2, Loss: 0.6953521966934204\n","Epoch: 2, Loss: 0.6846724152565002\n","Epoch: 2, Loss: 0.701700747013092\n","Epoch: 2, Loss: 0.6863061189651489\n","Epoch: 2, Loss: 0.6949488520622253\n","Epoch: 2, Loss: 0.6943250298500061\n","Epoch: 2, Loss: 0.6724669933319092\n","Epoch: 2, Loss: 0.7008079886436462\n","Epoch: 2, Loss: 0.6541987061500549\n","Epoch: 2, Loss: 0.6833292245864868\n","Epoch: 2, Loss: 0.6798478364944458\n","Epoch: 2, Loss: 0.6958261132240295\n","Epoch: 2, Loss: 0.7387604713439941\n","Epoch: 2, Loss: 0.701379656791687\n","Epoch: 2, Loss: 0.6937408447265625\n","Epoch: 2, Loss: 0.6642855405807495\n","Epoch: 2, Loss: 0.6894556879997253\n","Epoch: 2, Loss: 0.6820763945579529\n","Epoch: 2, Loss: 0.6980206966400146\n","Epoch: 2, Loss: 0.6831329464912415\n","Epoch: 2, Loss: 0.6810951828956604\n","Epoch: 2, Loss: 0.6862807273864746\n","Epoch: 2, Loss: 0.6872302293777466\n","Epoch: 2, Loss: 0.6924297213554382\n","Epoch: 2, Loss: 0.7245159149169922\n","Epoch: 2, Loss: 0.6639202237129211\n","Epoch: 2, Loss: 0.7074702978134155\n","Epoch: 2, Loss: 0.6888234615325928\n","Epoch: 2, Loss: 0.6888919472694397\n","Epoch: 2, Loss: 0.7369223833084106\n","Epoch: 2, Loss: 0.6734842658042908\n","Epoch: 2, Loss: 0.6731842756271362\n","Epoch: 2, Loss: 0.7028777003288269\n","Epoch: 2, Loss: 0.696876049041748\n","Epoch: 2, Loss: 0.6978699564933777\n","Epoch: 2, Loss: 0.7187560200691223\n","Epoch: 2, Loss: 0.6949893832206726\n","Epoch: 2, Loss: 0.6624230742454529\n","Epoch: 2, Loss: 0.6874868869781494\n","Epoch: 2, Loss: 0.6790750026702881\n","Epoch: 2, Loss: 0.6893683671951294\n","Epoch: 2, Loss: 0.7066977620124817\n","Epoch: 2, Loss: 0.6886885166168213\n","Epoch: 2, Loss: 0.7077205777168274\n","Epoch: 2, Loss: 0.7125251293182373\n","Epoch: 2, Loss: 0.6939335465431213\n","Epoch: 2, Loss: 0.6775423884391785\n","Epoch: 2, Loss: 0.6853230595588684\n","Epoch: 2, Loss: 0.6836434006690979\n","Epoch: 2, Loss: 0.6704495549201965\n","Epoch: 2, Loss: 0.6861423254013062\n","Epoch: 2, Loss: 0.7215408682823181\n","Epoch: 2, Loss: 0.6882667541503906\n","Epoch: 2, Loss: 0.6906535625457764\n","Epoch: 2, Loss: 0.7247551679611206\n","Epoch: 2, Loss: 0.6700090169906616\n","Epoch: 2, Loss: 0.7440434694290161\n","Epoch: 2, Loss: 0.6939488649368286\n","Epoch: 2, Loss: 0.6966043710708618\n","Epoch: 2, Loss: 0.6976618766784668\n","Epoch: 2, Loss: 0.6837469339370728\n","Epoch: 2, Loss: 0.705237090587616\n","Epoch: 2, Loss: 0.6641223430633545\n","Epoch: 2, Loss: 0.7023097276687622\n","Epoch: 2, Loss: 0.6836235523223877\n","Epoch: 2, Loss: 0.7151826620101929\n","Epoch: 2, Loss: 0.7188094258308411\n","Epoch: 2, Loss: 0.6918389797210693\n","Epoch: 2, Loss: 0.6983857750892639\n","Epoch: 2, Loss: 0.6860820651054382\n","Epoch: 2, Loss: 0.7033798694610596\n","Epoch: 2, Loss: 0.7115421891212463\n","Epoch: 2, Loss: 0.693584144115448\n","Epoch: 2, Loss: 0.7119377851486206\n","Epoch: 2, Loss: 0.6906639933586121\n","Epoch: 2, Loss: 0.7094345092773438\n","Epoch: 2, Loss: 0.699483335018158\n","Epoch: 2, Loss: 0.7099688053131104\n","Epoch: 2, Loss: 0.70607990026474\n","Epoch: 2, Loss: 0.7065895795822144\n","Epoch: 2, Loss: 0.7104122638702393\n","Epoch: 2, Loss: 0.6782422065734863\n","Epoch: 2, Loss: 0.6693912148475647\n","Epoch: 2, Loss: 0.6657543778419495\n","Epoch: 2, Loss: 0.6610302925109863\n","Epoch: 2, Loss: 0.6799737215042114\n","Epoch: 2, Loss: 0.7013712525367737\n","Epoch: 2, Loss: 0.6699411273002625\n","Epoch: 2, Loss: 0.6795627474784851\n","Epoch: 2, Loss: 0.7019680738449097\n","Epoch: 2, Loss: 0.693199872970581\n","Epoch: 2, Loss: 0.6990787386894226\n","Epoch: 2, Loss: 0.6995813250541687\n","Epoch: 2, Loss: 0.7171339988708496\n","Epoch: 2, Loss: 0.7025413513183594\n","Epoch: 2, Loss: 0.751362144947052\n","Epoch: 2, Loss: 0.6521090269088745\n","Epoch: 2, Loss: 0.688091516494751\n","Epoch: 2, Loss: 0.7192494869232178\n","Epoch: 2, Loss: 0.6992156505584717\n","Epoch: 2, Loss: 0.7203320264816284\n","Epoch: 2, Loss: 0.7009738683700562\n","Epoch: 2, Loss: 0.7077972888946533\n","Epoch: 2, Loss: 0.7243474721908569\n","Epoch: 2, Loss: 0.681858241558075\n","Epoch: 2, Loss: 0.6715471148490906\n","Epoch: 2, Loss: 0.6725936532020569\n","Epoch: 2, Loss: 0.6875348687171936\n","Epoch: 2, Loss: 0.6790223717689514\n","Epoch: 2, Loss: 0.7234187722206116\n","Epoch: 2, Loss: 0.6810742020606995\n","Epoch: 2, Loss: 0.7151002883911133\n","Epoch: 2, Loss: 0.6822336316108704\n","Epoch: 2, Loss: 0.6686509251594543\n","Epoch: 2, Loss: 0.6426529288291931\n","Epoch: 2, Loss: 0.7112386226654053\n","Epoch: 2, Loss: 0.6920982599258423\n","Epoch: 2, Loss: 0.6884967684745789\n","Epoch: 2, Loss: 0.716259241104126\n","Epoch: 2, Loss: 0.7026686072349548\n","Epoch: 2, Loss: 0.6657391786575317\n","Epoch: 2, Loss: 0.6821200847625732\n","Epoch: 2, Loss: 0.7109561562538147\n","Epoch: 2, Loss: 0.6987561583518982\n","Epoch: 2, Loss: 0.6859168410301208\n","Epoch: 2, Loss: 0.7140446901321411\n","Epoch: 2, Loss: 0.67149418592453\n","Epoch: 2, Loss: 0.6831852793693542\n","Epoch: 2, Loss: 0.7033367156982422\n","Epoch: 2, Loss: 0.6931159496307373\n","Epoch: 2, Loss: 0.6823606491088867\n","Epoch: 2, Loss: 0.690663754940033\n","Epoch: 2, Loss: 0.6933916211128235\n","Epoch: 2, Loss: 0.6666671633720398\n","Epoch: 2, Loss: 0.7111069560050964\n","Epoch: 2, Loss: 0.7061195969581604\n","Epoch: 2, Loss: 0.7091833353042603\n","Epoch: 2, Loss: 0.7045618295669556\n","Epoch: 2, Loss: 0.6873824596405029\n","Epoch: 2, Loss: 0.6829895973205566\n","Epoch: 2, Loss: 0.6881451606750488\n","Epoch: 2, Loss: 0.6582958698272705\n","Epoch: 2, Loss: 0.6954813599586487\n","Epoch: 2, Loss: 0.680866539478302\n","Epoch: 2, Loss: 0.691929817199707\n","Epoch: 2, Loss: 0.7126631140708923\n","Epoch: 2, Loss: 0.6846305727958679\n","Epoch: 2, Loss: 0.6908813118934631\n","Epoch: 2, Loss: 0.6724147200584412\n","Epoch: 2, Loss: 0.692930281162262\n","Epoch: 2, Loss: 0.6727958917617798\n","Epoch: 2, Loss: 0.6868327260017395\n","Epoch: 2, Loss: 0.6936013698577881\n","Epoch: 2, Loss: 0.7018917202949524\n","Epoch: 2, Loss: 0.7131428718566895\n","Epoch: 2, Loss: 0.7222993969917297\n","Epoch: 2, Loss: 0.6891939043998718\n","Epoch: 2, Loss: 0.6416746377944946\n","Epoch: 2, Loss: 0.6936977505683899\n","Epoch: 2, Loss: 0.6690807342529297\n","Epoch: 2, Loss: 0.7057463526725769\n","Epoch: 2, Loss: 0.6617945432662964\n","Epoch: 2, Loss: 0.6510270833969116\n","Epoch: 2, Loss: 0.7171134948730469\n","Epoch: 2, Loss: 0.7175012826919556\n","Epoch: 2, Loss: 0.6807445287704468\n","Epoch: 2, Loss: 0.6804085373878479\n","Epoch: 2, Loss: 0.6990793347358704\n","Epoch: 2, Loss: 0.6652504801750183\n","Epoch: 2, Loss: 0.7054640650749207\n","Epoch: 2, Loss: 0.6920497417449951\n","Epoch: 2, Loss: 0.6918399333953857\n","Epoch: 2, Loss: 0.6632777452468872\n","Epoch: 2, Loss: 0.6741679906845093\n","Epoch: 2, Loss: 0.7004356980323792\n","Epoch: 2, Loss: 0.7306822538375854\n","Epoch: 2, Loss: 0.6843389272689819\n","Epoch: 2, Loss: 0.692200779914856\n","Epoch: 2, Loss: 0.7356150150299072\n","Epoch: 2, Loss: 0.6992631554603577\n","Epoch: 2, Loss: 0.7020533680915833\n","Epoch: 2, Loss: 0.6930950880050659\n","Epoch: 2, Loss: 0.6677731871604919\n","Epoch: 2, Loss: 0.6734504699707031\n","Epoch: 2, Loss: 0.6827743053436279\n","Epoch: 2, Loss: 0.7265973091125488\n","Epoch: 2, Loss: 0.6976945400238037\n","Epoch: 2, Loss: 0.7036697268486023\n","Epoch: 2, Loss: 0.6927303671836853\n","Epoch: 2, Loss: 0.6983258128166199\n","Epoch: 2, Loss: 0.6848762631416321\n","Epoch: 2, Loss: 0.6848884224891663\n","Epoch: 2, Loss: 0.6874271035194397\n","Epoch: 2, Loss: 0.6785215139389038\n","Epoch: 2, Loss: 0.7011696100234985\n","Epoch: 2, Loss: 0.6998534202575684\n","Epoch: 2, Loss: 0.7307239174842834\n","Epoch: 2, Loss: 0.6832101941108704\n","Epoch: 2, Loss: 0.6633957624435425\n","Epoch: 2, Loss: 0.698498010635376\n","Epoch: 2, Loss: 0.7173460721969604\n","Epoch: 2, Loss: 0.6767712235450745\n","Epoch: 2, Loss: 0.7182132005691528\n","Epoch: 2, Loss: 0.7156707644462585\n","Epoch: 2, Loss: 0.7121094465255737\n","Epoch: 2, Loss: 0.6828294396400452\n","Epoch: 2, Loss: 0.6894342303276062\n","Epoch: 2, Loss: 0.7073773741722107\n","Epoch: 2, Loss: 0.7037346363067627\n","Epoch: 2, Loss: 0.7042398452758789\n","Epoch: 2, Loss: 0.7264220714569092\n","Epoch: 2, Loss: 0.6675919890403748\n","Epoch: 2, Loss: 0.7218658924102783\n","Epoch: 2, Loss: 0.6756371259689331\n","Epoch: 2, Loss: 0.6944679021835327\n","Epoch: 2, Loss: 0.7254080772399902\n","Epoch: 2, Loss: 0.7166019082069397\n","Epoch: 2, Loss: 0.7081988453865051\n","Epoch: 2, Loss: 0.697852373123169\n","Epoch: 2, Loss: 0.6904692053794861\n","Epoch: 2, Loss: 0.7217244505882263\n","Epoch: 2, Loss: 0.70406174659729\n","Epoch: 2, Loss: 0.7052469849586487\n","Epoch: 2, Loss: 0.70582115650177\n","Epoch: 2, Loss: 0.6862061023712158\n","Epoch: 2, Loss: 0.7071033120155334\n","Epoch: 2, Loss: 0.6998550295829773\n","Epoch: 2, Loss: 0.7027886509895325\n","Epoch: 2, Loss: 0.7035477161407471\n","Epoch: 2, Loss: 0.6814172267913818\n","Epoch: 2, Loss: 0.6954675912857056\n","Epoch: 2, Loss: 0.6968201398849487\n","Epoch: 2, Loss: 0.690796434879303\n","Epoch: 2, Loss: 0.6850258111953735\n","Epoch: 2, Loss: 0.7202833890914917\n","Epoch: 2, Loss: 0.7126957178115845\n","Epoch: 2, Loss: 0.7288838028907776\n","Epoch: 2, Loss: 0.6868641376495361\n","Epoch: 2, Loss: 0.7006930708885193\n","Epoch: 2, Loss: 0.6886035799980164\n","Epoch: 2, Loss: 0.7132960557937622\n","Epoch: 2, Loss: 0.6948676109313965\n","Epoch: 2, Loss: 0.7360945343971252\n","Epoch: 2, Loss: 0.679711103439331\n","Epoch: 2, Loss: 0.6767106056213379\n","Epoch: 2, Loss: 0.6951207518577576\n","Epoch: 2, Loss: 0.7079106569290161\n","Epoch: 2, Loss: 0.704947829246521\n","Epoch: 2, Loss: 0.6565550565719604\n","Epoch: 2, Loss: 0.6999561190605164\n","Epoch: 2, Loss: 0.697351336479187\n","Epoch: 2, Loss: 0.7095611095428467\n","Epoch: 2, Loss: 0.6843128204345703\n","Epoch: 2, Loss: 0.6989033222198486\n","Epoch: 2, Loss: 0.6879366636276245\n","Epoch: 2, Loss: 0.7091901302337646\n","Epoch: 2, Loss: 0.7231644988059998\n","Epoch: 2, Loss: 0.6903277039527893\n","Epoch: 2, Loss: 0.7054373025894165\n","Epoch: 2, Loss: 0.7074394226074219\n","Epoch: 2, Loss: 0.7045334577560425\n","Epoch: 2, Loss: 0.6974709033966064\n","Epoch: 2, Loss: 0.688300609588623\n","Epoch: 2, Loss: 0.7001770734786987\n","Epoch: 2, Loss: 0.7031610608100891\n","Epoch: 2, Loss: 0.7031151056289673\n","Epoch: 2, Loss: 0.7004340291023254\n","Epoch: 2, Loss: 0.704656720161438\n","Epoch: 2, Loss: 0.7083101868629456\n","Epoch: 2, Loss: 0.6626723408699036\n","Epoch: 2, Loss: 0.7080846428871155\n","Epoch: 2, Loss: 0.7115703225135803\n","Epoch: 2, Loss: 0.7159692049026489\n","Epoch: 2, Loss: 0.6690874695777893\n","Epoch: 2, Loss: 0.6808876991271973\n","Epoch: 2, Loss: 0.6871892213821411\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","overall_accuracies, accuracies, f1s, precisions, recalls = [], [], [], [], []\n","\n","# for run in range(1):\n","for run in range(3):\n","  model_path = 'cladder_' + model_base + '_' + str(run) + '.pt'\n","  print(model_path)\n","\n","  model = mpc.from_pretrained(model_base, num_labels = 2)\n","  model.load_state_dict(torch.load(model_path))\n","\n","  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","  model.to(device)\n","\n","  tokenizer = tkz.from_pretrained(model_base)\n","  validation_dataset = CladderDataset(validation_data, tokenizer)\n","  validation_dataloader = DataLoader(validation_dataset, batch_size=8)\n","\n","\n","\n","\n","  model.eval()\n","  correct_predictions = 0\n","  total_predictions = 0\n","\n","  accuracy, f1, precision, recall = [], [], [], []\n","  batches = 0\n","\n","  def compute_metrics(y_true, y_pred):\n","      accuracy = accuracy_score(y_true, y_pred)\n","      # print(y_true)\n","      # print(y_pred)\n","      f1 = f1_score(y_true, y_pred)\n","\n","      precision = precision_score(y_true, y_pred)\n","      # print(precision)\n","      recall = recall_score(y_true, y_pred)\n","      return [accuracy, f1, precision, recall]\n","\n","  with torch.no_grad():\n","      for batch in validation_dataloader:\n","          input_ids = batch['input_ids'].squeeze(1)\n","          attention_mask = batch['attention_mask'].squeeze(1)\n","          labels = batch['labels'].cpu()  # ground truth\n","          # print(labels)\n","\n","          outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","          # print(outputs)\n","          # print(outputs.logits)\n","          predictions = torch.argmax(outputs.logits, dim=1).cpu()  # predictions\n","          # print(predictions)\n","\n","          calculated_metrics = compute_metrics(labels, predictions)\n","          accuracy.append(calculated_metrics[0])\n","          f1.append(calculated_metrics[1])\n","          precision.append(calculated_metrics[2])\n","          recall.append(calculated_metrics[3])\n","          batches += 1\n","\n","          correct_predictions += (predictions == labels).sum().item()\n","          total_predictions += labels.size(0)\n","\n","  overall_accuracy = correct_predictions / total_predictions\n","  print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n","  overall_accuracies.append(overall_accuracy)\n","\n","  accuracy_var = sum(accuracy)/batches\n","  print(f\"Accuracy: {sum(accuracy)/batches:.4f}\")\n","  print(accuracy_var)\n","  accuracies.append(accuracy_var)\n","\n","  f1_var = sum(f1)/batches\n","  print(f\"F1: {sum(f1)/batches:.4f}\")\n","  print(f1_var)\n","  f1s.append(f1_var)\n","\n","  precision_var = sum(precision)/batches\n","  print(f\"Precision: {sum(precision)/batches:.4f}\")\n","  print(precision_var)\n","  precisions.append(precision_var)\n","\n","  recall_var = sum(recall)/batches\n","  print(f\"Recall: {sum(recall)/batches:.4f}\")\n","  print(recall_var)\n","  recalls.append(precision_var)\n","\n","  print(f'Number of batches: {batches}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUm1_9RmiWwc","executionInfo":{"status":"ok","timestamp":1707466644739,"user_tz":480,"elapsed":281713,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}},"outputId":"e0b4120d-7b77-4f6d-b32d-0be2389f7d49"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["cladder_albert-base-v2_0.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Overall Accuracy: 0.4905\n","Accuracy: 0.4905\n","0.49050632911392406\n","F1: 0.6387\n","0.6386568424543108\n","Precision: 0.4905\n","0.49050632911392406\n","Recall: 0.9968\n","0.9968354430379747\n","Number of batches: 316\n","cladder_albert-base-v2_1.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Overall Accuracy: 0.5036\n","Accuracy: 0.5036\n","0.5035601265822784\n","F1: 0.1086\n","0.10858700020092416\n","Precision: 0.2363\n","0.23628691983122366\n","Recall: 0.0745\n","0.07452531645569614\n","Number of batches: 316\n","cladder_albert-base-v2_2.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Overall Accuracy: 0.4905\n","Accuracy: 0.4905\n","0.49050632911392406\n","F1: 0.6387\n","0.6386568424543108\n","Precision: 0.4905\n","0.49050632911392406\n","Recall: 0.9968\n","0.9968354430379747\n","Number of batches: 316\n"]}]},{"cell_type":"code","source":["# # Prepare the DataLoader\n","# cladder_dataset = CladderDataset(train_data, tokenizer)\n","# dataloader = DataLoader(cladder_dataset, batch_size=8, shuffle=True)\n","\n","# # Optimizer and Loss Function\n","# optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","# loss_fn = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"_6eTqCkZWb8-","executionInfo":{"status":"ok","timestamp":1707466644740,"user_tz":480,"elapsed":20,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# # Training Loop\n","# model.train()\n","\n","# for epoch in range(3):  # Number of epochs\n","#   for batch in dataloader:\n","#       optimizer.zero_grad()\n","\n","#       input_ids = batch['input_ids'].squeeze(1)\n","#       attention_mask = batch['attention_mask'].squeeze(1)\n","#       labels = batch['labels']\n","\n","#       outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","#       loss = outputs.loss\n","\n","#       loss.backward()\n","#       optimizer.step()\n","\n","#       print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"],"metadata":{"id":"iF4TE_17WdkS","executionInfo":{"status":"ok","timestamp":1707466644740,"user_tz":480,"elapsed":19,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# validation_dataset = CladderDataset(validation_data, tokenizer)\n","# validation_dataloader = DataLoader(validation_dataset, batch_size=8)"],"metadata":{"id":"Nc3O5g-wWfA5","executionInfo":{"status":"ok","timestamp":1707466644740,"user_tz":480,"elapsed":19,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","correct_predictions = 0\n","total_predictions = 0\n","\n","with torch.no_grad():\n","    for batch in validation_dataloader:\n","        input_ids = batch['input_ids'].squeeze(1)\n","        attention_mask = batch['attention_mask'].squeeze(1)\n","        labels = batch['labels']\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        predictions = torch.argmax(outputs.logits, dim=1)\n","        correct_predictions += (predictions == labels).sum().item()\n","        print(f\"predictions: {predictions}, labels: {labels}\")\n","        total_predictions += labels.size(0)\n","\n","print(f\"total_predictions: {total_predictions}\")\n","\n","overall_accuracy = correct_predictions / total_predictions\n","print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7JzoyhuW6CD","executionInfo":{"status":"ok","timestamp":1705796664536,"user_tz":480,"elapsed":24906,"user":{"displayName":"MAYANK JINDAL","userId":"01144091630627793402"}},"outputId":"544bc3ed-53d6-41ce-d10b-bde5dc71af8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["predictions: tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 1, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 1, 0, 1, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","predictions: tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'), labels: tensor([0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n","predictions: tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'), labels: tensor([1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n","predictions: tensor([1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0'), labels: tensor([0, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n","predictions: tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'), labels: tensor([0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n","predictions: tensor([1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 1, 0, 0, 1, 0, 1], device='cuda:0'), labels: tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0')\n","predictions: tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'), labels: tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n","predictions: tensor([1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'), labels: tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n","predictions: tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'), labels: tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","total_predictions: 2528\n","Overall Accuracy: 0.5186\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"X_-sV5SLW89i"},"execution_count":null,"outputs":[]}]}